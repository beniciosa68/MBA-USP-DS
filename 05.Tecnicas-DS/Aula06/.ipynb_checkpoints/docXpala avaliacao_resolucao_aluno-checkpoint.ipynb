{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\"> MBA em Ciência de Dados</span>\n",
    "# <span style=\"color:blue\">Técnicas Avançadas para Captura e Tratamento de Dados</span>\n",
    "\n",
    "## <span style=\"color:blue\"> Matriz Documento $\\times$ Palavras - Bag of Words</span>\n",
    "    \n",
    "## <span style=\"color:blue\">Avaliação</span>\n",
    "\n",
    "**Material Produzido por Luis Gustavo Nonato**<br>\n",
    "**Cemeai - ICMC/USP São Carlos**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os exercícios abaixo fazem uso da coleção de documentos presente no diretório `DocCol2` contido no arquivo <font style=\"font-family: monaco\"> DocCol.zip</font>, o qual pode ser baixado do Moodle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\fernando\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\fernando\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "_ = nltk.download('punkt')\n",
    "_ = nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 1)\n",
    "Armazene os documentos disponíveis no diretório `DocCol2` em um dicionário onde a chave é o nome do arquivo e o valor é a string contida no arquivo. O documento contendo a string com o maior número de caracteres é:\n",
    "\n",
    "a) gr7<br>\n",
    "__b) au2__ <br>\n",
    "c) ch5<br>\n",
    "d) au8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Doc</th>\n",
       "      <th>LenDoc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>au2</td>\n",
       "      <td>From: welty@cabot.balltown.cma.COM (richard we...</td>\n",
       "      <td>11672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>au5</td>\n",
       "      <td>From: CPKJP@vm.cc.latech.edu (Kevin Parker)\\nS...</td>\n",
       "      <td>9693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>au14</td>\n",
       "      <td>From: eliot@engr.washington.edu (eliot)\\nSubje...</td>\n",
       "      <td>9351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>ch37</td>\n",
       "      <td>From: jhpb@sarto.budd-lake.nj.us (Joseph H. Bu...</td>\n",
       "      <td>9279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>gr23</td>\n",
       "      <td>From: lilley@v5.cgu.mcc.ac.uk (Chris Lilley)\\n...</td>\n",
       "      <td>9261</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Name                                                Doc  LenDoc\n",
       "7    au2  From: welty@cabot.balltown.cma.COM (richard we...   11672\n",
       "10   au5  From: CPKJP@vm.cc.latech.edu (Kevin Parker)\\nS...    9693\n",
       "5   au14  From: eliot@engr.washington.edu (eliot)\\nSubje...    9351\n",
       "45  ch37  From: jhpb@sarto.budd-lake.nj.us (Joseph H. Bu...    9279\n",
       "80  gr23  From: lilley@v5.cgu.mcc.ac.uk (Chris Lilley)\\n...    9261"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "files = glob.glob(\"DocCol2/*\")\n",
    "ddocs = []\n",
    "\n",
    "for fname in files:\n",
    "    key = fname.split('\\\\')[-1]\n",
    "    with open(fname,'r') as f:\n",
    "        ddocs.append((key, f.read()))\n",
    "        \n",
    "df_docs = pd.DataFrame(ddocs, columns=['Name', 'Doc'])\n",
    "df_docs['LenDoc'] = df_docs['Doc'].apply(len)\n",
    "df_docs.sort_values('LenDoc', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 2)\n",
    "Crie um dicionário chamado `docsXwords` onde as chaves são os nomes dos arquivos e os valores são as listas de palavras do documento correspondente. As palavras em cada uma das listas devem ser constituídas apenas por letras do alfabeto, estarem lexicamente normalizadas e conterem mais que 1 caracter. Qual o documento cuja lista de palavras resultante possui o **maior** número de palavras repetidas:\n",
    "\n",
    "a) gr22<br>\n",
    "__b) ch30__<br>\n",
    "c) au2<br>\n",
    "d) au8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Doc</th>\n",
       "      <th>LenDoc</th>\n",
       "      <th>Words</th>\n",
       "      <th>WordsLen</th>\n",
       "      <th>WordsUniqueLen</th>\n",
       "      <th>RepeatedWordsLen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>ch30</td>\n",
       "      <td>From: db7n+@andrew.cmu.edu (D. Andrew Byler)\\n...</td>\n",
       "      <td>8849</td>\n",
       "      <td>[from, andrew, byler, subject, the, nicen, cre...</td>\n",
       "      <td>1525</td>\n",
       "      <td>390</td>\n",
       "      <td>1135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>au2</td>\n",
       "      <td>From: welty@cabot.balltown.cma.COM (richard we...</td>\n",
       "      <td>11672</td>\n",
       "      <td>[from, welti, richard, welti, subject, welcom,...</td>\n",
       "      <td>1678</td>\n",
       "      <td>556</td>\n",
       "      <td>1122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>ch24</td>\n",
       "      <td>From: pharvey@quack.kfu.com (Paul Harvey)\\nSub...</td>\n",
       "      <td>8409</td>\n",
       "      <td>[from, pharvey, paul, harvey, subject, re, sab...</td>\n",
       "      <td>1413</td>\n",
       "      <td>382</td>\n",
       "      <td>1031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>gr23</td>\n",
       "      <td>From: lilley@v5.cgu.mcc.ac.uk (Chris Lilley)\\n...</td>\n",
       "      <td>9261</td>\n",
       "      <td>[from, lilley, chri, lilley, subject, oh, make...</td>\n",
       "      <td>1409</td>\n",
       "      <td>398</td>\n",
       "      <td>1011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ch21</td>\n",
       "      <td>From: REXLEX@fnal.fnal.gov\\nSubject: Assurance...</td>\n",
       "      <td>8109</td>\n",
       "      <td>[from, rexlex, subject, assur, of, hell, dream...</td>\n",
       "      <td>1413</td>\n",
       "      <td>408</td>\n",
       "      <td>1005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Name                                                Doc  LenDoc  \\\n",
       "38  ch30  From: db7n+@andrew.cmu.edu (D. Andrew Byler)\\n...    8849   \n",
       "7    au2  From: welty@cabot.balltown.cma.COM (richard we...   11672   \n",
       "31  ch24  From: pharvey@quack.kfu.com (Paul Harvey)\\nSub...    8409   \n",
       "80  gr23  From: lilley@v5.cgu.mcc.ac.uk (Chris Lilley)\\n...    9261   \n",
       "28  ch21  From: REXLEX@fnal.fnal.gov\\nSubject: Assurance...    8109   \n",
       "\n",
       "                                                Words  WordsLen  \\\n",
       "38  [from, andrew, byler, subject, the, nicen, cre...      1525   \n",
       "7   [from, welti, richard, welti, subject, welcom,...      1678   \n",
       "31  [from, pharvey, paul, harvey, subject, re, sab...      1413   \n",
       "80  [from, lilley, chri, lilley, subject, oh, make...      1409   \n",
       "28  [from, rexlex, subject, assur, of, hell, dream...      1413   \n",
       "\n",
       "    WordsUniqueLen  RepeatedWordsLen  \n",
       "38             390              1135  \n",
       "7              556              1122  \n",
       "31             382              1031  \n",
       "80             398              1011  \n",
       "28             408              1005  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tratar_texto(t):\n",
    "    words = nltk.word_tokenize(t) \n",
    "    words = [w.lower() for w in words if w.isalpha()] \n",
    "    words = [PorterStemmer().stem(w) for w in words]\n",
    "    words = [w for w in words if len(w) > 1]\n",
    "    return words\n",
    "\n",
    "df_docs['Words'] = df_docs['Doc'].apply(tratar_texto)\n",
    "df_docs['WordsLen'] = df_docs['Words'].apply(len)\n",
    "df_docs['WordsUniqueLen'] = df_docs['Words'].apply(lambda x: len(set(x)))\n",
    "df_docs['RepeatedWordsLen'] = df_docs['WordsLen'] - df_docs['WordsUniqueLen']\n",
    "df_docs.sort_values('RepeatedWordsLen', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 3)\n",
    "Utilizando as listas de palavras do dicionário `docsXwords`, quais as três palavras que mais aparecem na coleção de documentos:\n",
    "\n",
    "a) the, is, of<br>\n",
    "b) that, is, of<br>\n",
    "__c) the, of, to__ <br>\n",
    "d) to, is, of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "the         5014\n",
       "of          2627\n",
       "to          2611\n",
       "and         2093\n",
       "is          1762\n",
       "            ... \n",
       "stingi         1\n",
       "spectat        1\n",
       "yugo           1\n",
       "belgium        1\n",
       "spacelab       1\n",
       "Length: 6865, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(df_docs['Words'].sum()).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 4)\n",
    "Qual o documento cuja lista de palavras possui o **menor** número de \"stop words\"? Quantas \"stop words\" aparecem neste documento:\n",
    "\n",
    "__a) gr5 com 47 \"stop words\"__<br>\n",
    "b) gr17 com 47 \"stop words\"<br>\n",
    "c) gr5 com 37 \"stop words\"<br>\n",
    "d) gr17 com 37 \"stop words\"\n",
    "\n",
    "**Dica**: Crie um dicionário onde a chave é o nome do documento e o valor o número de stop words no documento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Doc</th>\n",
       "      <th>LenDoc</th>\n",
       "      <th>Words</th>\n",
       "      <th>WordsLen</th>\n",
       "      <th>WordsUniqueLen</th>\n",
       "      <th>RepeatedWordsLen</th>\n",
       "      <th>TotalStopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>gr5</td>\n",
       "      <td>From: lusardi@cs.buffalo.edu (Christopher Lusa...</td>\n",
       "      <td>4887</td>\n",
       "      <td>[from, lusardi, christoph, lusardi, subject, p...</td>\n",
       "      <td>256</td>\n",
       "      <td>88</td>\n",
       "      <td>168</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>gr17</td>\n",
       "      <td>From: walter@uni-koblenz.de (Walter Hower)\\nSu...</td>\n",
       "      <td>4931</td>\n",
       "      <td>[from, walter, walter, hower, subject, re, des...</td>\n",
       "      <td>435</td>\n",
       "      <td>191</td>\n",
       "      <td>244</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>gr12</td>\n",
       "      <td>From: spl@dim.ucsd.edu (Steve Lamont)\\nSubject...</td>\n",
       "      <td>7477</td>\n",
       "      <td>[from, spl, steve, lamont, subject, re, find, ...</td>\n",
       "      <td>346</td>\n",
       "      <td>145</td>\n",
       "      <td>201</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>gr7</td>\n",
       "      <td>From: arp@cooper!osd (Andrew Pinkowitz)\\nSubje...</td>\n",
       "      <td>5337</td>\n",
       "      <td>[from, arp, cooper, osd, andrew, pinkowitz, su...</td>\n",
       "      <td>460</td>\n",
       "      <td>269</td>\n",
       "      <td>191</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>gr13</td>\n",
       "      <td>From: ianf@random.se (Ian Feldman, The Other I...</td>\n",
       "      <td>8606</td>\n",
       "      <td>[from, ianf, ian, feldman, the, other, interne...</td>\n",
       "      <td>612</td>\n",
       "      <td>357</td>\n",
       "      <td>255</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Name                                                Doc  LenDoc  \\\n",
       "86   gr5  From: lusardi@cs.buffalo.edu (Christopher Lusa...    4887   \n",
       "73  gr17  From: walter@uni-koblenz.de (Walter Hower)\\nSu...    4931   \n",
       "68  gr12  From: spl@dim.ucsd.edu (Steve Lamont)\\nSubject...    7477   \n",
       "88   gr7  From: arp@cooper!osd (Andrew Pinkowitz)\\nSubje...    5337   \n",
       "69  gr13  From: ianf@random.se (Ian Feldman, The Other I...    8606   \n",
       "\n",
       "                                                Words  WordsLen  \\\n",
       "86  [from, lusardi, christoph, lusardi, subject, p...       256   \n",
       "73  [from, walter, walter, hower, subject, re, des...       435   \n",
       "68  [from, spl, steve, lamont, subject, re, find, ...       346   \n",
       "88  [from, arp, cooper, osd, andrew, pinkowitz, su...       460   \n",
       "69  [from, ianf, ian, feldman, the, other, interne...       612   \n",
       "\n",
       "    WordsUniqueLen  RepeatedWordsLen  TotalStopwords  \n",
       "86              88               168              47  \n",
       "73             191               244              68  \n",
       "68             145               201              69  \n",
       "88             269               191              99  \n",
       "69             357               255             130  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def contar_stopwords(lista):\n",
    "    return len([l for l in lista if l in stop_words])\n",
    "    \n",
    "df_docs['TotalStopwords'] = df_docs['Words'].apply(contar_stopwords)\n",
    "df_docs.sort_values('TotalStopwords').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 5) \n",
    "Utilize o dicionário `docsXwords` para construir\n",
    "uma matriz Documentos $\\times$ Palavras para a coleção de documentos do diretório `DocCol2`. Utilizando a distância cosseno, qual é o documento mais parecido com o documento 'ch7':\n",
    "\n",
    "a) ch8<br>\n",
    "__b) ch16__<br>\n",
    "c) ch5<br>\n",
    "d) au8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_ch7 = df_docs.loc[df_docs['Name'] == 'ch7'].index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>from</th>\n",
       "      <th>ssave</th>\n",
       "      <th>the</th>\n",
       "      <th>devil</th>\n",
       "      <th>reincarn</th>\n",
       "      <th>subject</th>\n",
       "      <th>re</th>\n",
       "      <th>wa</th>\n",
       "      <th>safeti</th>\n",
       "      <th>how</th>\n",
       "      <th>...</th>\n",
       "      <th>bonu</th>\n",
       "      <th>pardon</th>\n",
       "      <th>hiss</th>\n",
       "      <th>fume</th>\n",
       "      <th>libel</th>\n",
       "      <th>frustat</th>\n",
       "      <th>consent</th>\n",
       "      <th>isabel</th>\n",
       "      <th>barreno</th>\n",
       "      <th>sabbat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 6865 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    from  ssave  the  devil  reincarn  subject  re  wa  safeti  how  ...  \\\n",
       "37     0      0    0      0         0        0   0   0       0    0  ...   \n",
       "41     0      0    0      0         0        0   0   0       0    0  ...   \n",
       "50     0      0    0      0         0        0   0   0       0    0  ...   \n",
       "38     0      0    0      0         0        0   0   0       0    0  ...   \n",
       "52     0      0    0      0         0        0   0   0       0    0  ...   \n",
       "\n",
       "    bonu  pardon  hiss  fume  libel  frustat  consent  isabel  barreno  sabbat  \n",
       "37     0       0     0     0      0        0        0       0        0       0  \n",
       "41     0       0     0     0      0        0        0       0        0       0  \n",
       "50     0       0     0     0      0        0        0       0        0       0  \n",
       "38     0       0     0     0      0        0        0       0        0       0  \n",
       "52     0       0     0     0      0        0        0       0        0       0  \n",
       "\n",
       "[5 rows x 6865 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer()\n",
    "df_cv = cv.fit_transform(df_docs['Words'].apply(lambda x: ' '.join(x)))\n",
    "df_cv = pd.DataFrame(df_cv.todense(), columns=cv.vocabulary_.keys())\n",
    "df_cv.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Doc</th>\n",
       "      <th>LenDoc</th>\n",
       "      <th>Words</th>\n",
       "      <th>WordsLen</th>\n",
       "      <th>WordsUniqueLen</th>\n",
       "      <th>RepeatedWordsLen</th>\n",
       "      <th>TotalStopwords</th>\n",
       "      <th>DistToCh7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>ch7</td>\n",
       "      <td>From: shellgate!llo@uu4.psi.com (Larry L. Over...</td>\n",
       "      <td>5941</td>\n",
       "      <td>[from, shellgat, llo, larri, overack, subject,...</td>\n",
       "      <td>872</td>\n",
       "      <td>333</td>\n",
       "      <td>539</td>\n",
       "      <td>401</td>\n",
       "      <td>3.552714e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ch16</td>\n",
       "      <td>From: jhpb@sarto.budd-lake.nj.us (Joseph H. Bu...</td>\n",
       "      <td>7162</td>\n",
       "      <td>[from, jhpb, joseph, buehler, subject, re, ssp...</td>\n",
       "      <td>1131</td>\n",
       "      <td>402</td>\n",
       "      <td>729</td>\n",
       "      <td>500</td>\n",
       "      <td>9.780925e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ch17</td>\n",
       "      <td>From: wagner@grace.math.uh.edu (David Wagner)\\...</td>\n",
       "      <td>8161</td>\n",
       "      <td>[from, wagner, david, wagner, subject, re, cer...</td>\n",
       "      <td>1324</td>\n",
       "      <td>425</td>\n",
       "      <td>899</td>\n",
       "      <td>606</td>\n",
       "      <td>9.789468e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ch10</td>\n",
       "      <td>From: johnsd2@rpi.edu (Dan Johnson)\\nSubject: ...</td>\n",
       "      <td>6239</td>\n",
       "      <td>[from, dan, johnson, subject, re, the, arrog, ...</td>\n",
       "      <td>1019</td>\n",
       "      <td>345</td>\n",
       "      <td>674</td>\n",
       "      <td>478</td>\n",
       "      <td>9.824535e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>au9</td>\n",
       "      <td>From: storrs@eos.ncsu.edu (JERRY STORRS)\\nSubj...</td>\n",
       "      <td>4926</td>\n",
       "      <td>[from, storr, jerri, storr, subject, re, warn,...</td>\n",
       "      <td>636</td>\n",
       "      <td>287</td>\n",
       "      <td>349</td>\n",
       "      <td>276</td>\n",
       "      <td>9.867951e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ch19</td>\n",
       "      <td>From: cmgrawbu@eos.ncsu.edu (CHRISTOPHER M GRA...</td>\n",
       "      <td>6643</td>\n",
       "      <td>[from, cmgrawbu, christoph, grawburg, subject,...</td>\n",
       "      <td>1132</td>\n",
       "      <td>399</td>\n",
       "      <td>733</td>\n",
       "      <td>549</td>\n",
       "      <td>1.025342e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>au12</td>\n",
       "      <td>From: heiser@acs2.bu.edu (Bill Heiser)\\nSubjec...</td>\n",
       "      <td>7736</td>\n",
       "      <td>[from, heiser, bill, heiser, subject, re, ford...</td>\n",
       "      <td>1184</td>\n",
       "      <td>428</td>\n",
       "      <td>756</td>\n",
       "      <td>513</td>\n",
       "      <td>1.026010e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>au5</td>\n",
       "      <td>From: CPKJP@vm.cc.latech.edu (Kevin Parker)\\nS...</td>\n",
       "      <td>9693</td>\n",
       "      <td>[from, cpkjp, kevin, parker, subject, insur, r...</td>\n",
       "      <td>1192</td>\n",
       "      <td>465</td>\n",
       "      <td>727</td>\n",
       "      <td>466</td>\n",
       "      <td>1.026856e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>gr4</td>\n",
       "      <td>From: mogal@deadhead.asd.sgi.com (Joshua Mogal...</td>\n",
       "      <td>6240</td>\n",
       "      <td>[from, mogal, joshua, mogal, subject, re, sgi,...</td>\n",
       "      <td>888</td>\n",
       "      <td>379</td>\n",
       "      <td>509</td>\n",
       "      <td>384</td>\n",
       "      <td>1.027233e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>au14</td>\n",
       "      <td>From: eliot@engr.washington.edu (eliot)\\nSubje...</td>\n",
       "      <td>9351</td>\n",
       "      <td>[from, eliot, eliot, subject, review, audi, qu...</td>\n",
       "      <td>1491</td>\n",
       "      <td>580</td>\n",
       "      <td>911</td>\n",
       "      <td>647</td>\n",
       "      <td>1.031898e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>91 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Name                                                Doc  LenDoc  \\\n",
       "62   ch7  From: shellgate!llo@uu4.psi.com (Larry L. Over...    5941   \n",
       "22  ch16  From: jhpb@sarto.budd-lake.nj.us (Joseph H. Bu...    7162   \n",
       "23  ch17  From: wagner@grace.math.uh.edu (David Wagner)\\...    8161   \n",
       "16  ch10  From: johnsd2@rpi.edu (Dan Johnson)\\nSubject: ...    6239   \n",
       "14   au9  From: storrs@eos.ncsu.edu (JERRY STORRS)\\nSubj...    4926   \n",
       "..   ...                                                ...     ...   \n",
       "25  ch19  From: cmgrawbu@eos.ncsu.edu (CHRISTOPHER M GRA...    6643   \n",
       "3   au12  From: heiser@acs2.bu.edu (Bill Heiser)\\nSubjec...    7736   \n",
       "10   au5  From: CPKJP@vm.cc.latech.edu (Kevin Parker)\\nS...    9693   \n",
       "85   gr4  From: mogal@deadhead.asd.sgi.com (Joshua Mogal...    6240   \n",
       "5   au14  From: eliot@engr.washington.edu (eliot)\\nSubje...    9351   \n",
       "\n",
       "                                                Words  WordsLen  \\\n",
       "62  [from, shellgat, llo, larri, overack, subject,...       872   \n",
       "22  [from, jhpb, joseph, buehler, subject, re, ssp...      1131   \n",
       "23  [from, wagner, david, wagner, subject, re, cer...      1324   \n",
       "16  [from, dan, johnson, subject, re, the, arrog, ...      1019   \n",
       "14  [from, storr, jerri, storr, subject, re, warn,...       636   \n",
       "..                                                ...       ...   \n",
       "25  [from, cmgrawbu, christoph, grawburg, subject,...      1132   \n",
       "3   [from, heiser, bill, heiser, subject, re, ford...      1184   \n",
       "10  [from, cpkjp, kevin, parker, subject, insur, r...      1192   \n",
       "85  [from, mogal, joshua, mogal, subject, re, sgi,...       888   \n",
       "5   [from, eliot, eliot, subject, review, audi, qu...      1491   \n",
       "\n",
       "    WordsUniqueLen  RepeatedWordsLen  TotalStopwords     DistToCh7  \n",
       "62             333               539             401  3.552714e-15  \n",
       "22             402               729             500  9.780925e-01  \n",
       "23             425               899             606  9.789468e-01  \n",
       "16             345               674             478  9.824535e-01  \n",
       "14             287               349             276  9.867951e-01  \n",
       "..             ...               ...             ...           ...  \n",
       "25             399               733             549  1.025342e+00  \n",
       "3              428               756             513  1.026010e+00  \n",
       "10             465               727             466  1.026856e+00  \n",
       "85             379               509             384  1.027233e+00  \n",
       "5              580               911             647  1.031898e+00  \n",
       "\n",
       "[91 rows x 9 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = StandardScaler().fit_transform(df_cv)\n",
    "distances = cosine_distances(X, X[idx_ch7, :])\n",
    "df_docs['DistToCh7'] = distances[:, 0]\n",
    "df_docs.sort_values('DistToCh7')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
