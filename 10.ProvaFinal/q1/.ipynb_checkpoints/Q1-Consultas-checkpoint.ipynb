{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Orientações - Prof. Louzada\n",
    "\n",
    "1. Uma questão terá como foco as disciplinas “Introdução a Ciências de Dados” e “Aprendizado de Máquina”. Essa questão é dissertativa e dividida em itens. O objetivo consiste em avaliar se o significado dos termos overfitting e underfitting foram compreendidos. Não será necessário descrever esses termos em detalhes. Espera-se uma descriçãointuitiva sobre o que esses conceitos querem dizer e quando eles ocorrem. Também se espera que sejam apresentadosalguns exemplos. No último item da questão, deve ser descrito ao menos um método para tratar o problema de desbalanceamento nos dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verificar Aula 02 - INTRODUCAO CIENCIA DE DADOS\n",
    "\n",
    "<img src=\"img/slide-overfit.JPG\" alt=\"title\"> \n",
    "<img src=\"img/slide-overfit-2.JPG\" alt=\"title\"> \n",
    "\n",
    "#### Overfitting:\n",
    "\n",
    "É um termo usado em estatística para descrever quando um modelo estatístico se ajusta muito bem ao conjunto de dados anteriormente observado, mas se mostra ineficaz para prever novos resultados. \n",
    "É comum que a amostra apresente desvios causados por erros de medição ou fatores aleatórios. Ocorre o overfitting (sobre-ajuste) quando o modelo se ajusta a estes. Um modelo sobre-ajustado apresenta alta precisão quando testado com seu conjunto de dados, porém tal modelo não é uma boa representação da realidade e por isso deve ser evitado.\n",
    "Uma ferramenta para contornar o problema do sobre-ajuste é a regularização, que adiciona à função custo o valor dos parâmetros. Tal adição resulta na eliminação de parâmetros de pouca importância e, portanto, em um modelo mais convexo, do qual que se espera que seja mais representativo da realidade.\n",
    "\n",
    "<img src=\"img/Overfitting.gif\" alt=\"title\" width=\"300\" height=\"200\">\n",
    "   \n",
    "   Sistema de predição em que a linha verde representa um modelo sobreajustado e a linha preta um modelo regularizado.\n",
    "   \n",
    "\n",
    "#### Regularização:\n",
    "Nos modelos de regressão pode ocorrer o problema de overfitting. \n",
    "\n",
    "<img src=\"img/overfitting.gif\" width=\"500\" height=\"300\">\n",
    "\n",
    "A regularização é uma maneira de evitar isso. E uma das mais conhecidas é o método de ridge regression ou Tikhonov regularization e outro método bastante conhecido é o LASSO."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ridge Regression (Tikhonov regularization):\n",
    "A regressão de Ridge é uma técnica para analisar vários dados de regressão que sofrem de multicolinearidade. Quando ocorre multicolinearidade, as estimativas de mínimos quadrados são imparciais, mas suas variações são grandes e podem estar longe deo verdadeiro valor. Ao adicionar um grau de viés às estimativas de regressão, a regressão de crista reduz os erros padrão.\n",
    "\n",
    "<img src=\"img/ridge-regression.gif\" width=\"600\" height=\"500\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bibliotecas\n",
    "from sklearn.linear_model import Ridge, RidgeCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#criando modelo ridge regression\n",
    "ridge2 = Ridge(alpha = 0, normalize = True)\n",
    "#ajustando\n",
    "ridge2.fit(x_train, y_train)\n",
    "#predizendo\n",
    "y_pred = ridge2.predict(x_test)\n",
    "#avaliando com RSME\n",
    "RSME = mean_squared_error(y_test, y_pred)\n",
    "print(\"RSME:\", RSME)          # Calculate the test MSE\n",
    "\n",
    "#DICA:\n",
    "#lendo dados:\n",
    "data = pd.read_csv('data/Advertising.csv', header=(0))\n",
    "#converter o dataframe para numpy para melhor manipular os dados\n",
    "data = data.to_numpy()\n",
    "nrow,ncol = data.shape\n",
    "X = data[:,0:ncol-1]\n",
    "y = data[:,-1]\n",
    "\n",
    "#OBS: Maiores detalhes Aula 05 - ICD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LASSO (Least Absolute Shrinkage and Selection Operator):\n",
    "Em estatística e aprendizado de máquina , o lasso ( operador de contração e seleção menos absoluto ; também Lasso ou LASSO) é um método de análise de regressão que executa a seleção de variáveis e a regularização , a fim de aprimorar a precisão das previsões e a interpretabilidade do modelo estatístico que produz. \n",
    "\n",
    "Enquanto ridge regression mantém os valores dos parâmetros pequenos, LASSO tende a selecionar alguns valores para serem diferentes de zero, enquanto que outros são exatamente iguais a zero. Assim, LASSO pode ser usado para selecionar atributos.\n",
    "\n",
    "<img src=\"img/ridge-vs-lasso.gif\" width=\"500\" height=\"300\"> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bibliotecas\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "#criando modelo LASSO\n",
    "lasso = Lasso(alpha=0.1,normalize=True, max_iter=1e5)\n",
    "#ajustando\n",
    "lasso.fit(x_train, y_train)\n",
    "#predizendo\n",
    "y_pred = lasso.predict(x_test)\n",
    "#avaliando com RSME\n",
    "RSME = mean_squared_error(y_test, y_pred)\n",
    "print('RSME:', RSME)\n",
    "#avaliando com R2 (MSE)\n",
    "R2 = r2_score(y_test, y_pred)\n",
    "print(\"R2:\", R2)\n",
    "\n",
    "#DICA:\n",
    "\n",
    "#PLOT:\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "l = plt.plot(y_pred, y_test, 'bo')\n",
    "plt.setp(l, markersize=10)\n",
    "plt.setp(l, markerfacecolor='C0')\n",
    "plt.ylabel(\"Y\", fontsize=15)\n",
    "plt.xlabel(\"Prediction\", fontsize=15)\n",
    "xl = np.arange(min(y_test), 1.2*max(y_test),(max(y_test)-min(y_test))/10)\n",
    "yl = xl\n",
    "plt.plot(xl, yl, 'r--')\n",
    "plt.show(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#material para consultar:\n",
    "-> Aula 02 - ICD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verificar Aula 02 - Técnicas Avançadas de Ciencia de Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SMOTE(Synthetic Minority Oversampling Technique)\n",
    "\n",
    " Existem vários métodos disponíveis para superamostrar um conjunto de dados usado em um problema de classificação típico desbalanceado. A técnica mais comum é conhecida como SMOTE: Synthetic Minority Over-sampling Technique. \n",
    " Para ilustrar como essa técnica funciona, considere alguns dados de treinamento que possuem s amostras e f recursos no espaço de recursos dos dados. Observe que esses recursos, para simplificar, são contínuos. Como exemplo, considere um conjunto de dados de pássaros para classificação. O espaço de recursos para a classe minoritária para a qual queremos sobreamostrar pode ser o comprimento do bico, a envergadura e o peso (todos contínuos). Para então sobreamostrar, pegue uma amostra do conjunto de dados e considere seus k vizinhos mais próximos (no espaço de recursos). Para criar um ponto de dados sintético, pegue o vetor entre um desses k vizinhos e o ponto de dados atual. Multiplique esse vetor por um número aleatório x que fica entre 0 e 1. Adicione isso ao ponto de dados atual para criar o novo ponto de dados sintético."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bibliotecas para uso do SMOTE (técnica para tratar o balanceamento de dados):\n",
    "from imblearn import over_sampling \n",
    "from imblearn import under_sampling\n",
    "\n",
    "#aplicando técnicas de SMOTE para verificar uma estratégia melhor de balanceamento para validar os modelos\n",
    "\n",
    "#Over Sampling\n",
    "oversamp = over_sampling.SMOTE() # sampling_strategy pode ser usado para casos binários\n",
    "Xo, Yo = oversamp.fit_resample(x_train_map, y_train_map)\n",
    "\n",
    "plt.figure(figsize=(16,5))\n",
    "h = plt.hist(Yo)\n",
    "\n",
    "#Under Sampling\n",
    "undersamp = under_sampling.RandomUnderSampler()\n",
    "Xu, Yu = undersamp.fit_resample(x_train_map, y_train_map)\n",
    "\n",
    "plt.figure(figsize=(16,5))\n",
    "h = plt.hist(Yu)\n",
    "\n",
    "#Over Under Sampling (estratégia mista - combinado)\n",
    "overunder = combine.SMOTEENN(sampling_strategy='all')\n",
    "Xc, Yc = overunder.fit_resample(x_train_map, y_train_map)\n",
    "\n",
    "plt.figure(figsize=(16,5))\n",
    "h = plt.hist(Yc)\n",
    "\n",
    "#Dica:\n",
    "#avaliando qual a melhor estratégia de SMOTE\n",
    "clf_ov = SVC(gamma='auto')\n",
    "clf_ov.fit(Xo,Yo)\n",
    "ZYov_ = clf_ov.predict(x_test_map)\n",
    "\n",
    "clf_un = SVC(gamma='auto')\n",
    "clf_un.fit(Xu,Yu)\n",
    "ZYun_ = clf_un.predict(x_test_map)\n",
    "\n",
    "clf_co = SVC(gamma='auto')\n",
    "clf_co.fit(Xc,Yc)\n",
    "ZYco_ = clf_co.predict(x_test_map)\n",
    "#Plotar matriz confusão para verificar de cada modelo após aplicação do SMOTE:\n",
    "disp = plot_confusion_matrix(clf_ov, x_test_map, y_test_map,\n",
    "                                 cmap=plt.cm.Blues,\n",
    "                                 normalize='true')\n",
    "\n",
    "disp = plot_confusion_matrix(clf_un, x_test_map, y_test_map,\n",
    "                                 cmap=plt.cm.Blues,\n",
    "                                 normalize='true')\n",
    "\n",
    "disp = plot_confusion_matrix(clf_co, x_test_map, y_test_map,\n",
    "                                 cmap=plt.cm.Blues,\n",
    "                                 normalize='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#material para consultar:\n",
    "-> Aula 02 - TACTD\n",
    "-> TACTD 02-4 - Tratamento dados desbalanceados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verificar Aula 02 - Aprendizado de Máquina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#material para consultar:\n",
    "-> Prova de AM\n",
    "-> Aula 02 - AM\n",
    "-> under_oversampling"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
