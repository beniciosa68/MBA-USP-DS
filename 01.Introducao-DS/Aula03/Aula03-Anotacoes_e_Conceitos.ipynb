{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anotações e Conceitos - Aula03 - ICD\n",
    "\n",
    "\n",
    "## Fixação de Conceitos:\n",
    "\n",
    "\n",
    "#### Transformação e Tratamento de Dados\n",
    "        \n",
    " #### Principais Problemas:\n",
    " \n",
    "   ##### Ruídos:\n",
    "         Dados ruidosos são dados corrompidos, distorcidos ou com baixa relação sinal / ruído. Procedimentos inadequados para subtrair o ruído nos dados podem levar a uma falsa sensação de precisão ou a conclusões falsas. \n",
    "         \n",
    "                                       Data = true signal + noise\n",
    "\n",
    "   ##### Amostragem:\n",
    "        Se diminuirmos o tamanho das amostras, ocorre que os dados originais são muito alterados, atrapalhando a análise dos dados.\n",
    "    \n",
    "   ##### Dados incompletos:\n",
    "        Dados que não foram coletados. Para este caso, temos técnicas específicas de como tratar este problema.\n",
    "    \n",
    "   ##### Maldição da Dimensionalidade:\n",
    "        Se temos dados que estão representados em uma dimensão, muitas vezes ele pode preencher bem alguma informação. Porém, quando dispomos ele em duas dimensões ou três, ocorre uma disparsidade muito grande dos dados e isso pode dificultar o entendimento e interpretação dos mesmos. Isso ocorre pois o número de regiões onde o dado terá para ficar disponível aumenta exponencialmente. 1 dimensão = 4 regiões, 2 dimensões = 16 regiões, 4 dimensões = 64 regiões.\n",
    "\n",
    "   ##### Fenômeno de Hughes\n",
    "        Conforme vamos aumentando o número de atributos vamos melhorando a classificação da amostra, porém, dado um certo momento ocorre um efeito decrescente, ou seja, quanto mais atributos pior fica a acurácia, prejudicando a classificação dos dados.\n",
    "        \n",
    "#### PrincipaisTécnicas:\n",
    "   \n",
    "   ##### Eliminação manual de atributos\n",
    "       Observando os dados e retirando na mão.\n",
    "       Observar quais atributos não são relevantes para o problema que está sendo tratado.\n",
    "       Outra técnica são atributos que tem os mesmos dados para todas as observações, em muito destes casos, a informação acaba se tornando irrelevante.\n",
    "       \n",
    "   ##### Integração de dados\n",
    "       Combinar um atributo com outro, para gerar um terceiro dado.\n",
    "       \n",
    "   ##### Amostragem de dados\n",
    "       No caso de termos muitos dados e pouco poder computacional, podemos processar uma parte simplesmente pegando uma amostra do todo, porém, quanto mais dados, maior tende ser a acurácia do modelo. O ideal é fazer um balanço entre a eficiência computacional e a acurácia dos dados.\n",
    "       Um dos problemas da amostragem é o balanceamento, ou seja, quando pegamos um dado, que só representa um tipo de informação, induzindo a análise para conclusões que podem não ser verdadeiras ou altamente influenciáveis.\n",
    "       \n",
    "       Amostragem aleatório simples:\n",
    "           Com reposição: Vou retirando amostras aleatórias sem me preocupar se os dados que saíram estão repetidos ou não.\n",
    "           Sem reposição: Vou retirando amostras aleatórias e me preocupando com os dados que já saíram, não repetindo.\n",
    "           \n",
    "       Amostragem estratificada:\n",
    "           Manter o mesmo número de objetos para cada classe de dados ou manter um número de dados proporcionais. Ex, temos uma amostra com 100 homens e 20 mulheres, então vamos tentar deixar ambos com uma quantidade igual de elementos, ou aumentando o número de mulheres ou diminuindo o número de homens. Algumas técnicas pra isso são acréscimo ou eliminação.\n",
    "           \n",
    "       Amostragem progressiva:\n",
    "           Vai processando uma amostra pequena e vai incluindo dados até a amostra ficar com uma acurácia preditiva pára de melhorar, então não precisamos mais continuar processando dados, uma vez que não teremos mais ganho com isso.\n",
    "       \n",
    "   \n",
    "   ##### Limpeza de dados\n",
    "       Ruídos: erros ou valores diferentes do esperado. Ex. Idade com valores negativos.\n",
    "       Inconsistências: valores que não combinam ou contradizem a lógica. Ex. pessoa de 1,95m de altura pesando 10Kg.\n",
    "       Redundâncias: objetos/atributos com mesmos valores. Ex. 2 entradas iguais, influenciando no algoritimo.\n",
    "       Dados incompletos: ausência de atributos.\n",
    "           Soluções:  Eliminar objetos com valores ausentes.\n",
    "                      Preencher manualmente valores faltantes.\n",
    "                      Utilizar algum método/heurística/algoritmo para prever/estimar valores faltantes automaticamente.\n",
    "                      \n",
    "   \n",
    "   ##### Transformação de valores\n",
    "       Quando os algoritimos tem dificuldades de usar os dados no seu formato original, então nesse caso, você realiza uma transformação, passando ele para um formato que seja inteligivel tanto para a análise quanto para o algoritimo de processamento. Por ex, one-hot encoding scheme:\n",
    "   \n",
    "   ###### One-Hot Enconding    \n",
    "   <img src=\"img/one-hot-encoding.jpg\" width=\"500\" height=\"400\">\n",
    "   \n",
    "\n",
    "    Normalização (MinMax Scaling):\n",
    "        Os dados serão ajustados de forma que o valor máximo será 1 e o valor mínimo será 0.\n",
    "        Desvantagem: Sensível a outliers.\n",
    " \n",
    " <img src=\"img/min-max-scaling.png\">        \n",
    " <img src=\"img/graf-min-max-scaling.png\" width=\"300\" height=\"200\">   \n",
    "        \n",
    "    Padronizaçao (Z-Score Normalization:)\n",
    "        Os dados serão ajustados de forma que a média será 0 e o desvio padrão será 1.\n",
    "        \n",
    "  <img src=\"img/z-normalization.gif\" width=\"150\" height=\"100\">    \n",
    "  <img src=\"img/graf-z-normalization.png\" width=\"500\" height=\"400\">\n",
    "  \n",
    "    Softmax:\n",
    "        Em matemática , a função softmax, também conhecida como softargmax ou função exponencial normalizada é uma função que recebe como entrada um vetor de K números reais e o normaliza em uma distribuição de probabilidade composta por K proporcionalmente. para os exponenciais dos números de entrada. Ou seja, antes da aplicação do softmax, alguns componentes do vetor podem ser negativos ou maiores que um; e pode não somar 1; mas depois de aplicar o softmax, cada componente estará no intervalo (0,1) , e os componentes adicionarão até 1, para que possam ser interpretados como probabilidades. Além disso, os componentes de entrada maiores corresponderão a probabilidades maiores. O Softmax é freqüentemente usado em redes neurais , para mapear a saída não normalizada de uma rede para uma distribuição de probabilidade sobre as classes de saída previstas.\n",
    "        \n",
    " <img src=\"img/softmax.png\" width=\"300\" height=\"200\">        \n",
    " \n",
    " <img src=\"img/graf-softmax.png\" width=\"500\" height=\"400\">  \n",
    " \n",
    " \n",
    "  ##### Análise dos Componentes Principais (PCA):\n",
    "      \n",
    "         PCA (Principal Component Analysis) consiste na simplificação dos dados sem perder informações relevantes, ajudando no processamento dos dados, pois reduz tempo computacional e complexidade nos algoritimos. O PCA ajuda a eliminar dados reduntantes, preservando informações importantes e ajudando no processo de análise dos dados.\n",
    "      \n",
    "      Decomposição de Valores Singulares (SVD decomposition):\n",
    "          Passos:\n",
    "              1) Centralizar os dados (cada valor menos a média): \n",
    "  <img src=\"img/pca-centralizar.gif\" width=\"100\" height=\"50\"> \n",
    "  \n",
    "              2) Calcular a matriz de covariância:\n",
    "                  Na prática o número de atributos, vai definir a dimensão da matriz. Ex. Se tenho 4 atributos, vou ter uma matriz 4x4.\n",
    "  <img src=\"img/pca-cov.gif\" width=\"250\" height=\"150\">   \n",
    "               \n",
    "              3) Calcular os autovetores e autovalores da matriz de covariância:\n",
    "  <img src=\"img/pca-autovetor-valor.gif\" width=\"500\" height=\"300\">  \n",
    "              \n",
    "              4) Ordenar autovetores de acordo com os autovalores:\n",
    "                  Na prática vou pegar o maior autovalor e para ele teremos um autovetor equivalente, o segundo maior autovalor, terá seu autovetor correspondente e assim por diante.\n",
    "                  \n",
    "              5) Multiplicar os dados originais pelos principais autovetores:\n",
    "                  Na prática vou pegar esses autovetores encontrados no passo anterior, que correspondem aos maiores autovalores e multiplicar pelos meus dados originais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
