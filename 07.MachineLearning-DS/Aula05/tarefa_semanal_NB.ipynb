{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparando o Naive Bayes com outros algoritmos em dados de texto\n",
    "\n",
    "\n",
    "O algorimo Naive Bayes (NB), como visto em aula, é um tipo de classificador baseado no teorema de Bayes que faz uma suposição ingênua de que os atributos preditivos são independentes uns dos outros.\n",
    "\n",
    "Em sua formulação mais básica, i.e., para dados discretos, a implementação do NB é muito simples. Todavia, dependendo do tipo dos dados de entrada precisamos de algumas suposições adicionais. Tais detalhes serão discutidos na monitoria.\n",
    "\n",
    "O `sklearn` implementa várias variantes do NB, que são focadas em tipos diferentes de dados e/ou fazem suposições diferentes em relação aos dados de entrada. A [documentação do sklearn](https://scikit-learn.org/stable/modules/naive_bayes.html) é muito completa e nos ajuda durante o processo de escolha da melhor variante para o nosso problema. São poucos os hiperparâmetros que devem ser ajustados no NB (quando existentes), o que facita a sua rápida aplicação em um novo problema ou sua utilização para prototipagem.\n",
    "\n",
    "\n",
    "Podemos importar as variantes do NB a partir do módulo `sklearn.naive_bayes`, por exemplo:\n",
    "\n",
    "\n",
    "```python\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Informações introdutórias e contexto \n",
    "\n",
    "Nessa semana aplicaremos o NB em tarefas de processamento de texto. A ideia é entender como o viés preditivo do NB se sai em comparação com outros algoritmos de aprendizado que vimos anteriormente. Para tal, precisamos de alguns recursos e ferramentas que nos permitam:\n",
    "\n",
    "1. Carregar a base dados proposta (cujas entradas são textos)\n",
    "2. Extrair atributos estruturados dessa base e pré-processa-la em um formato adequado para os classificadores\n",
    "\n",
    "Como base de dados utilizaremos o [*20 newsgroups*](http://people.csail.mit.edu/jrennie/20Newsgroups/), que é um conjunto muito conhecido na área de pesquisa de mineração de dados de textos.\n",
    "\n",
    "Devido ao tamanho desse dataset, limitaremos nossa análise a 4 sub-categorias de texto. Essas categorias serão as classes do problema preditivo que trateramos. O conjunto de dados mencionado está disponível diretamente no `sklearn`.\n",
    "\n",
    "\n",
    "O trecho a seguir ilustra como carregar o conjunto de dados e também apresenta as categorias que consideraremos e como separá-las:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizaremos 4 das 20 categorias de texto disponiveis no dataset\n",
    "categories = ['alt.atheism', 'soc.religion.christian', 'comp.graphics', 'sci.med']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregaremos o subconjunto de treino do dataset e selecionaremos apenas as 4 categorias apresentadas anteriormente. Essas categorias serão as classes do sub-problema que levaremos em conta, ou seja, tentaremos predizer o assunto que cada texto aborda utilizando aprendizado de máquina."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "twenty_train = fetch_20newsgroups(subset='train', categories=categories, shuffle=True,\n",
    "                                  random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Notem que usamos `shuffle=True`, então nossos dados já vêm embaralhados)\n",
    "\n",
    "Vamos ver que campos temos no dataset e a quantidade de amostras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Campos disponíveis: ['data', 'filenames', 'target_names', 'target', 'DESCR']\n",
      "Quantidade de amostras: 2257\n"
     ]
    }
   ],
   "source": [
    "print('Campos disponíveis:', list(twenty_train))\n",
    "print('Quantidade de amostras:', len(twenty_train.data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veremos também quão desbalanceado é o problema em nossas mãos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3]), array([480, 584, 594, 599]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Formato: (array_com_as_classes, array_com_qnt_exemplos_em_cada_classe)\n",
    "np.unique(twenty_train.target, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os dados estão relativamente balanceados! Muito provavelmente não precisaremos nos preocupar com desbalanceamento.\n",
    "\n",
    "Por outro lado nossos dados são textuais:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'From: sd345@city.ac.uk (Michael Collier)\\nSubject: Converting images to HP LaserJet III?\\nNntp-Posting-Host: hampton\\nOrganization: The City University\\nLines: 14\\n\\nDoes anyone know of a good way (standard PC application/PD utility) to\\nconvert tif/img/tga files into LaserJet III format.  We would also like to\\ndo the same, converting to HPGL (HP plotter) files.\\n\\nPlease email any response.\\n\\nIs this the correct group?\\n\\nThanks in advance.  Michael.\\n-- \\nMichael Collier (Programmer)                 The Computer Unit,\\nEmail: M.P.Collier@uk.ac.city                The City University,\\nTel: 071 477-8000 x3769                      London,\\nFax: 071 477-8565                            EC1V 0HB.\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_train['data'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E agora?\n",
    "\n",
    "Nosso foco aqui não é o processamento dos dados, e sim comparar algorítmos preditivos.\n",
    "\n",
    "A extração de features pode ser feita de várias formas. O `sklearn` nos oferece ferramentos muito práticas para tal. Uma sugestão é utilizar o [`CountVectorizer`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer) para a extração das features e o [`TfidfTransformer`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html#sklearn.feature_extraction.text.TfidfTransformer) como passo de pré-processamento.\n",
    "\n",
    "\n",
    "Certo. Temos meios de organizar de forma tabular nossos dados e, assim, utilizá-los para treinar alguns modelos de aprendizado de máquina. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dados os pontos mencionados anteriormente, a tarefa é:\n",
    "\n",
    "# **Tarefa:**\n",
    "\n",
    "## Comparar o Naive Bayes contra o k-NN e Árvore de decisão utilizando as 4 categorias de tipo texto carregadas anteriormente da base de dados 20 newsgroups.\n",
    "\n",
    "Passos:\n",
    "\n",
    "1. [x] Carregar o conjunto de dados\n",
    "2. [ ] Extrair atributos e aplicar pré-processamento (`CountVectorizer` e `TfidfTransformer`)\n",
    "3. [ ] Separar os dados entre treinamento e validação\n",
    "4. [ ] Escolher uma métrica de avaliação adequada\n",
    "5. [ ] Comparar o desempenho dos algoritmos (Naive Bayes, k-NN e Árvore de Decisão)\n",
    "\n",
    "\n",
    "*Observações:*\n",
    "\n",
    "- **Não existe uma única forma \"certa\" de realizar a tarefa**, mas a motivação de cada escolha deve ser justificável.\n",
    "- O ajuste de hiperparâmetros (quando aplicável) não precisa ser necessariamente automático, por simplicidade vocês podem ajustá-los manualmente\n",
    "- A ideia aqui é discutir como os diferentes vieses preditivos se comportam no problema proposto e aplicar os conhecimentos adquiridos nas aulas passadas\n",
    "\n",
    "Vale ressaltar que algumas decisões deverão ser tomadas para realizar essa tarefa:\n",
    "\n",
    "a) Que variante do NB utilizaremos?\n",
    "\n",
    "b) Como iremos configurar nossos preditores? (ajuste de hiperparâmetros)\n",
    "\n",
    "c) Como avaliar a performance dos diferentes algoritmos de forma justa?\n",
    "   - Que métrica de avaliação utilizar\n",
    "   - Como particionar os dados? (e.g., cross-validation)\n",
    "\n",
    "Lembrem-se de utilizar os mesmos passos de processamento no treino e teste (`fit` no treino e `transform` no teste). Dica para simplicidade e elegância: pipelines (no fórum temos um exemplo de utilização)!\n",
    "\n",
    "\n",
    "\n",
    "## Desafios opcionais:\n",
    "\n",
    "### Desafio extra 1:\n",
    "\n",
    "Considerar a [Regressão Logística](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) na comparação.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desafio extra 2:\n",
    "\n",
    "O conjunto que utilizamos conta com um sub-conjunto de dados de teste. Tais dados são carregados via:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "twenty_test = fetch_20newsgroups(subset='test', categories=categories, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Que tal aplicar os modelos selecionados na tarefa da semana nesses dados?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apêndice A\n",
    "\n",
    "## Utilização básica do Naive Bayes e Regressão Logística na base de dados iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n",
      "(150,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# recuperando conjunto de dados\n",
    "data = load_iris()\n",
    "X, y = data['data'], data['target']\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "#dividindo os dados em treino e teste.\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc do NB é:  0.96\n"
     ]
    }
   ],
   "source": [
    "clf = GaussianNB()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "acc_nb = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Acc do NB é: \", acc_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc do LR é:  1.0\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=0, max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "acc_lr = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Acc do LR é: \", acc_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_lr > acc_nb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
