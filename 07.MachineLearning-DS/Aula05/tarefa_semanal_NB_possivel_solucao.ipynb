{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparando o Naive Bayes com outros algoritmos em dados de texto\n",
    "\n",
    "\n",
    "O algorimo Naive Bayes (NB), como visto em aula, é um tipo de classificador baseado no teorema de Bayes que faz uma suposição ingênua de que os atributos preditivos são independentes uns dos outros.\n",
    "\n",
    "Em sua formulação mais básica, i.e., para dados discretos, a implementação do NB é muito simples. Todavia, dependendo do tipo dos dados de entrada precisamos de algumas suposições adicionais. Tais detalhes serão discutidos na monitoria.\n",
    "\n",
    "O `sklearn` implementa várias variantes do NB, que são focadas em tipos diferentes de dados e/ou fazem suposições diferentes em relação aos dados de entrada. A [documentação do sklearn](https://scikit-learn.org/stable/modules/naive_bayes.html) é muito completa e nos ajuda durante o processo de escolha da melhor variante para o nosso problema. São poucos os hiperparâmetros que devem ser ajustados no NB (quando existentes), o que facita a sua rápida aplicação em um novo problema ou sua utilização para prototipagem.\n",
    "\n",
    "\n",
    "Podemos importar as variantes do NB a partir do módulo `sklearn.naive_bayes`, por exemplo:\n",
    "\n",
    "\n",
    "```python\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Informações introdutórias e contexto \n",
    "\n",
    "Nessa semana aplicaremos o NB em tarefas de processamento de texto. A ideia é entender como o viés preditivo do NB se sai em comparação com outros algoritmos de aprendizado que vimos anteriormente. Para tal, precisamos de alguns recursos e ferramentas que nos permitam:\n",
    "\n",
    "1. Carregar a base dados proposta (cujas entradas são textos)\n",
    "2. Extrair atributos estruturados dessa base e pré-processa-la em um formato adequado para os classificadores\n",
    "\n",
    "Como base de dados utilizaremos o [*20 newsgroups*](http://people.csail.mit.edu/jrennie/20Newsgroups/), que é um conjunto muito conhecido na área de pesquisa de mineração de dados de textos.\n",
    "\n",
    "Devido ao tamanho desse dataset, limitaremos nossa análise a 4 sub-categorias de texto. Essas categorias serão as classes do problema preditivo que trateramos. O conjunto de dados mencionado está disponível diretamente no `sklearn`.\n",
    "\n",
    "\n",
    "O trecho a seguir ilustra como carregar o conjunto de dados e também apresenta as categorias que consideraremos e como separá-las:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizaremos 4 das 20 categorias de texto disponiveis no dataset\n",
    "categories = ['alt.atheism', 'soc.religion.christian', 'comp.graphics', 'sci.med']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregaremos o subconjunto de treino do dataset e selecionaremos apenas as 4 categorias apresentadas anteriormente. Essas categorias serão as classes do sub-problema que levaremos em conta, ou seja, tentaremos predizer o assunto que cada texto aborda utilizando aprendizado de máquina."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "twenty_train = fetch_20newsgroups(subset='train', categories=categories, shuffle=True,\n",
    "                                  random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Notem que usamos `shuffle=True`, então nossos dados já vêm embaralhados)\n",
    "\n",
    "Vamos ver que campos temos no dataset e a quantidade de amostras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Campos disponíveis: ['data', 'filenames', 'target_names', 'target', 'DESCR']\n",
      "Quantidade de amostras: 2257\n"
     ]
    }
   ],
   "source": [
    "print('Campos disponíveis:', list(twenty_train))\n",
    "print('Quantidade de amostras:', len(twenty_train.data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veremos também quão desbalanceado é o problema em nossas mãos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3]), array([480, 584, 594, 599]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Formato: (array_com_as_classes, array_com_qnt_exemplos_em_cada_classe)\n",
    "np.unique(twenty_train.target, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os dados estão relativamente balanceados! Muito provavelmente não precisaremos nos preocupar com desbalanceamento.\n",
    "\n",
    "Por outro lado nossos dados são textuais:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'From: sd345@city.ac.uk (Michael Collier)\\nSubject: Converting images to HP LaserJet III?\\nNntp-Posting-Host: hampton\\nOrganization: The City University\\nLines: 14\\n\\nDoes anyone know of a good way (standard PC application/PD utility) to\\nconvert tif/img/tga files into LaserJet III format.  We would also like to\\ndo the same, converting to HPGL (HP plotter) files.\\n\\nPlease email any response.\\n\\nIs this the correct group?\\n\\nThanks in advance.  Michael.\\n-- \\nMichael Collier (Programmer)                 The Computer Unit,\\nEmail: M.P.Collier@uk.ac.city                The City University,\\nTel: 071 477-8000 x3769                      London,\\nFax: 071 477-8565                            EC1V 0HB.\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_train['data'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E agora?\n",
    "\n",
    "Nosso foco aqui não é o processamento dos dados, e sim comparar algorítmos preditivos.\n",
    "\n",
    "A extração de features pode ser feita de várias formas. O `sklearn` nos oferece ferramentos muito práticas para tal. Uma sugestão é utilizar o [`CountVectorizer`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer) para a extração das features e o [`TfidfTransformer`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html#sklearn.feature_extraction.text.TfidfTransformer) como passo de pré-processamento.\n",
    "\n",
    "\n",
    "Certo. Temos meios de organizar de forma tabular nossos dados e, assim, utilizá-los para treinar alguns modelos de aprendizado de máquina. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dados os pontos mencionados anteriormente, a tarefa é:\n",
    "\n",
    "# **Tarefa:**\n",
    "\n",
    "## Comparar o Naive Bayes contra o k-NN e Árvore de decisão utilizando as 4 categorias de tipo texto carregadas anteriormente da base de dados 20 newsgroups.\n",
    "\n",
    "Passos:\n",
    "\n",
    "1. [x] Carregar o conjunto de dados\n",
    "2. [ ] Extrair atributos e aplicar pré-processamento (`CountVectorizer` e `TfidfTransformer`)\n",
    "3. [ ] Separar os dados entre treinamento e validação\n",
    "4. [ ] Escolher uma métrica de avaliação adequada\n",
    "5. [ ] Comparar o desempenho dos algoritmos (Naive Bayes, k-NN e Árvore de Decisão)\n",
    "\n",
    "\n",
    "*Observações:*\n",
    "\n",
    "- **Não existe uma única forma \"certa\" de realizar a tarefa**, mas a motivação de cada escolha deve ser justificável.\n",
    "- O ajuste de hiperparâmetros (quando aplicável) não precisa ser necessariamente automático, por simplicidade vocês podem ajustá-los manualmente\n",
    "- A ideia aqui é discutir como os diferentes vieses preditivos se comportam no problema proposto e aplicar os conhecimentos adquiridos nas aulas passadas\n",
    "\n",
    "Vale ressaltar que algumas decisões deverão ser tomadas para realizar essa tarefa:\n",
    "\n",
    "a) Que variante do NB utilizaremos?\n",
    "\n",
    "b) Como iremos configurar nossos preditores? (ajuste de hiperparâmetros)\n",
    "\n",
    "c) Como avaliar a performance dos diferentes algoritmos de forma justa?\n",
    "   - Que métrica de avaliação utilizar\n",
    "   - Como particionar os dados? (e.g., cross-validation)\n",
    "\n",
    "Lembrem-se de utilizar os mesmos passos de processamento no treino e teste (`fit` no treino e `transform` no teste). Dica para simplicidade e elegância: pipelines (no fórum temos um exemplo de utilização)!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "# Exploraremos uma possível solução para a tarefa\n",
    "\n",
    "Propositalmente esse exercício foi concebido de forma a termos múltiplas soluções que não são mutuamente exclusivas. Então, se em sua solução você acabou escolhendo outras alternativas, não se preocupe. Estou explorando bastente coisa apenas para servir como uma referência no futuro, se precisarem. Não tem problema se não conhecem uma coisa ou outra de Python ou do sklearn :D\n",
    "\n",
    "## O que decidi fazer:\n",
    "\n",
    "### 1. Com os dados de treino do 20 newsgroups\n",
    "\n",
    "**Atenção**: os termos *treino/teste/validação* podem confundir porque são utilizados em vários momentos, com objetivos diferentes. Aqui, os dados de treino que estou me referindo são aqueles já disponibilizados na base de dados que estamos utilizando. Eles foram carregados e filtrados com:\n",
    "\n",
    "```python\n",
    "# Utilizaremos 4 das 20 categorias de texto disponiveis no dataset\n",
    "categories = ['alt.atheism', 'soc.religion.christian', 'comp.graphics', 'sci.med']\n",
    "twenty_train = fetch_20newsgroups(subset='train', categories=categories, shuffle=True,\n",
    "                                  random_state=42)\n",
    "```\n",
    "\n",
    "Lembram?\n",
    "\n",
    "\n",
    "Esses dados serão particionados ainda mais entre *treino* e *validação*. Utilizarei essa \"re-partição\" de treino para ajustar os hiperparâmetros dos algoritmos e avaliarei os melhores modelos encontrados no conjunto de validação.\n",
    "\n",
    "Como selecionaremos um **único** modelo para aplicar nos dados de teste (aqueles que são disponibilizados no próprio dataset 20 newsgroups), já são outros quinhentos. Veremos isso depois.\n",
    "\n",
    "Fiz algumas escolhas para essa solução candidata:\n",
    "\n",
    "- Como vi que os dados não são muito desbalanceados, resolvi usar a acurácia como métrica de avaliação.\n",
    "- Resolvi usar 10-fold cross-validation (CV) para particionar nossos dados \"externamente\".\n",
    "- Para cada partição realizada no CV \"externo\", tomarei o conjunto de treino e o particionarei novamente utilizando um 5-fold CV. Nessa partição interna eu aplicarei um [random search](https://medium.com/swlh/randomized-or-grid-search-with-pipeline-cheatsheet-719c72eda68) e selecionarei o melhor modelo encontrado. A seleção de melhor modelo é feita automaticamente pelo sklearn ao utilizarmos a classe `RandomizedSearchCV`.\n",
    "- Nesses experimentos eu escolhi um *budget* (quantidade de iterações) de `30` para o random search. Esse número pode (e deve) ser alterado conforme as necessidades. Minha ideia aqui foi tentar ser didático. Notem que ao escolher esse valor, no fim das contas, treinaremos *budget x n_fold_interno x n_fold_externo* modelos. Em outras palavras, `30 x 5 x 10 = 1500` modelos por algoritmo! (o negócio é lento hahaha)\n",
    "- O melhor modelo encontrado será avaliado no conjunto de validação. Guardarei cada um dos melhores conjuntos de hiperparâmetros encontrados nos conjuntos de treino (notem que aqui \"treino\" já passou a significar as 10 partições que farei nos dados que carregamos) e os resultados que os modelos relacionados a eles obteram nos conjuntos de validação.\n",
    "\n",
    "### 2. Com os dados de teste do 20 newsgroups\n",
    "\n",
    "Os dados de teste que estou me referindo aqui são aqueles carregados com:\n",
    "\n",
    "```python\n",
    "twenty_test = fetch_20newsgroups(subset='test', categories=categories, shuffle=True, random_state=42)\n",
    "```\n",
    "Certo. Se tudo correu bem até aqui, teremos 10 \"melhores\" conjuntos de hiperparâmetros e 10 valores de acurácia (um para cada partição que fizemos nos dados). E agora? Qual será nosso modelo \"definitivo\", ou seja, qual desses conjuntos de hiperparâmetros utilizarei para treinar nosso modelo \"final\" com todos os dados de treino que temos disponíveis (sei que já \"sacaram\" mas vale reforçar: treino aqui são os dados completos que carregamos) e avaliá-lo nos dados de teste?\n",
    "\n",
    "Uma boa prática, defendida pelo professor André C. P. L. F. de Carvalho, é selecionar o conjunto de hiperparâmetros que resultou no desempenho *mediano* nos nossos dados de validação. Por que mediano? Dessa forma, buscamos mitigar possíveis efeitos aleatórios da nossa partição treino/validação:\n",
    "\n",
    "- E se justo naquela partição que resultou no modelo mais acurado os dados de validação eram mais \"fáceis\"?\n",
    "- E se justo naquela partição que resultou no modelo menos acurado os dados de validação eram mais \"difíceis\"?\n",
    "\n",
    "Lembre-se que aqui já estamos falando de modelos cujos hiperparâmetros foram ajustados com Random Search. Mais um lembrete:\n",
    "\n",
    "Podemos levantar também a questão do desbalanceamento: e se nossa partição de dados, que não foi estratificada (propositalmente), acabou por gerar pouca representatividade de alguma(s) classe(s) no treino/validação? Isso certamente é possível (no entanto não muito provável) e poderia ser evitado com o uso de amostragem estratificada. Fica aí o desafio para quem quiser explorar mais! No entanto, lembre-se também que desbalanceamento não necessariamente é um problema, pode ser apenas uma característica do problema que temos em mãos. As coisas complicam quando temos desbalanceamento e as classes não são facilmente separáveis.\n",
    "\n",
    "Chega de filosofar e vamos à prática! Todavia, esse tipo de discussão e planejamento é essencial antes de qualquer experimentação. Uma metodologia sólida, robusta e bem definida é mandatória!\n",
    "\n",
    "Definirei duas funções a seguir:\n",
    "\n",
    "- `run_random_search`: faz o tuning nos dados internos\n",
    "- `tune_and_nfold_cross_validate`: particiona os dados, chama a função de tuning, salva melhores modelos, etc. etc.\n",
    "\n",
    "Buscarei deixar as coisas bem documentadas e flexíveis para futura referência. Notem como basicamente tudo pode ser configurado :)\n",
    "\n",
    "Notem também que as diversas \"sementes\" passadas para os pseudo-geradores de números aleatórios são configuráveis para garantir transparência de resultados e reproducibilidade.\n",
    "\n",
    "Mãos a obra!\n",
    "\n",
    "---\n",
    "---\n",
    "\n",
    "### Parte 1: tuning e validação cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "from sklearn.model_selection import KFold, RandomizedSearchCV\n",
    "\n",
    "# Função auxiliar para realizar um random search em um algoritmo/pipeline,\n",
    "# dadas a partição dos dados e formas de se amostrar os hiperparâmetros\n",
    "def run_random_search(X_train, y_train, partition, classifier, dist_params, search_seed, budget,\n",
    "                      metric):\n",
    "    # Note que 'partition' tem sua própria seed para particionar os dados\n",
    "    # random_state aqui controla como os hiperparâmetros serão amostrados\n",
    "    clf = RandomizedSearchCV(classifier, dist_params, cv=partition, random_state=search_seed,\n",
    "                             n_iter=budget, scoring=make_scorer(metric), n_jobs=4)\n",
    "    random_search = clf.fit(X_train, y_train)\n",
    "    return random_search\n",
    "\n",
    "# Nossos dados são textuais, não conseguimos acessá-los como uma matriz, infelizmente\n",
    "def filter_data(data, indices):\n",
    "    return [data[i] for i in indices]\n",
    "\n",
    "\n",
    "def tune_and_nfold_cross_validate(X, y, pipeline, dist_params, outer_data_seed=7, inner_data_seed=8,\n",
    "                                 search_seed=42, outer_nfold=10, inner_nfold=5, metric=accuracy_score,\n",
    "                                 budget_random_search=30):\n",
    "    \"\"\" Roda um n-fold cross-validation externo e para a partição de treino roda outro n-fold\n",
    "    cross-validation interno, onde o algoritmo/pipeline em questão é ajustado com random search.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "        X : np.ndarray(n_samples, n_features)\n",
    "            Matriz com os atributos preditivos\n",
    "        y : np.ndarray (, n_features)\n",
    "            Array com os targets\n",
    "        pipeline : sklearn.pipeline or sklearn.classifier\n",
    "            Pipeline que queremos usar\n",
    "        dist_params : dict\n",
    "            Dicionario cujas chaves são os nomes dos parâmetros a serem ajustados e seus valores\n",
    "            são funções de amostragens para tais parâmetros ou listas de possíveis valores. Os parâmetros\n",
    "            devem ser identificados pelo componente do pipeline ao qual pertencem (mais informações\n",
    "            serão apresentadas quando formos utilizar essa função).\n",
    "        outer_data_seed : int, optional (default=7)\n",
    "            Seed para controlar a partição externa dos dados\n",
    "        inner_data_seed : int, optional (default=8)\n",
    "            Seed para controlar a partição interna dos dados (tuning)\n",
    "        search_seed : int, optional (default=42)\n",
    "            Seed para controlar a amostragem dos hiperparâmetros no random search\n",
    "        outer_nfold : int, optional (default=10)\n",
    "            Número de folds na partição externa\n",
    "        inner_nfold : int, optional (default=5)\n",
    "            Número de folds na partição interna (utilizada para ajuste de hiperparâmetros)\n",
    "        metric : sklearn.metric or callable, optional (default=accuracy_score)\n",
    "            A métrica de classificação que será utilizada para avaliação dos modelos\n",
    "        budget_random_search : int, optional (default=30)\n",
    "            Quantidade de iterações que o random search executará para cada partição\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "        results : dict\n",
    "            Dicionário com os seguintes conteúdos:\n",
    "\n",
    "            'best_candidate' : dict\n",
    "                Dicionário com os hiperparâmetros do pipeline mediano\n",
    "            'scores':  list\n",
    "                Lista com a performance obtida pelos modelos ajustados em cada um dos folds\n",
    "            externos\n",
    "            \n",
    "    \"\"\"\n",
    "    \n",
    "    # Definimos primeiramente como particionaremos os dados externamente\n",
    "    outer_kfold = KFold(n_splits=outer_nfold, shuffle=True, random_state=outer_data_seed)\n",
    "    \n",
    "    best_scores = []\n",
    "    best_params = []\n",
    "    \n",
    "    for train_id, val_id in outer_kfold.split(X):\n",
    "        # Use as linhas a seguir se seus dados são estruturados\n",
    "        # # Conjuntos de treino\n",
    "        # X_train, y_train = X[train_id], y[train_id]\n",
    "        # # Conjuntos de validação\n",
    "        # X_val, y_val = X[val_id], y[val_id]\n",
    "        \n",
    "        X_train = filter_data(X, train_id)\n",
    "        y_train = y[train_id]\n",
    "        X_val = filter_data(X, val_id)\n",
    "        y_val = y[val_id]\n",
    "        \n",
    "        # Definimos a partição interna para o tuning\n",
    "        inner_kfold = KFold(n_splits=inner_nfold, shuffle=True, random_state=inner_data_seed)\n",
    "        # Executamos o random search\n",
    "        random_search = run_random_search(X_train=X_train, y_train=y_train, partition=inner_kfold,\n",
    "                                          classifier=pipeline, dist_params=dist_params,\n",
    "                                          search_seed=search_seed, budget=budget_random_search,\n",
    "                                          metric=metric)\n",
    "        # Selecionamos o melhor modelo encontrado\n",
    "        best_model = random_search.best_estimator_\n",
    "        # Salvamos seus hiperparâmetros para \"mais tarde\"\n",
    "        best_params.append(random_search.best_params_)\n",
    "        # Calculamos a metrica de avaliação no conjunto de validação\n",
    "        best_scores.append(metric(y_val, best_model.predict(X_val)))\n",
    "    \n",
    "    # Performance mediana\n",
    "    median_score = np.median(best_scores)\n",
    "    # Selecionamos a partição que obteve a performance mediana\n",
    "    median_candidate = np.argmin(np.abs(np.array(best_scores) - median_score))\n",
    "    \n",
    "    results = {\n",
    "        'best_candidate': best_params[median_candidate],\n",
    "        'scores': best_scores\n",
    "    }\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quase tudo pronto para a diversão. Resta um aspecto essencial para definirmos: como criaremos o espaço de busca dos nossos algoritmos. Para tal, utilizemos alguns recursos disponíveis no `scipy`. Mas antes vamos definir o nosso pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "\n",
    "# Monta pipeline com o classificador passado como parâmetro\n",
    "def assemble_text_pipeline(classifier):\n",
    "    pipeline = Pipeline(\n",
    "        steps=[\n",
    "            ('vectorizer', CountVectorizer()),\n",
    "            ('pre_processor', TfidfTransformer()),\n",
    "            ('classifier', classifier())\n",
    "        ]\n",
    "    )\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos começar montando o espaço de hiperparâmetros da árvore de decisão: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['memory', 'steps', 'verbose', 'vectorizer', 'pre_processor', 'classifier', 'vectorizer__analyzer', 'vectorizer__binary', 'vectorizer__decode_error', 'vectorizer__dtype', 'vectorizer__encoding', 'vectorizer__input', 'vectorizer__lowercase', 'vectorizer__max_df', 'vectorizer__max_features', 'vectorizer__min_df', 'vectorizer__ngram_range', 'vectorizer__preprocessor', 'vectorizer__stop_words', 'vectorizer__strip_accents', 'vectorizer__token_pattern', 'vectorizer__tokenizer', 'vectorizer__vocabulary', 'pre_processor__norm', 'pre_processor__smooth_idf', 'pre_processor__sublinear_tf', 'pre_processor__use_idf', 'classifier__ccp_alpha', 'classifier__class_weight', 'classifier__criterion', 'classifier__max_depth', 'classifier__max_features', 'classifier__max_leaf_nodes', 'classifier__min_impurity_decrease', 'classifier__min_impurity_split', 'classifier__min_samples_leaf', 'classifier__min_samples_split', 'classifier__min_weight_fraction_leaf', 'classifier__presort', 'classifier__random_state', 'classifier__splitter'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "pipeline = assemble_text_pipeline(DecisionTreeClassifier)\n",
    "\n",
    "# Vamos ver o que temos de opções para ajuste\n",
    "pipeline.get_params().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notem que as chaves desse dicionário de hiperparâmetros tem o formato:\n",
    "\n",
    "\"identificador de component\" + \"\\_\\_\" + \"nome hiperparâmetro\"\n",
    "\n",
    "Legal! Já sabemos como acessar apenas os parâmetros da Árvore de Decisão. Eu não preciso mas vou ajustar também um pouco dos componentes de processamento dos dados. Vou colocar alguns extras no meu [pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html):\n",
    "\n",
    "* A possibilidade de utilizar um CountVectorizer com remoção de stop-words\n",
    "* A possibilidade de utilizar um CountVectorizer padrão\n",
    "* A possibilidade de omitir o TF-IDF\n",
    "* A possibilidade de utilizar um TF-IDF padrão\n",
    "\n",
    "O que nos interessa aqui são principalmente os campos iniciados com `classifier`. Para a árvore de decisão, decidi avaliar apenas os critérios de split e realizar pós-poda (vale a pena conferir a prática de árvores para relembrar). Em outras palavras, deixaremos as árvores crescerem livremente e depois removeremos alguns ramos que podem não ser tão úteis. **Alerta:** poderíamos ajustar outros parâmetros, mas essa é uma decisão que estou fazendo aqui.\n",
    "\n",
    "O `scipy` será utilizado para definir distribuições das quais amostraremos nossos valores candidatos para hiperparâmetros.\n",
    "\n",
    "Here we go:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizarei o pacote a seguir para selecionar stop-words para possível remoção\n",
    "# Se não tiver o pacote instalado, execute a linha a seguir (você deve remover o comentário antes)\n",
    "# !pip install spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "# Nos provê as diferentes distribuições que utilizaremos para amostragem\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "dt_params = {\n",
    "    'vectorizer': [CountVectorizer(strip_accents='unicode'),\n",
    "                   # Adicionei duas stop-words extras porque elas geravam um warning\n",
    "                   CountVectorizer(strip_accents='unicode', stop_words=STOP_WORDS | {'ll', 've'})],\n",
    "    'pre_processor': [None, TfidfTransformer()],\n",
    "    'classifier__criterion': ['gini', 'entropy'],\n",
    "    'classifier__ccp_alpha': stats.uniform(loc=0.0, scale=0.05),  # Escolha arbitrária de ranges \n",
    "    'classifier__random_state': [0]  # Na dúvida, melhor garantir\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos selecionar nossos dados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = twenty_train['data'], twenty_train['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exemplo completo com árvore de decisão:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_dt = assemble_text_pipeline(DecisionTreeClassifier)\n",
    "\n",
    "results_dt = tune_and_nfold_cross_validate(X, y, pipeline_dt, dt_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faremos a mesma coisa para o k-NN e o Naive Bayes. Aqui, escolherei o MultinomialNB (tenho certeza que sabem minha motivação, dado o tipo de dados e o pré-processamento que estamos aplicando a eles).\n",
    "\n",
    "Em seguida, o k-NN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_params = {\n",
    "    'vectorizer': [CountVectorizer(strip_accents='unicode'),\n",
    "                   # Adicionei duas stop-words extras porque elas geravam um warning\n",
    "                   CountVectorizer(strip_accents='unicode', stop_words=STOP_WORDS | {'ll', 've'})],\n",
    "    # Se TfidfTransformer está ativo, a distância euclidiana é equivalente à similaridade cosseno\n",
    "    # uma vez que uma norma l2 é aplicada nos dados. Caso contrário, nossas métricas de distância podem\n",
    "    # não ser as melhores :P\n",
    "    'pre_processor': [None, TfidfTransformer()],\n",
    "    'classifier__n_neighbors': stats.randint(low=2, high=21),  # [2, 20]\n",
    "    'classifier__weights': ['uniform', 'distance'], \n",
    "    'classifier__metric': ['euclidean', 'manhattan', 'chebyshev']\n",
    "    \n",
    "}\n",
    "\n",
    "pipeline_knn = assemble_text_pipeline(KNeighborsClassifier)\n",
    "results_knn = tune_and_nfold_cross_validate(X, y, pipeline_knn, knn_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E o Naive Bayes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb_params = {\n",
    "    'vectorizer': [CountVectorizer(strip_accents='unicode'),\n",
    "                   # Adicionei duas stop-words extras porque elas geravam um warning\n",
    "                   CountVectorizer(strip_accents='unicode', stop_words=STOP_WORDS | {'ll', 've'})],\n",
    "    'pre_processor': [None, TfidfTransformer()],\n",
    "    'classifier__alpha': stats.uniform(loc=0, scale=1),\n",
    "    'classifier__fit_prior': [True, False]\n",
    "    \n",
    "}\n",
    "\n",
    "pipeline_nb = assemble_text_pipeline(MultinomialNB)\n",
    "results_nb = tune_and_nfold_cross_validate(X, y, pipeline_nb, nb_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 2: avaliando nossos modelos no conjunto de testes\n",
    "\n",
    "Vamos construir nossos pipelines finais:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "final_dt = assemble_text_pipeline(DecisionTreeClassifier).set_params(**results_dt['best_candidate'])\n",
    "final_knn = assemble_text_pipeline(KNeighborsClassifier).set_params(**results_knn['best_candidate'])\n",
    "final_nb = assemble_text_pipeline(MultinomialNB).set_params(**results_nb['best_candidate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora é a hora da verdade! Finalmente aplicaremos nossos pipelines candidatos no conjunto de testes :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuracias\n",
      "\n",
      "Na validação:\n",
      "DT: 0.8432 +/ 0.0271\n",
      "k-NN: 0.9278 +/ 0.0146\n",
      "M-NB: 0.9734 +/ 0.0084\n",
      "\n",
      "No teste:\n",
      "DT: 0.7529960053262317\n",
      "k-NN: 0.844207723035952\n",
      "M-NB: 0.9467376830892144\n"
     ]
    }
   ],
   "source": [
    "final_dt.fit(twenty_train['data'], twenty_train['target'])\n",
    "final_knn.fit(twenty_train['data'], twenty_train['target'])\n",
    "final_nb.fit(twenty_train['data'], twenty_train['target'])\n",
    "\n",
    "twenty_test = fetch_20newsgroups(subset='test', categories=categories, shuffle=True, random_state=42)\n",
    "\n",
    "acc_dt = accuracy_score(twenty_test['target'], final_dt.predict(twenty_test['data']))\n",
    "acc_knn = accuracy_score(twenty_test['target'], final_knn.predict(twenty_test['data']))\n",
    "acc_nb = accuracy_score(twenty_test['target'], final_nb.predict(twenty_test['data']))\n",
    "\n",
    "print('Acuracias\\n')\n",
    "print('Na validação:')\n",
    "print('DT: {0:.4f} +/ {1:.4f}'.format(np.mean(results_dt['scores']), np.std(results_dt['scores'])))\n",
    "print('k-NN: {0:.4f} +/ {1:.4f}'.format(np.mean(results_knn['scores']), np.std(results_knn['scores'])))\n",
    "print('M-NB: {0:.4f} +/ {1:.4f}'.format(np.mean(results_nb['scores']), np.std(results_nb['scores'])))\n",
    "\n",
    "print('\\nNo teste:')\n",
    "print('DT:', acc_dt)\n",
    "print('k-NN:', acc_knn)\n",
    "print('M-NB:', acc_nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Temos um vencedor!!!**\n",
    "\n",
    "Com essa referência em mãos, minha sugestão é alterar valores, mudar os hiper-espaços de busca, etc. Divirtam-se!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
