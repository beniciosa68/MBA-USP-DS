{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HRPwCEdgS4pR"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from numpy.random import seed\n",
    "from tensorflow.random import set_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 253
    },
    "id": "BQaVQ5qUTOit",
    "outputId": "203ad45f-5e4b-4494-999b-7fe124218acd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>feature_10</th>\n",
       "      <th>feature_11</th>\n",
       "      <th>feature_12</th>\n",
       "      <th>feature_13</th>\n",
       "      <th>feature_14</th>\n",
       "      <th>feature_15</th>\n",
       "      <th>feature_16</th>\n",
       "      <th>feature_17</th>\n",
       "      <th>feature_18</th>\n",
       "      <th>feature_19</th>\n",
       "      <th>feature_20</th>\n",
       "      <th>feature_21</th>\n",
       "      <th>feature_22</th>\n",
       "      <th>feature_23</th>\n",
       "      <th>feature_24</th>\n",
       "      <th>feature_25</th>\n",
       "      <th>feature_26</th>\n",
       "      <th>feature_27</th>\n",
       "      <th>feature_28</th>\n",
       "      <th>feature_29</th>\n",
       "      <th>feature_30</th>\n",
       "      <th>feature_31</th>\n",
       "      <th>feature_32</th>\n",
       "      <th>feature_33</th>\n",
       "      <th>feature_34</th>\n",
       "      <th>feature_35</th>\n",
       "      <th>feature_36</th>\n",
       "      <th>feature_37</th>\n",
       "      <th>feature_38</th>\n",
       "      <th>feature_39</th>\n",
       "      <th>feature_40</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_523</th>\n",
       "      <th>feature_524</th>\n",
       "      <th>feature_525</th>\n",
       "      <th>feature_526</th>\n",
       "      <th>feature_527</th>\n",
       "      <th>feature_528</th>\n",
       "      <th>feature_529</th>\n",
       "      <th>feature_530</th>\n",
       "      <th>feature_531</th>\n",
       "      <th>feature_532</th>\n",
       "      <th>feature_533</th>\n",
       "      <th>feature_534</th>\n",
       "      <th>feature_535</th>\n",
       "      <th>feature_536</th>\n",
       "      <th>feature_537</th>\n",
       "      <th>feature_538</th>\n",
       "      <th>feature_539</th>\n",
       "      <th>feature_540</th>\n",
       "      <th>feature_541</th>\n",
       "      <th>feature_542</th>\n",
       "      <th>feature_543</th>\n",
       "      <th>feature_544</th>\n",
       "      <th>feature_545</th>\n",
       "      <th>feature_546</th>\n",
       "      <th>feature_547</th>\n",
       "      <th>feature_548</th>\n",
       "      <th>feature_549</th>\n",
       "      <th>feature_550</th>\n",
       "      <th>feature_551</th>\n",
       "      <th>feature_552</th>\n",
       "      <th>feature_553</th>\n",
       "      <th>feature_554</th>\n",
       "      <th>feature_555</th>\n",
       "      <th>feature_556</th>\n",
       "      <th>feature_557</th>\n",
       "      <th>feature_558</th>\n",
       "      <th>feature_559</th>\n",
       "      <th>feature_560</th>\n",
       "      <th>feature_561</th>\n",
       "      <th>activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.289</td>\n",
       "      <td>-0.0203</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.983</td>\n",
       "      <td>-0.914</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.983</td>\n",
       "      <td>-0.924</td>\n",
       "      <td>-0.935</td>\n",
       "      <td>-0.567</td>\n",
       "      <td>-0.744</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.814</td>\n",
       "      <td>-0.966</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.988</td>\n",
       "      <td>-0.943</td>\n",
       "      <td>-0.408</td>\n",
       "      <td>-0.679</td>\n",
       "      <td>-0.602</td>\n",
       "      <td>0.9290</td>\n",
       "      <td>-0.8530</td>\n",
       "      <td>0.360</td>\n",
       "      <td>-0.0585</td>\n",
       "      <td>0.2570</td>\n",
       "      <td>-0.2250</td>\n",
       "      <td>0.264</td>\n",
       "      <td>-0.0952</td>\n",
       "      <td>0.279</td>\n",
       "      <td>-0.4650</td>\n",
       "      <td>0.4920</td>\n",
       "      <td>-0.191</td>\n",
       "      <td>0.3760</td>\n",
       "      <td>0.4350</td>\n",
       "      <td>0.661</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.991</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.937</td>\n",
       "      <td>0.347</td>\n",
       "      <td>-0.516</td>\n",
       "      <td>-0.803</td>\n",
       "      <td>-0.980</td>\n",
       "      <td>-0.961</td>\n",
       "      <td>-0.974</td>\n",
       "      <td>-0.952</td>\n",
       "      <td>-0.989</td>\n",
       "      <td>-0.980</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.701</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-0.1290</td>\n",
       "      <td>0.586</td>\n",
       "      <td>0.375</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.991</td>\n",
       "      <td>-0.990</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.991</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.990</td>\n",
       "      <td>-0.871</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-0.0743</td>\n",
       "      <td>-0.299</td>\n",
       "      <td>-0.710</td>\n",
       "      <td>-0.1130</td>\n",
       "      <td>0.03040</td>\n",
       "      <td>-0.465</td>\n",
       "      <td>-0.0184</td>\n",
       "      <td>-0.841</td>\n",
       "      <td>0.180</td>\n",
       "      <td>-0.0586</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.278</td>\n",
       "      <td>-0.0164</td>\n",
       "      <td>-0.124</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.975</td>\n",
       "      <td>-0.960</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.975</td>\n",
       "      <td>-0.958</td>\n",
       "      <td>-0.943</td>\n",
       "      <td>-0.558</td>\n",
       "      <td>-0.818</td>\n",
       "      <td>0.849</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.823</td>\n",
       "      <td>-0.982</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.978</td>\n",
       "      <td>-0.948</td>\n",
       "      <td>-0.715</td>\n",
       "      <td>-0.501</td>\n",
       "      <td>-0.571</td>\n",
       "      <td>0.6120</td>\n",
       "      <td>-0.3300</td>\n",
       "      <td>0.284</td>\n",
       "      <td>0.2850</td>\n",
       "      <td>0.1160</td>\n",
       "      <td>-0.0910</td>\n",
       "      <td>0.294</td>\n",
       "      <td>-0.2810</td>\n",
       "      <td>0.086</td>\n",
       "      <td>-0.0222</td>\n",
       "      <td>-0.0167</td>\n",
       "      <td>-0.221</td>\n",
       "      <td>-0.0134</td>\n",
       "      <td>-0.0727</td>\n",
       "      <td>0.579</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.991</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.841</td>\n",
       "      <td>0.532</td>\n",
       "      <td>-0.625</td>\n",
       "      <td>-0.900</td>\n",
       "      <td>-0.988</td>\n",
       "      <td>-0.983</td>\n",
       "      <td>-0.983</td>\n",
       "      <td>-0.986</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.988</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.721</td>\n",
       "      <td>-0.949</td>\n",
       "      <td>-0.2720</td>\n",
       "      <td>-0.336</td>\n",
       "      <td>-0.720</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>0.1580</td>\n",
       "      <td>-0.595</td>\n",
       "      <td>-0.861</td>\n",
       "      <td>0.0535</td>\n",
       "      <td>-0.00743</td>\n",
       "      <td>-0.733</td>\n",
       "      <td>0.7040</td>\n",
       "      <td>-0.845</td>\n",
       "      <td>0.180</td>\n",
       "      <td>-0.0543</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.280</td>\n",
       "      <td>-0.0195</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.967</td>\n",
       "      <td>-0.979</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.964</td>\n",
       "      <td>-0.977</td>\n",
       "      <td>-0.939</td>\n",
       "      <td>-0.558</td>\n",
       "      <td>-0.818</td>\n",
       "      <td>0.844</td>\n",
       "      <td>0.682</td>\n",
       "      <td>0.839</td>\n",
       "      <td>-0.983</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.999</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.965</td>\n",
       "      <td>-0.975</td>\n",
       "      <td>-0.592</td>\n",
       "      <td>-0.486</td>\n",
       "      <td>-0.571</td>\n",
       "      <td>0.2730</td>\n",
       "      <td>-0.0863</td>\n",
       "      <td>0.337</td>\n",
       "      <td>-0.1650</td>\n",
       "      <td>0.0172</td>\n",
       "      <td>-0.0745</td>\n",
       "      <td>0.342</td>\n",
       "      <td>-0.3330</td>\n",
       "      <td>0.239</td>\n",
       "      <td>-0.1360</td>\n",
       "      <td>0.1740</td>\n",
       "      <td>-0.299</td>\n",
       "      <td>-0.1250</td>\n",
       "      <td>-0.1810</td>\n",
       "      <td>0.609</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.987</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.905</td>\n",
       "      <td>0.661</td>\n",
       "      <td>-0.725</td>\n",
       "      <td>-0.929</td>\n",
       "      <td>-0.989</td>\n",
       "      <td>-0.986</td>\n",
       "      <td>-0.984</td>\n",
       "      <td>-0.991</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.989</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-0.737</td>\n",
       "      <td>-0.795</td>\n",
       "      <td>-0.2130</td>\n",
       "      <td>-0.535</td>\n",
       "      <td>-0.872</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-0.556</td>\n",
       "      <td>0.4150</td>\n",
       "      <td>-0.391</td>\n",
       "      <td>-0.760</td>\n",
       "      <td>-0.1190</td>\n",
       "      <td>0.17800</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.8090</td>\n",
       "      <td>-0.849</td>\n",
       "      <td>0.181</td>\n",
       "      <td>-0.0491</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.279</td>\n",
       "      <td>-0.0262</td>\n",
       "      <td>-0.123</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.983</td>\n",
       "      <td>-0.991</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.983</td>\n",
       "      <td>-0.989</td>\n",
       "      <td>-0.939</td>\n",
       "      <td>-0.576</td>\n",
       "      <td>-0.830</td>\n",
       "      <td>0.844</td>\n",
       "      <td>0.682</td>\n",
       "      <td>0.838</td>\n",
       "      <td>-0.986</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.984</td>\n",
       "      <td>-0.986</td>\n",
       "      <td>-0.627</td>\n",
       "      <td>-0.851</td>\n",
       "      <td>-0.912</td>\n",
       "      <td>0.0614</td>\n",
       "      <td>0.0748</td>\n",
       "      <td>0.198</td>\n",
       "      <td>-0.2640</td>\n",
       "      <td>0.0725</td>\n",
       "      <td>-0.1550</td>\n",
       "      <td>0.323</td>\n",
       "      <td>-0.1710</td>\n",
       "      <td>0.295</td>\n",
       "      <td>-0.3060</td>\n",
       "      <td>0.4820</td>\n",
       "      <td>-0.470</td>\n",
       "      <td>-0.3060</td>\n",
       "      <td>-0.3630</td>\n",
       "      <td>0.507</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.988</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.679</td>\n",
       "      <td>-0.701</td>\n",
       "      <td>-0.910</td>\n",
       "      <td>-0.989</td>\n",
       "      <td>-0.988</td>\n",
       "      <td>-0.987</td>\n",
       "      <td>-0.987</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.989</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-0.989</td>\n",
       "      <td>-0.721</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-0.0357</td>\n",
       "      <td>-0.230</td>\n",
       "      <td>-0.511</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.956</td>\n",
       "      <td>-0.937</td>\n",
       "      <td>0.4050</td>\n",
       "      <td>-0.117</td>\n",
       "      <td>-0.483</td>\n",
       "      <td>-0.0368</td>\n",
       "      <td>-0.01290</td>\n",
       "      <td>0.640</td>\n",
       "      <td>-0.4850</td>\n",
       "      <td>-0.849</td>\n",
       "      <td>0.182</td>\n",
       "      <td>-0.0477</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.277</td>\n",
       "      <td>-0.0166</td>\n",
       "      <td>-0.115</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.981</td>\n",
       "      <td>-0.990</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.980</td>\n",
       "      <td>-0.990</td>\n",
       "      <td>-0.942</td>\n",
       "      <td>-0.569</td>\n",
       "      <td>-0.825</td>\n",
       "      <td>0.849</td>\n",
       "      <td>0.683</td>\n",
       "      <td>0.838</td>\n",
       "      <td>-0.993</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.981</td>\n",
       "      <td>-0.991</td>\n",
       "      <td>-0.787</td>\n",
       "      <td>-0.559</td>\n",
       "      <td>-0.761</td>\n",
       "      <td>0.3130</td>\n",
       "      <td>-0.1310</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.2580</td>\n",
       "      <td>-0.2730</td>\n",
       "      <td>0.435</td>\n",
       "      <td>-0.3150</td>\n",
       "      <td>0.440</td>\n",
       "      <td>-0.2690</td>\n",
       "      <td>0.1790</td>\n",
       "      <td>-0.089</td>\n",
       "      <td>-0.1560</td>\n",
       "      <td>-0.1900</td>\n",
       "      <td>0.599</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.994</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>0.559</td>\n",
       "      <td>-0.529</td>\n",
       "      <td>-0.859</td>\n",
       "      <td>-0.991</td>\n",
       "      <td>-0.989</td>\n",
       "      <td>-0.988</td>\n",
       "      <td>-0.991</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>-0.991</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-0.989</td>\n",
       "      <td>-0.763</td>\n",
       "      <td>-0.897</td>\n",
       "      <td>-0.2740</td>\n",
       "      <td>-0.510</td>\n",
       "      <td>-0.831</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-0.937</td>\n",
       "      <td>0.0878</td>\n",
       "      <td>-0.351</td>\n",
       "      <td>-0.699</td>\n",
       "      <td>0.1230</td>\n",
       "      <td>0.12300</td>\n",
       "      <td>0.694</td>\n",
       "      <td>-0.6160</td>\n",
       "      <td>-0.848</td>\n",
       "      <td>0.185</td>\n",
       "      <td>-0.0439</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 562 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_1  feature_2  feature_3  ...  feature_560  feature_561  activity\n",
       "0      0.289    -0.0203     -0.133  ...        0.180      -0.0586         5\n",
       "1      0.278    -0.0164     -0.124  ...        0.180      -0.0543         5\n",
       "2      0.280    -0.0195     -0.113  ...        0.181      -0.0491         5\n",
       "3      0.279    -0.0262     -0.123  ...        0.182      -0.0477         5\n",
       "4      0.277    -0.0166     -0.115  ...        0.185      -0.0439         5\n",
       "\n",
       "[5 rows x 562 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"smartphone_activity_dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "GPQMMBD-UDXl",
    "outputId": "bbd5f46d-2062-4292-908f-605cc6cb80ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8239\n",
      "2059\n"
     ]
    }
   ],
   "source": [
    "rotulos = np.array(df['activity'])\n",
    "features = np.array(df.iloc[:, :-1])\n",
    "\n",
    "perc_train = 0.8\n",
    "\n",
    "n_train = int(features.shape[0]*perc_train)\n",
    "n_test = int(features.shape[0]*(1-perc_train))\n",
    "print(n_train)\n",
    "print(n_test)\n",
    "\n",
    "x_train = features[:n_train,:]\n",
    "y_train = rotulos[:n_train]\n",
    "\n",
    "x_test = features[n_train:,:]\n",
    "y_test = rotulos[n_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "id": "q3Hu_HSEUMrT",
    "outputId": "50296bcc-eeb6-481e-a735-ab9c26102987"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         [(None, 561)]             0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 128)               71936     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "code (Dense)                 (None, 50)                6450      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 128)               6528      \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 561)               72369     \n",
      "=================================================================\n",
      "Total params: 190,307\n",
      "Trainable params: 190,307\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_data = tf.keras.layers.Input(shape=(x_train.shape[1],))\n",
    "x = keras.layers.Dense(128,activation='tanh')(input_data)\n",
    "x = keras.layers.Dense(128,activation='tanh')(x)\n",
    "x = keras.layers.Dropout(0.25)(x)\n",
    "x = keras.layers.Dense(50, activation='tanh',name='code')(x)\n",
    "x = keras.layers.Dense(128, activation='tanh')(x)\n",
    "x = keras.layers.Dense(128, activation='tanh')(x)\n",
    "output = keras.layers.Dense(x_train.shape[1],activation='tanh')(x)\n",
    "\n",
    "autoencoder = keras.models.Model(input_data, output)\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "OuzTJ2pFXAKs",
    "outputId": "cc839b0f-167d-459f-ce6a-80d323f2f167"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "515/515 [==============================] - 2s 4ms/step - loss: 0.0431 - accuracy: 0.1571\n",
      "Epoch 2/50\n",
      "515/515 [==============================] - 2s 4ms/step - loss: 0.0265 - accuracy: 0.1959\n",
      "Epoch 3/50\n",
      "515/515 [==============================] - 2s 4ms/step - loss: 0.0240 - accuracy: 0.2271\n",
      "Epoch 4/50\n",
      "515/515 [==============================] - 2s 3ms/step - loss: 0.0214 - accuracy: 0.2687\n",
      "Epoch 5/50\n",
      "515/515 [==============================] - 2s 4ms/step - loss: 0.0203 - accuracy: 0.2552\n",
      "Epoch 6/50\n",
      "515/515 [==============================] - 2s 3ms/step - loss: 0.0188 - accuracy: 0.2684\n",
      "Epoch 7/50\n",
      "515/515 [==============================] - 2s 4ms/step - loss: 0.0177 - accuracy: 0.3027\n",
      "Epoch 8/50\n",
      "515/515 [==============================] - 2s 4ms/step - loss: 0.0170 - accuracy: 0.3195\n",
      "Epoch 9/50\n",
      "515/515 [==============================] - 2s 4ms/step - loss: 0.0162 - accuracy: 0.3354\n",
      "Epoch 10/50\n",
      "515/515 [==============================] - 2s 4ms/step - loss: 0.0157 - accuracy: 0.3508\n",
      "Epoch 11/50\n",
      "515/515 [==============================] - 2s 3ms/step - loss: 0.0151 - accuracy: 0.3503\n",
      "Epoch 12/50\n",
      "515/515 [==============================] - 2s 3ms/step - loss: 0.0146 - accuracy: 0.3593\n",
      "Epoch 13/50\n",
      "515/515 [==============================] - 2s 4ms/step - loss: 0.0141 - accuracy: 0.3672\n",
      "Epoch 14/50\n",
      "515/515 [==============================] - 2s 4ms/step - loss: 0.0138 - accuracy: 0.3650\n",
      "Epoch 15/50\n",
      "515/515 [==============================] - 2s 3ms/step - loss: 0.0135 - accuracy: 0.3764\n",
      "Epoch 16/50\n",
      "515/515 [==============================] - 2s 3ms/step - loss: 0.0131 - accuracy: 0.3754\n",
      "Epoch 17/50\n",
      "515/515 [==============================] - 2s 4ms/step - loss: 0.0130 - accuracy: 0.3721\n",
      "Epoch 18/50\n",
      "515/515 [==============================] - 2s 4ms/step - loss: 0.0128 - accuracy: 0.3763\n",
      "Epoch 19/50\n",
      "515/515 [==============================] - 2s 4ms/step - loss: 0.0125 - accuracy: 0.3740\n",
      "Epoch 20/50\n",
      "515/515 [==============================] - 2s 4ms/step - loss: 0.0125 - accuracy: 0.3764\n",
      "Epoch 21/50\n",
      "515/515 [==============================] - 2s 4ms/step - loss: 0.0122 - accuracy: 0.3868\n",
      "Epoch 22/50\n",
      "515/515 [==============================] - 2s 4ms/step - loss: 0.0121 - accuracy: 0.3852\n",
      "Epoch 23/50\n",
      "515/515 [==============================] - 2s 3ms/step - loss: 0.0119 - accuracy: 0.3805\n",
      "Epoch 24/50\n",
      "515/515 [==============================] - 2s 4ms/step - loss: 0.0118 - accuracy: 0.3781\n",
      "Epoch 25/50\n",
      "515/515 [==============================] - 2s 3ms/step - loss: 0.0117 - accuracy: 0.3811\n",
      "Epoch 26/50\n",
      "515/515 [==============================] - 2s 4ms/step - loss: 0.0117 - accuracy: 0.3808\n",
      "Epoch 27/50\n",
      "515/515 [==============================] - 2s 4ms/step - loss: 0.0117 - accuracy: 0.3875\n",
      "Epoch 28/50\n",
      "515/515 [==============================] - 2s 4ms/step - loss: 0.0112 - accuracy: 0.3929\n",
      "Epoch 29/50\n",
      "515/515 [==============================] - 2s 4ms/step - loss: 0.0112 - accuracy: 0.3954\n",
      "Epoch 30/50\n",
      "515/515 [==============================] - 2s 4ms/step - loss: 0.0113 - accuracy: 0.3954\n",
      "Epoch 31/50\n",
      "515/515 [==============================] - 2s 4ms/step - loss: 0.0112 - accuracy: 0.3968\n",
      "Epoch 32/50\n",
      "515/515 [==============================] - 2s 4ms/step - loss: 0.0112 - accuracy: 0.3964\n",
      "Epoch 33/50\n",
      "515/515 [==============================] - 2s 3ms/step - loss: 0.0110 - accuracy: 0.3950\n",
      "Epoch 34/50\n",
      "515/515 [==============================] - 2s 4ms/step - loss: 0.0109 - accuracy: 0.3953\n",
      "Epoch 35/50\n",
      "515/515 [==============================] - 2s 4ms/step - loss: 0.0108 - accuracy: 0.3899\n",
      "Epoch 36/50\n",
      "515/515 [==============================] - 2s 4ms/step - loss: 0.0108 - accuracy: 0.4016\n",
      "Epoch 37/50\n",
      "515/515 [==============================] - 2s 3ms/step - loss: 0.0109 - accuracy: 0.3942\n",
      "Epoch 38/50\n",
      "515/515 [==============================] - 2s 4ms/step - loss: 0.0106 - accuracy: 0.4088\n",
      "Epoch 39/50\n",
      "515/515 [==============================] - 2s 3ms/step - loss: 0.0109 - accuracy: 0.4056\n",
      "Epoch 40/50\n",
      "515/515 [==============================] - 2s 4ms/step - loss: 0.0106 - accuracy: 0.4156\n",
      "Epoch 41/50\n",
      "515/515 [==============================] - 2s 4ms/step - loss: 0.0106 - accuracy: 0.4078\n",
      "Epoch 42/50\n",
      "515/515 [==============================] - 2s 4ms/step - loss: 0.0105 - accuracy: 0.4183\n",
      "Epoch 43/50\n",
      "515/515 [==============================] - 2s 4ms/step - loss: 0.0106 - accuracy: 0.4075\n",
      "Epoch 44/50\n",
      "515/515 [==============================] - 2s 4ms/step - loss: 0.0106 - accuracy: 0.4189\n",
      "Epoch 45/50\n",
      "515/515 [==============================] - 2s 4ms/step - loss: 0.0104 - accuracy: 0.4181\n",
      "Epoch 46/50\n",
      "515/515 [==============================] - 2s 4ms/step - loss: 0.0104 - accuracy: 0.4135\n",
      "Epoch 47/50\n",
      "515/515 [==============================] - 2s 4ms/step - loss: 0.0105 - accuracy: 0.4189\n",
      "Epoch 48/50\n",
      "515/515 [==============================] - 2s 4ms/step - loss: 0.0103 - accuracy: 0.4170\n",
      "Epoch 49/50\n",
      "515/515 [==============================] - 2s 4ms/step - loss: 0.0103 - accuracy: 0.4235\n",
      "Epoch 50/50\n",
      "515/515 [==============================] - 2s 4ms/step - loss: 0.0102 - accuracy: 0.4184\n"
     ]
    }
   ],
   "source": [
    "#sementes\n",
    "seed(1)\n",
    "tf.random.set_seed(2)\n",
    "\n",
    "#epochs e batchsize\n",
    "epochs = 50\n",
    "batchsize = 16\n",
    "\n",
    "autoencoder.compile(optimizer=keras.optimizers.Adam(lr=0.001),\n",
    "                    loss='mse',\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "hist_autoencoder = autoencoder.fit(x_train, x_train, batch_size=batchsize, epochs=epochs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UNW0m2zvY5NY"
   },
   "outputs": [],
   "source": [
    "code_model = keras.models.Model(inputs=autoencoder.input, outputs=autoencoder.get_layer('dense_14').output)\n",
    "code_train = np.asarray(code_model.predict(x_train))\n",
    "code_test  = np.asarray(code_model.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "id": "QOUuOGRpcQaQ",
    "outputId": "ac15bf74-ed44-46c7-ca95-6e55cb85157b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.5, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=1, shrinking=True, tol=0.001,\n",
       "    verbose=False)"
      ]
     },
     "execution_count": 49,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "model = SVC(C = 0.5, random_state=1)\n",
    "model.fit(code_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "fSTHOnvhkVs5",
    "outputId": "20d914dd-f00b-4170-ead2-23725fbd8402"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9140776699029126\n"
     ]
    }
   ],
   "source": [
    "score = model.score(code_test,y_test)\n",
    "print(score)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled5.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
