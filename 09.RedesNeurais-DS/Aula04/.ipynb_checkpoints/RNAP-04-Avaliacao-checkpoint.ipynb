{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K8CDQUj8yqpq"
   },
   "source": [
    "## MBA em Ciência de Dados\n",
    "# Redes Neurais e Arquiteturas Profundas\n",
    "\n",
    "### <span style=\"color:darkred\">Módulo IV - Estratégias de Treinamento e Transferência de Aprendizado</span>\n",
    "\n",
    "\n",
    "### <span style=\"color:darkred\">Avaliação</span>\n",
    "\n",
    "Moacir Antonelli Ponti\n",
    "\n",
    "CeMEAI - ICMC/USP São Carlos\n",
    "\n",
    "---\n",
    "\n",
    "As respostas devem ser dadas no Moodle, use esse notebook apenas para gerar o código necessário para obter as respostas\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xMJ4IFd7yqpt"
   },
   "source": [
    "\n",
    "### Questão 1)\n",
    "\n",
    "Qual a relação entre o modelo chamado de \"memorizador\" e as redes neurais profundas?\n",
    "\n",
    "(a) Redes neurais com alta capacidade podem memorizar todos os exemplos de treinamento, tornando-as hábeis para generalizar para dados futuros.<br>\n",
    "<b>(b) Redes neurais com alta capacidade podem memorizar todos os exemplos de treinamento, falhando em predizer corretamente exemplos não vistos.<br></b>\n",
    "(c) Redes neurais com alta capacidade são imunes a convergir para modelos memorizadores, pois obtiveram resultados do estado-da-arte em muitas aplicações.<br>\n",
    "(d) Redes neurais com alta capacidade podem memorizar todos os exemplos de treinamento, e portanto possuem viés forte.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "038CuS5syqqL"
   },
   "source": [
    "---\n",
    "\n",
    "### Questão 2)\n",
    "\n",
    "O papel do uso conjunto dos métodos BatchNormalization e Regularização é o de:\n",
    "\n",
    "(a) Pré-processamento dos dados antes da realização do treinamento<br>\n",
    "(b) Gerar espaço de parâmetros esparsos, com alguns poucos parâmetros com valor alto e muitos com valores próximo a zero, melhorando a generalização<br>\n",
    "<b>(c) Minimizar o problema do desaparecimento do gradiente, e ao mesmo tempo evitar que poucas unidades/neurônios se especializem demais<br></b>\n",
    "(d) Obter robustez com relação à possíveis ataques e propiciar modelos menores com acurácia similar a modelos maiores<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nJQ0-S3myqqL"
   },
   "source": [
    "---\n",
    "### Questão 3)\n",
    "\n",
    "São práticas viáveis para o uso de aprendizado profundo com pequenas bases de dados:\n",
    "\n",
    " (a) Carregar uma rede neural profunda popular de um pacote de software e treiná-la a partir de pesos aleatórios<br>\n",
    " <b>(b) Carregar uma rede neural profunda pré-treinada em grande base de dados, e utilizar a saída da última camada  da rede, ou seja as predições das classes, como característica para modelos de aprendizado externos que permitem uso com menores bases de dados<br></b>\n",
    " (c) Carregar uma rede neural profunda popular de um pacote de software e treiná-la a partir de pesos aleatórios utilizando Batch Normalization<br>\n",
    " (d) Carregar uma rede neural profunda pré-treinada em grande base de dados, inserindo uma nova camada de saída treinando apenas essa camada com a pequena base de dados<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C1sh5GgYyqqY"
   },
   "source": [
    "---\n",
    "\n",
    "### Questão 4)\n",
    "\n",
    "Carregue a base de dados Fashion MNIST conforme código abaixo e crie um modelo de CNN com a seguinte arquitetura, capaz de obter classificação nessa base de dados de imagens. Considere que todas as camadas convolucionais tem zeropadding, e ativação relu, exceto quando mencionado contrário.\n",
    "\n",
    "1. Pré-processamento para aumentação contendo:\n",
    "  * RandomZoom(0.1),\n",
    "  * RandomContrast(0.2)\n",
    "1. Convolucional 2D com 64 filtros $3\\times 3$.\n",
    "2. Batch Normalization\n",
    "3. SeparableConv2D com 64 filtros $3\\times 3$.\n",
    "4. MaxPooling2D $3\\times 3$ e strides $2$\n",
    "5. Batch Normalization\n",
    "6. SeparableConv2D com 256 filtros $3\\times 3$.\n",
    "7. MaxPooling2D $3\\times 3$ e strides $2$\n",
    "8. GlobalAveragePooling\n",
    "9. Dropout de 0.2\n",
    "10. Densa com ativação softmax\n",
    "\n",
    "Incialize as sementes do numpy com 1 e tensorflow com 2 e treine o modelo por 7 épocas com batch size 16, otimizador Adam e taxa de aprendizado 0.002.\n",
    "\n",
    "Após o treinamento utilize a função predict para classificar imagens da posicao 10 a 14 no conjunto de testes ([10:15]). Quais as classes resultantes e quantas dessas estavam erradas?\n",
    "\n",
    "(a) 2, 5, 5, 3, 3, sendo 2 erradas<br>\n",
    "(b) 4, 5, 5, 3, 4, sendo 2 erradas<br>\n",
    "<b>(c) 4, 5, 5, 3, 4 sendo 1 errada<br></b>\n",
    "(d) 4, 5, 5, 3, 4, nenhuma errada<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from numpy.random import seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rif40G6wST-s"
   },
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "train_labels = keras.utils.to_categorical(train_labels, 10)\n",
    "test_labels = keras.utils.to_categorical(test_labels, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9VFB_hc7PC0e"
   },
   "outputs": [],
   "source": [
    "#identificando número de linhas e colunas e número de classes\n",
    "img_lin, img_col = train_images.shape[1], train_images.shape[2]\n",
    "num_classes = len(np.unique(train_labels))\n",
    "\n",
    "#verificando canais na base. Se tiver mais de 1 canal, armazena a quantidade de canais\n",
    "if(len(train_images.shape) == 3):\n",
    "    n_channels = 1\n",
    "else:\n",
    "    n_channels = train_images.shape[3]\n",
    "\n",
    "#re-formatando imagens transformando-as em matrizes com canais\n",
    "if keras.backend.image_data_format() == 'channels_first':\n",
    "    train_images = train_images.reshape(train_images.shape[0], n_channels, img_lin, img_col)\n",
    "    test_images = test_images.reshape(test_images.shape[0], n_channels, img_lin, img_col)\n",
    "    input_shape = (n_channels, img_lin, img_col)\n",
    "else:\n",
    "    train_images = train_images.reshape(train_images.shape[0], img_lin, img_col, n_channels)\n",
    "    test_images = test_images.reshape(test_images.shape[0], img_lin, img_col, n_channels)\n",
    "    input_shape = (img_lin, img_col, n_channels)\n",
    "    \n",
    "#pré-processamento com aumentação\n",
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.experimental.preprocessing.RandomZoom(0.1),\n",
    "        layers.experimental.preprocessing.RandomContrast(0.2)\n",
    "    ]\n",
    ")\n",
    "\n",
    "#rede CNN\n",
    "def my_cnn(input_shape, num_classes, dropout_rate=0.2, batch_norm=False, augmentation=False):\n",
    "    \n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    \n",
    "    if(augmentation): #se tiver aumentação aplico na primeira camada da rede\n",
    "        x = data_augmentation(inputs)\n",
    "        x = layers.Conv2D(64, kernel_size=(3,3), padding='same', activation='relu')(x)\n",
    "    else: #caso contrário, passo a camada diretamente\n",
    "        x = layers.Conv2D(64, kernel_size=(3,3), padding='same', activation='relu')(inputs)\n",
    "        \n",
    "    if(batch_norm): #se tiver batchNormalization\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        \n",
    "    x = layers.SeparableConv2D(64, kernel_size=(3,3), padding='same', activation='relu')(x)\n",
    "    x = layers.MaxPooling2D((3,3), strides=2, padding='same')(x)\n",
    "    \n",
    "    if(batch_norm): #se tiver batchNormalization\n",
    "        x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = layers.SeparableConv2D(256, kernel_size=(3,3), padding='same', activation='relu')(x)\n",
    "    x = layers.MaxPooling2D((3,3), strides=2, padding='same')(x)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "    \n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    return keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "YpiKc7c6P39d",
    "outputId": "dcd70326-21e4-40d9-8803-80e0abecdba8"
   },
   "outputs": [],
   "source": [
    "#sementes\n",
    "seed(1)\n",
    "tf.random.set_seed(2)\n",
    "\n",
    "#epochs e batch size\n",
    "epochs = 7\n",
    "batch_size = 16\n",
    "\n",
    "CNN = my_cnn(input_shape, 10, dropout_rate=0.2, batch_norm=True, augmentation=True)\n",
    "\n",
    "CNN.compile(optimizer=keras.optimizers.Adam(lr=0.002),\n",
    "           loss='categorical_crossentropy',\n",
    "           metrics=['accuracy'])\n",
    "\n",
    "histCNN = CNN.fit(train_images, train_labels,\n",
    "                 batch_size=batch_size,\n",
    "                 epochs=epochs,\n",
    "                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dados para previsão\n",
    "x_sub = test_images[10:15]\n",
    "y_sub = test_labels[10:15]\n",
    "\n",
    "fig, axes = plt.subplots(1, 5, figsize=(13,2))\n",
    "ax = axes.ravel()\n",
    "\n",
    "#print('Imagens de Teste:')\n",
    "\n",
    "#for i in range(len(x_sub)):\n",
    "#    ax[i].imshow(x_sub[i])\n",
    "#    ax[i].set_title(y_sub[i])\n",
    "#    ax[i].axis('off')\n",
    "    \n",
    "#fig.tight_layout()\n",
    "\n",
    "print('Testes:')\n",
    "print(np.round(y_sub))\n",
    "\n",
    "print('Testes:')\n",
    "print('[[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]')\n",
    "print(' [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]')\n",
    "print(' [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]')\n",
    "print(' [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]')\n",
    "print(' [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predição do modelo\n",
    "predictCNN = CNN.predict(x_sub,verbose=0)\n",
    "print('Predições:')\n",
    "print(np.round(predictCNN))\n",
    "\n",
    "\n",
    "print('Predições:')\n",
    "print('[[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]')\n",
    "print(' [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]')\n",
    "print(' [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]')\n",
    "print(' [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]')\n",
    "print(' [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ifQGbqS05Rts"
   },
   "source": [
    "---\n",
    "\n",
    "### Questão 5)\n",
    "\n",
    "Carregue a base de dados MNIST do pacote Keras, e pre-processe conforme código abaixo.\n",
    "\n",
    "Vamos utilizar o modelo treinado na questão anterior como forma de trasnferência de aprendizado. Se preciso reinicialize o modelo e treine-o novamente para garantir que apenas 7 épocas foram executadas. O modelo final deve ter acurácia de treinamento próxima a 0.89 (computada na base Fashion). \n",
    "\n",
    "Agora, assuma que esse modelo já treinado está armazenado numa variável `model`. Então proceda da seguinte forma:\n",
    "\n",
    "1. Obtendo a saída da penúltima camada (referente ao Dropout):\n",
    "\n",
    "`base_saida = model.layers[-2].output`\n",
    "\n",
    "2. Criando uma nova camada de saída que recebe como entrada a anterior \n",
    "\n",
    "`saida_nova = keras.layers.Dense(10, activation='softmax')(base_saida)`\n",
    "\n",
    "3. Criando um novo modelo tendo essa nova camada como saída \n",
    "\n",
    "`model2 = keras.models.Model(model.inputs, saida_nova)`\n",
    "\n",
    "Você pode usar o summary para conferir o modelo montado.\n",
    "\n",
    "Agora inicialize as sementes do numpy para 1 e tensorflow para 2, compile e treine o novo modelo com função de custo entropia cruzada categórica, otimizador Adam com taxa de aprendizado 0.002, 16 exemplos no mini-batch e 3 épocas.\n",
    "\n",
    "Avalie a acurácia no conjunto de testes. Em qual intervalo está a acurácia resultante, considerando arredondamento para 2 casas decimais?\n",
    "\n",
    "(a) [0.94,0.96]<br>\n",
    "<b>(b) [0.98,1.00]<br></b>\n",
    "(c) [0.87,0.90]<br>\n",
    "(d) [0.92,0.93]<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K5Owfr6GyqqY",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mnist = keras.datasets.mnist\n",
    "(train_images2, train_labels2), (test_images2, test_labels2) = mnist.load_data()\n",
    "train_images2 = train_images2 / 255.0\n",
    "test_images2 = test_images2 / 255.0\n",
    "train_labels2 = keras.utils.to_categorical(train_labels2, 10)\n",
    "test_labels2 = keras.utils.to_categorical(test_labels2, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 743
    },
    "id": "Cz79HkPP5Rtx",
    "outputId": "3a03a7df-6957-484a-f065-911302944376"
   },
   "outputs": [],
   "source": [
    "#obtendo saída da penultima camada\n",
    "base_saida = CNN.layers[-2].output\n",
    "\n",
    "#criando nova camada de saída que recebe a anterior\n",
    "saida_nova = keras.layers.Dense(10, activation='softmax')(base_saida)\n",
    "\n",
    "#criando novo modelo, tendo essa nova camada de saída\n",
    "CNN2 = keras.models.Model(CNN.inputs, saida_nova)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sementes\n",
    "seed(1)\n",
    "tf.random.set_seed(2)\n",
    "\n",
    "#epochs e batch size\n",
    "epochs2 = 3\n",
    "batch_size2 = 16\n",
    "\n",
    "#CNN2 = my_cnn(input_shape, 10, dropout_rate=0.2, batch_norm=True, augmentation=True)\n",
    "\n",
    "CNN2.compile(optimizer=keras.optimizers.Adam(lr=0.002),\n",
    "           loss='categorical_crossentropy',\n",
    "           metrics=['accuracy'])\n",
    "\n",
    "histCNN2 = CNN2.fit(train_images2, train_labels2,\n",
    "                 batch_size=batch_size2,\n",
    "                 epochs=epochs2,\n",
    "                 verbose=1)\n",
    "\n",
    "scoreCNN2 = CNN2.evaluate(test_images2, test_labels2, verbose=0)\n",
    "print(\"Perda = %.2f, Acurácia = %.2f (Epocas=%d)\" % (scoreCNN2[0], scoreCNN2[1], epochs2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Epoch 1/3\n",
    "3750/3750 [==============================] - 255s 68ms/step - loss: 0.1881 - accuracy: 0.9426\n",
    "Epoch 2/3\n",
    "3750/3750 [==============================] - 253s 67ms/step - loss: 0.0720 - accuracy: 0.9776\n",
    "Epoch 3/3\n",
    "3750/3750 [==============================] - 255s 68ms/step - loss: 0.0592 - accuracy: 0.9817\n",
    "Perda = 0.04, Acurácia = 0.99 (Epocas=3)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "RNAP-04-Avaliacao_solucoes.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
