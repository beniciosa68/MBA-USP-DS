{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MBA em Ciência de Dados\n",
    "# Redes Neurais e Arquiteturas Profundas\n",
    "\n",
    "### <span style=\"color:darkred\">Módulo I - Deep Learning e redes do tipo Perceptron</span>\n",
    "\n",
    "\n",
    "### <span style=\"color:darkred\">Exercícios com soluções</span>\n",
    "\n",
    "Moacir Antonelli Ponti\n",
    "\n",
    "CeMEAI - ICMC/USP São Carlos\n",
    "\n",
    "---\n",
    "\n",
    "#### <span style=\"color:red\">Recomenda-se fortemente que os exercícios sejam feitos sem consultar as respostas antecipadamente.</span>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 1)\n",
    "\n",
    "As redes neurais artificiais são uma família de métodos conhecidos por conexionistas. Assinale a alternativa mais completa que explica o porquê.\n",
    " \n",
    "<font color='red'>(a) Porque são inspirados por neurônios biológicos, que representam a informação por uma rede de unidades de processamento e o aprendizado pela força de suas conexões</font><br>\n",
    " (b) Porque apenas as redes neurais possuem uma estrutura em que há nós conectados pelos quais passam as informações<br>\n",
    " (c) Porque é possível conectar os neurônios artificiais de qualquer maneira, simulando um cérebro humano<br>\n",
    " (d) Porque são métodos de aprendizado de máquina supervisionados não-paramétricos, muito utilizados em tarefas de classificação e regressão, e que armazenam informações em nós organizados de forma hierárquica, desde sua entrada, conhecida por raiz, até a saída, chamada de folha.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Exercício 2)\n",
    "\n",
    "As redes neurais artificial passaram por um chamado \"inverno\" em que recebiam pouca atenção da academia e do mercado quando comparado aos sistemas especialistas. Porque isso mudou em meados de 2010?\n",
    "\n",
    " (a) Devido a descobertas da inteligência artificial em 2012 que revolucionou a área<br>\n",
    " <font color='red'>(b) Trabalhos científicos mostraram que a utilização de grandes bases de dados anotadas e o uso de placas gráficas permitiam treinar modelos com baixo erro de classificação</font><br>\n",
    " (c) Devido a melhoria dos sistemas computacionais, incluindo melhores processadores (CPUs), maior memória principal disponível (RAM) e placas gráficas (GPUs)<br>\n",
    " (d) Pois foi nessa época em que a área de ciência de dados tomou destaque, devido a grande quantidade de dados disponível (big data)<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Exercício 3)\n",
    "\n",
    "Seja $\\mathbf{x} \\in X$ um vetor com informações sobre perfis de clientes de um e-commerce, incluindo: data de nascimento, cidade, quantidade de pedidos realizados nos últimos 12 meses, total em reais das compras, entre outros. Desejamos obter um modelo que seja capaz de receber por entrada uma instância de $X$ e inferir a probabilidade $y$ de um cliente realizar uma compra no próximo mês. Considere duas formulações conforme abaixo:\n",
    "\n",
    "1. Modelo A: $f(\\mathbf{x}) = \\hat{y}$\n",
    "2. Modelo B: $$\\begin{align}\n",
    "g(\\mathbf{x}) &= \\mathbf{r},\\\\\n",
    "h(\\mathbf{r}) &= \\mathbf{s},\\\\\n",
    "i(\\mathbf{s}) &= \\mathbf{w},\\\\\n",
    "f(\\mathbf{w}) &= \\hat{y}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "O que podemos dizer sobre A e B?\n",
    "\n",
    "(a) A é um classificador linear e B é um regressor multi-estágio<br>\n",
    "(b) apenas B é uma formulação de aprendizado de máquina, enquanto A não pode ser considerado aprendizado de máquina<br>\n",
    "(c) A é um classificador linear como o Perceptron, enquanto B é uma rede neural profunda<br>\n",
    "<font color='red'>(d) A é uma formulação rasa, enquanto que B é uma formulação profunda para aprendizado de máquina</font><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Exercício 4)\n",
    "\n",
    "Seja $\\mathbf{x}$ um vetor de entrada e $s$ um valor de saída de um neurônio de uma rede neural baseada em Perceptron. O processamento pode ser escrito na forma:\n",
    "\n",
    "$f(\\mathbf{x}) = a(\\mathbf{w}^t\\mathbf{x}+b) = s$,\n",
    "\n",
    "sendo que $a()$ é a função de ativação. Sabendo que a entrada tem $d$ dimensões, quais são as dimensões das variáveis $w$ e $b$?\n",
    "\n",
    "<font color='red'>(a) $w$ é um vetor com $d$ dimensões, enquanto $b$ é escalar possuindo uma dimensão<br></font>\n",
    "(b) $w$ é um vetor com 2 dimensões, enquanto $b$ é escalar possuindo uma dimensão<br>\n",
    "(c) $w$ é escalar com 1 dimensão, enquanto $b$ é o vetor bias cujo número de dimensões é igual ao número de classes do problema<br>\n",
    "(d) $w$ é um vetor com $d-1$ dimensões, enquanto $b$ é bias e portanto possui apenas 1 dimensão\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Exercício 5)\n",
    "\n",
    "Seja $\\mathbf{x}$ um vetor de entrada e $\\mathbf{s}$ um vetor de saída de uma camada de rede neural baseada em Perceptron. O processamento pode ser escrito na forma:\n",
    "\n",
    "$f(\\mathbf{x}) = a(W\\mathbf{x}+\\mathbf{b}) = \\mathbf{s}$,\n",
    "\n",
    "sendo que $a()$ é a função de ativação. Sabendo que a entrada tem $d$ dimensões e a saída tem $z$ dimensões, quais são as dimensões das variáveis $W$ e $b$ e quantos neurônios possui essa camada?\n",
    "\n",
    "(a) são $d$ neurônios, sendo que $W$ possui $z \\times d$, e $b$ possui $d$ dimensões<br>\n",
    "(b) são $d \\times z$ neurônios, sendo que $W$ possui $z \\times d$, e $b$ possui $d$ dimensões<br>\n",
    "<font color='red'>(c) são $z$ neurônios, sendo que $W$ possui $z \\times d$, e $b$ possui $z$ dimensões<br></font>\n",
    "(d) são $z$ neurônios, sendo que $W$ possui $d$, e $b$ possui $z$ dimensões\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Exercício 6)\n",
    "\n",
    "Qual a diferença entre as funções de ativação *sigmoide* e *softmax* aplicadas a uma camada de uma rede neural?\n",
    "\n",
    "(a) a sigmóide produz como saída vetores cuja somatória é 1 e que podem ser interpretados como uma distribuição de probabilidade, enquanto a softmax comprime os valores da saída entre 0 e 1 <br>\n",
    "(b) a sigmóide produz como saída vetores cujos valores estão entre -1 e 1, enquanto a softmax comprime os valores da saída entre 0 e 1<br>\n",
    "<font color='red'>(c) a sigmóide comprime os valores da saída entre 0 e 1, enquanto a softmax produz como saída vetores cuja somatória é 1 e que podem ser interpretados como uma distribuição de probabilidade<br></font>\n",
    "(d) a sigmóide produz como saída vetores cujos valores individuais estão entre 0 e 1 utilizando uma função suave, enquanto a softmax produz vetores no formato one-hot-encoding compatíveis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Exercício 7)\n",
    "\n",
    "Utilizando a biblioteca Keras, formule um modelo de rede neural sequencial, do tipo MLP, cuja entrada seja preparada para receber um vetor de 100 dimensões e que possua 2 camadas ocultas, cada uma com 50 neurônios, e 1 camada de saída, com 3 neurônios e função de ativação softmax.\n",
    "\n",
    "Quantos parâmetros, no total, essa rede possui?\n",
    "\n",
    "(a) 203<br>\n",
    "(b) 10303<br>\n",
    "(c) 7651<br>\n",
    "<font color='red'>(d) 7753<br></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 7,753\n",
      "Trainable params: 7,753\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "model1 = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(50, activation=\"relu\", input_shape=(100,)),\n",
    "        keras.layers.Dense(50, activation=\"relu\"),\n",
    "        keras.layers.Dense(3, activation=\"relu\"),\n",
    "    ]\n",
    ")\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Exercício 8)\n",
    "\n",
    "Considerando que temos uma base de dados de treinamento com 8000 exemplos. Definindo o tamanho do lote (minibatch size) como sendo 50, quantas iterações o algoritmo backpropagation deverá executar, adaptando os parâmetros da rede, para completar 5 épocas?\n",
    "\n",
    "<font color='red'>(a) 800<br></font>\n",
    "(a) 160<br>\n",
    "(b) 801<br>\n",
    "(c) 250<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 8000\n",
    "batchsize = 50\n",
    "\n",
    "iteracoes_epoca = N/batchsize\n",
    "iteracoes_epoca * 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Exercício 9)\n",
    "\n",
    "Defina as sementes aleatórias do numpy para 1 e do tensorflow para 2, depois carregue a base de dados boston housing da biblioteca Keras, conforme código abaixo. \n",
    "\n",
    "O objetivo dessa base de dados é obter a regressão do preço das casas com base em 13 características de entrada. Assim, os valores alvo (target) são escalares, tipicamente entre 10 e 50 (representando os preços em milhares de dólares).\n",
    "\n",
    "Considerando o valor alvo descrito, e que você tem disponíveis as funções de ativação: sigmóide, relu, tangente hiperbólica e softmax, escolha as funções mais adequadas e monte uma arquitetura da rede com 3 camadas ocultas, todas com 32 neurônios.\n",
    "\n",
    "Como deve ficar a arquitetura da rede neural?\n",
    "\n",
    "(a) 4 camadas com 32, 32, 32 e 50 neurônios, 4202 parâmetros e função de ativação relu na camada de saída<br>\n",
    "<font color='red'>(b) 4 camadas com 32, 32, 32 e 1 neurônios, 2593 parâmetros e função de ativação relu na camada de saída<br></font>\n",
    "(b) 5 camadas com 13, 32, 32, 32 e 1 neurônios, 2414 parâmetros e função de ativação sigmóide na camada de saída<br>\n",
    "(c) 4 camadas com 32, 32, 32 e 1 neurônios, 2593 parâmetros e função de ativação sigmóide na camada de saída<br>\n",
    "\n",
    "\n",
    "**Justificativa**: como a saída precisa ser um número positivo (preços), a função de ativação relu deve ser utilizada. O uso de funções como sigmóide comprime a saída para o valor máximo 1 o que impede obter valores no intervalo exigido pela base de dados (tipicamente entre 10 e 50). Com 3 camadas ocultas cada uma de 32 neurônios e uma camada de saída com 1 neurônio para produzir o valor (preço), veja abaixo o código que confirma o número de parâmetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow.random import set_seed\n",
    "set_seed(2)\n",
    "\n",
    "from tensorflow.keras.datasets import boston_housing\n",
    "(x_train, y_train), (x_target, y_target) = boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 32)                448       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,537\n",
      "Trainable params: 1,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(32, activation=\"relu\", input_shape=(x_train.shape[1],)),\n",
    "        keras.layers.Dense(32, activation=\"relu\"),\n",
    "        keras.layers.Dense(1, activation=\"relu\"),\n",
    "    ]\n",
    ")\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Exercício 10)\n",
    "\n",
    "Utilizando a base de dados e o modelo de rede neural criado na questão anterior, compile o modelo utilizando uma função de custo de média quadrática (mse), o otimizador SGD e a taxa de aprendizado 0.01. Adicione a métrica `mae` (mean absolute error)\n",
    "\n",
    "Depois, normalize os dados (x) por meio da normalização z-score (calcule média e desvio no conjunto de treinamento apenas).\n",
    "\n",
    "Utilize os dados normalizados para treinar a rede neural por 25 épocas, com batch-size 8. \n",
    "\n",
    "Avalie o modelo treinado nos dados de teste, e reporte as posições 0 e 1 do score resultante, respectivamente relativas ao MSE e MAE calculados. Escolha a opção para a qual o intervalo se enquadre nos valores computados.\n",
    "\n",
    "<font color='red'>(a) MSE = (60,90), MAE = (4,8)<br></font>\n",
    "(b) MSE = (90,110), MAE = (10,20) <br>\n",
    "(c) MSE = (3,9), MAE = (50,100) <br>\n",
    "(d) MSE = (10,30), MAE = (6,8) <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "51/51 [==============================] - 0s 3ms/step - loss: 334.0641 - mae: 15.2494 - val_loss: 247.3618 - val_mae: 13.2049\n",
      "Epoch 2/20\n",
      "51/51 [==============================] - 0s 965us/step - loss: 160.0893 - mae: 8.7878 - val_loss: 142.0547 - val_mae: 9.3258\n",
      "Epoch 3/20\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 200.4650 - mae: 7.5299 - val_loss: 77.0997 - val_mae: 7.0073\n",
      "Epoch 4/20\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 93.5560 - mae: 6.5951 - val_loss: 92.3308 - val_mae: 6.8377\n",
      "Epoch 5/20\n",
      "51/51 [==============================] - 0s 955us/step - loss: 84.5059 - mae: 6.5111 - val_loss: 90.4973 - val_mae: 6.7482\n",
      "Epoch 6/20\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 80.5228 - mae: 6.2591 - val_loss: 80.5288 - val_mae: 6.2996\n",
      "Epoch 7/20\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 83.7971 - mae: 6.5576 - val_loss: 88.2580 - val_mae: 6.7510\n",
      "Epoch 8/20\n",
      "51/51 [==============================] - 0s 975us/step - loss: 84.0770 - mae: 6.5913 - val_loss: 88.0135 - val_mae: 6.7729\n",
      "Epoch 9/20\n",
      "51/51 [==============================] - 0s 997us/step - loss: 84.8860 - mae: 6.7145 - val_loss: 88.2327 - val_mae: 6.7527\n",
      "Epoch 10/20\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 84.8026 - mae: 6.6657 - val_loss: 88.2897 - val_mae: 6.7488\n",
      "Epoch 11/20\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 75.3431 - mae: 6.0220 - val_loss: 66.8622 - val_mae: 5.7074\n",
      "Epoch 12/20\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 81.7483 - mae: 6.5896 - val_loss: 87.8642 - val_mae: 6.8119\n",
      "Epoch 13/20\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 84.8955 - mae: 6.7533 - val_loss: 87.4497 - val_mae: 6.6733\n",
      "Epoch 14/20\n",
      "51/51 [==============================] - 0s 972us/step - loss: 72.7666 - mae: 5.8011 - val_loss: 55.9328 - val_mae: 4.6123\n",
      "Epoch 15/20\n",
      "51/51 [==============================] - 0s 877us/step - loss: 61.7811 - mae: 5.2582 - val_loss: 71.7082 - val_mae: 6.1856\n",
      "Epoch 16/20\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 52.7741 - mae: 4.8651 - val_loss: 55.1857 - val_mae: 5.0545\n",
      "Epoch 17/20\n",
      "51/51 [==============================] - 0s 961us/step - loss: 48.3681 - mae: 4.6415 - val_loss: 55.2821 - val_mae: 4.8337\n",
      "Epoch 18/20\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 47.6488 - mae: 4.5799 - val_loss: 54.3281 - val_mae: 5.1766\n",
      "Epoch 19/20\n",
      "51/51 [==============================] - 0s 970us/step - loss: 90.8173 - mae: 7.1720 - val_loss: 87.5158 - val_mae: 6.8292\n",
      "Epoch 20/20\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 84.3498 - mae: 6.6930 - val_loss: 79.0294 - val_mae: 6.2044\n"
     ]
    }
   ],
   "source": [
    "mean = x_train.mean(axis=0)\n",
    "x_train -= mean\n",
    "std = x_train.std(axis=0)\n",
    "x_train /= std\n",
    "\n",
    "x_target -= mean\n",
    "x_target /= std\n",
    "\n",
    "model2.compile(optimizer=keras.optimizers.SGD(0.01),\n",
    "              loss='mse', metrics=['mae'])\n",
    "\n",
    "history = model2.fit(\n",
    "    x_train, y_train,\n",
    "    batch_size=8,\n",
    "    epochs=20,\n",
    "    verbose=1,\n",
    "    validation_data=(x_target, y_target),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 79.0\n",
      "MAE: 6.2\n"
     ]
    }
   ],
   "source": [
    "score = model2.evaluate(x_target, y_target, verbose=0)\n",
    "print(\"MSE: %.1f\" % (score[0]))\n",
    "print(\"MAE: %.1f\" % (score[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
