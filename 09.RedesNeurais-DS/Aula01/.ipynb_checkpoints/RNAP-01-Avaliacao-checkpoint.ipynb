{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MBA em Ci√™ncia de Dados\n",
    "# Redes Neurais e Arquiteturas Profundas\n",
    "\n",
    "### <span style=\"color:darkred\">M√≥dulo I - Deep Learning e redes do tipo Perceptron</span>\n",
    "\n",
    "\n",
    "### <span style=\"color:darkred\">Avalia√ß√£o</span>\n",
    "\n",
    "Moacir Antonelli Ponti\n",
    "\n",
    "CeMEAI - ICMC/USP S√£o Carlos\n",
    "\n",
    "---\n",
    "\n",
    "**As respostas devem ser dadas no Moodle. O notebook deve ser usado apenas para codificar o necess√°rio para responder as quest√µes**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Quest√£o 1)\n",
    "\n",
    "O que diferencia m√©todos de aprendizado profundo (*deep learning*) de m√©todos de aprendizado de m√°quina considerados rasos (*shallow*)?\n",
    "\n",
    "<b>(a) Os m√©todos rasos comumente aprendem um mapeamento direto entre dados de entrada (atributos) e sa√≠da (alvo), enquanto os profundos aprendem uma sequ√™ncia de mapeamentos (ou fun√ß√µes) para m√∫ltiplos espa√ßos antes de mapear para o espa√ßo de sa√≠da alvo<br></b>\n",
    "(b) Os m√©todos rasos podem ser considerados aprendizado de m√°quina e permitem tarefas distintas como classifica√ß√£o, regress√£o, agrupamento, entre outros, enquanto os chamados profundos permitem modelar tarefas de classifica√ß√£o<br>\n",
    "(c) Os m√©todos rasos s√£o baseados em m√©todos estat√≠sticos e √°rvores de decis√£o, enquanto os de aprendizado profundo s√£o unicamente baseados em redes neurais<br>\n",
    "(d) Os m√©todos rasos trabalham apenas com dados estruturados, enquanto que os profundos funcionam com dados estruturados e n√£o estruturados.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(a) Os m√©todos rasos comumente aprendem um mapeamento direto entre dados de entrada (atributos) e sa√≠da (alvo), enquanto os profundos aprendem uma sequ√™ncia de mapeamentos (ou fun√ß√µes) para m√∫ltiplos espa√ßos antes de mapear para o espa√ßo de sa√≠da alvo\n"
     ]
    }
   ],
   "source": [
    "print('(a) Os m√©todos rasos comumente aprendem um mapeamento direto entre dados de entrada (atributos) e sa√≠da (alvo), enquanto os profundos aprendem uma sequ√™ncia de mapeamentos (ou fun√ß√µes) para m√∫ltiplos espa√ßos antes de mapear para o espa√ßo de sa√≠da alvo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Quest√£o 2)\n",
    "\n",
    "Seja $\\mathbf{z}$ um vetor de entrada e $\\mathbf{s}$ um vetor de sa√≠da de uma camada de rede neural baseada em Perceptron. Essa camada pode ser formulada como:\n",
    "\n",
    "$f(\\mathbf{z}) = a(W\\mathbf{z}+\\mathbf{b}) = \\mathbf{s}$,\n",
    "sendo que $a()$ √© a fun√ß√£o de ativa√ß√£o. \n",
    "\n",
    "Sabendo que a entrada tem $40$ dimens√µes e a sa√≠da tem $k$ dimens√µes, Qual o tamanho da matriz $W$ e do vetor $b$ e quantos par√¢metros essa camada possui para serem aprendidos durante o treinamento?\n",
    "\n",
    "\n",
    "(a) $W$ possui $40 \\times k$, e $b$ possui $40$ dimens√µes, totalizando $40k + 40$ par√¢metros<br>\n",
    "<b>(b) $W$ possui $k \\times 40$, e $b$ possui $k$ dimens√µes, totalizando $41k$ par√¢metros<br></b>\n",
    "(c) $W$ possui $k \\times 40$, e $b$ possui 1 dimens√£o (escalar), totalizando $40k + 1$ par√¢metros<br>\n",
    "(d) $W$ possui $k \\times k$, e $b$ possui 40 dimens√µes, totalizando $2k + 40$ par√¢metros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(b)  ùëä  possui  ùëò√ó40 , e  ùëè  possui  ùëò  dimens√µes, totalizando  41ùëò  par√¢metros\n"
     ]
    }
   ],
   "source": [
    "#entrada = 40 dimens√µes\n",
    "#sa√≠da = k \n",
    "\n",
    "#W = k * 40\n",
    "#b = k\n",
    "\n",
    "print('(b)  ùëä  possui  ùëò√ó40 , e  ùëè  possui  ùëò  dimens√µes, totalizando  41ùëò  par√¢metros')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Quest√£o 3)\n",
    "\n",
    "Qual o impacto do tamanho do batch (lote) no treinamento por meio do Stochastic Gradient Descent (SGD)?\n",
    "\n",
    "<b>(a) O tamanho do batch impacta na quantidade de √©pocas necess√°rias para completar o treinamento, se o tamanho do batch for grande, apenas uma √©poca √© necess√°ria<br></b>\n",
    "(b) Quanto menor o tamanho do batch, mais r√°pido o treinamento, pois assim o SGD se aproxima do Gradient Descent convencional j√° que utiliza cada exemplo individualmente para adaptar os pesos<br>\n",
    "(c) Quanto menor o tamanho do batch melhor ser√° a acur√°cia do modelo pois as estimativas do gradiente ser√£o mais precisas considerando cada itera√ß√£o<br>\n",
    "(d) Quanto menor o tamanho do batch, mais r√°pida cada itera√ß√£o do treinamento, por√©m mais grosseira √© a estimativa do gradiente por itera√ß√£o<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(a) O tamanho do batch impacta na quantidade de √©pocas necess√°rias para completar o treinamento, se o tamanho do batch for grande, apenas uma √©poca √© necess√°ria\n"
     ]
    }
   ],
   "source": [
    "print('(a) O tamanho do batch impacta na quantidade de √©pocas necess√°rias para completar o treinamento, se o tamanho do batch for grande, apenas uma √©poca √© necess√°ria')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Quest√£o 4)\n",
    "\n",
    "Defina as sementes aleat√≥rias do numpy para 1 e do tensorflow para 2, depois carregue a base de dados boston housing da biblioteca Keras, conforme c√≥digo abaixo. \n",
    "\n",
    "O objetivo dessa base de dados √© obter a regress√£o do pre√ßo das casas com base em 13 caracter√≠sticas de entrada. Assim, os valores alvo (target) s√£o escalares, tipicamente entre 10 e 50 (representando os pre√ßos em milhares de d√≥lares).\n",
    "\n",
    "Utilizando a biblioteca Keras, formule um modelo de rede neural sequencial, do tipo MLP, com 3 camadas ocultas contendo, respectivamente, e, na ordem, 32, 16 e 8 neur√¥nios, todas com fun√ß√£o de ativa√ß√£o do tipo `relu`.\n",
    "\n",
    "Quantos par√¢metros, no total, essa rede possui?\n",
    "\n",
    "(a) 4096<br>\n",
    "<b>(b) 1121<br></b>\n",
    "(c) 53248<br>\n",
    "(d) 3031<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow.random import set_seed\n",
    "set_seed(2)\n",
    "\n",
    "from tensorflow.keras.datasets import boston_housing\n",
    "(x_train, y_train), (x_target, y_target) = boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modelo perceptron com 3 camadas internas\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(32,activation='relu',input_shape=(x_train.shape[1],)),\n",
    "        keras.layers.Dense(16,activation='relu'),\n",
    "        keras.layers.Dense(8,activation='relu'),\n",
    "        keras.layers.Dense(1,activation='relu'),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 32)                448       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 1,121\n",
      "Trainable params: 1,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Quest√£o 5)\n",
    "\n",
    "Utilizando a base de dados e o modelo de rede neural criado na quest√£o anterior, compile o modelo utilizando uma fun√ß√£o de custo `mae` (mean absolute error), o otimizador SGD e a taxa de aprendizado 0.01. \n",
    "\n",
    "Adicione tamb√©m a m√©trica `mse` (mean squared error) para permitir avali√°-la adicionalmente.\n",
    "\n",
    "Normalize os dados (x) por meio da normaliza√ß√£o z-score (calcule m√©dia e desvio no conjunto de treinamento apenas).\n",
    "\n",
    "Utilize os dados normalizados para treinar a rede neural por 15 √©pocas, com batch-size 4. \n",
    "\n",
    "Avalie o modelo treinado nos dados de teste, e reporte as posi√ß√µes 0 e 1 do score resultante, respectivamente relativas ao MAE e MSE calculados. Escolha a op√ß√£o para a qual o intervalo se enquadre nos valores computados.\n",
    "\n",
    "(a) MAE = (50,53), MSE = (18,22) <br>\n",
    "(b) MAE = (6,12), MSE = (25,15) <br>\n",
    "(c) MAE = (4,8), MSE = (60,80) <br>\n",
    "<b>(d) MAE = (1,5), MSE = (15,25)<br></b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "101/101 - 1s - loss: 2.4812 - mse: 13.3247 - val_loss: 2.9941 - val_mse: 20.4800\n",
      "Epoch 2/15\n",
      "101/101 - 0s - loss: 2.5595 - mse: 13.8206 - val_loss: 2.8041 - val_mse: 23.2002\n",
      "Epoch 3/15\n",
      "101/101 - 0s - loss: 2.3728 - mse: 11.0215 - val_loss: 3.6314 - val_mse: 37.9799\n",
      "Epoch 4/15\n",
      "101/101 - 0s - loss: 2.5296 - mse: 13.6031 - val_loss: 2.9779 - val_mse: 21.8714\n",
      "Epoch 5/15\n",
      "101/101 - 0s - loss: 2.4601 - mse: 12.1412 - val_loss: 3.4813 - val_mse: 33.3591\n",
      "Epoch 6/15\n",
      "101/101 - 0s - loss: 2.3929 - mse: 12.0569 - val_loss: 3.4795 - val_mse: 28.5983\n",
      "Epoch 7/15\n",
      "101/101 - 0s - loss: 2.3841 - mse: 12.3761 - val_loss: 2.4875 - val_mse: 16.0777\n",
      "Epoch 8/15\n",
      "101/101 - 0s - loss: 2.5565 - mse: 12.5199 - val_loss: 4.1102 - val_mse: 34.7347\n",
      "Epoch 9/15\n",
      "101/101 - 0s - loss: 2.4024 - mse: 12.0609 - val_loss: 2.7534 - val_mse: 18.0267\n",
      "Epoch 10/15\n",
      "101/101 - 0s - loss: 2.4419 - mse: 12.0935 - val_loss: 2.6813 - val_mse: 20.9256\n",
      "Epoch 11/15\n",
      "101/101 - 0s - loss: 2.2884 - mse: 11.0188 - val_loss: 4.0100 - val_mse: 29.9883\n",
      "Epoch 12/15\n",
      "101/101 - 0s - loss: 2.3714 - mse: 12.1644 - val_loss: 3.5150 - val_mse: 25.6639\n",
      "Epoch 13/15\n",
      "101/101 - 0s - loss: 2.3130 - mse: 11.3417 - val_loss: 3.4174 - val_mse: 23.7603\n",
      "Epoch 14/15\n",
      "101/101 - 0s - loss: 2.2778 - mse: 10.9369 - val_loss: 3.5260 - val_mse: 25.8102\n",
      "Epoch 15/15\n",
      "101/101 - 0s - loss: 2.2408 - mse: 10.7908 - val_loss: 2.6265 - val_mse: 16.3823\n"
     ]
    }
   ],
   "source": [
    "#normaliza√ß√£o z-score\n",
    "mean = x_train.mean(axis=0)\n",
    "std = x_train.std(axis=0)\n",
    "\n",
    "#aplicando  para treino\n",
    "x_train -= mean\n",
    "x_train /= std\n",
    "\n",
    "#aplicando para teste\n",
    "x_target -= mean\n",
    "x_target /= std\n",
    "\n",
    "#compilando o modelo\n",
    "model.compile(optimizer=keras.optimizers.SGD(0.01),loss='mae',metrics=['mse'])\n",
    "\n",
    "#fitando o modelo\n",
    "model.fit(x_train, y_train, batch_size=4,epochs=15,verbose=2,validation_data=(x_target,y_target),)\n",
    "\n",
    "#avaliando o modelo\n",
    "score = model.evaluate(x_target, y_target, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 2.626547336578369\n",
      "MSE: 16.382349014282227\n"
     ]
    }
   ],
   "source": [
    "print('MAE:',score[0])\n",
    "print('MSE:',score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(d) MAE = (1,5), MSE = (15,25)\n"
     ]
    }
   ],
   "source": [
    "print('(d) MAE = (1,5), MSE = (15,25)')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
