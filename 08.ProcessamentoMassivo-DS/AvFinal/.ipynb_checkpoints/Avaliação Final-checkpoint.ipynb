{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "flekT6GFDN6m"
   },
   "source": [
    "# <span style=\"color:blue\">MBA em Ciência de Dados</span>\n",
    "# <span style=\"color:blue\">Análise de Dados com Base em Processamento Massivo em Paralelo</span>\n",
    "\n",
    "## <span style=\"color:blue\">Avaliação Final</span>\n",
    "\n",
    "**Material Produzido por:**<br>\n",
    ">**Profa. Dra. Cristina Dutra de Aguiar Ciferri**<br>\n",
    ">**André Perez**<br> \n",
    ">**Guilherme Muzzi da Rocha**<br> \n",
    ">**Jadson José Monteiro Oliveira**<br>\n",
    ">**João Pedro de Carvalho Castro**<br> \n",
    ">**Leonardo Mauro Pereira Moraes**<br> \n",
    ">**Piero Lima Capelo**<br>\n",
    "\n",
    "\n",
    "**CEMEAI - ICMC/USP São Carlos**\n",
    "\n",
    "**A avaliação final contém 7 questões, as quais estão espalhadas ao longo do texto. Por favor, procurem por Questão para encontrar a especificação das questões. Também é possível localizar as questões utilizando o menu de navegação. O *notebook* contém a constelação de fatos da BI Solutions que deve ser utilizada para responder às questões e também toda a obtenção dos dados e a respectiva geração dos DataFrames e das visões temporárias.** \n",
    "\n",
    "**Desejamos uma boa avaliação!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3o3dN_WLQcyD"
   },
   "source": [
    "#1 Constelação de Fatos da BI Solutions\n",
    "\n",
    "A aplicação de *data warehousing* da BI Solutions utiliza como base uma contelação de fatos, conforme descrita a seguir.\n",
    "\n",
    "**Tabelas de dimensão**\n",
    "\n",
    "- data (dataPK, dataCompleta, dataDia, dataMes, dataBimestre, dataTrimestre, dataSemestre, dataAno)\n",
    "- funcionario (funcPK, funcMatricula, funcNome, funcSexo, funcDataNascimento, funcDiaNascimento, funcMesNascimento, funcAnoNascimento, funcCidade, funcEstadoNome, funcEstadoSigla, funcRegiaoNome, funcRegiaoSigla, funcPaisNome, funcPaisSigla)\n",
    "- equipe (equipePK, equipeNome, filialNome, filialCidade, filialEstadoNome, filialEstadoSigla, filialRegiaoNome, filialRegiaoSigla, filialPaisNome, filialPaisSigla)\n",
    "- cargo (cargoPK, cargoNome, cargoRegimeTrabalho, cargoEscolaridadeMinima, cargoNivel)\n",
    "- cliente (clientePK, clienteNomeFantasia, clienteSetor, clienteCidade, clienteEstadoNome, clienteEstadoSigla, clienteRegiaoNome, clienteRegiaoSigla, clientePaisNome, clientePaisSigla)\n",
    "\n",
    "**Tabelas de fatos**\n",
    "- pagamento (dataPK, funcPK, equipePK, cargoPK, salario, quantidadeLancamentos)\n",
    "- negociacao (dataPK, equipePK, clientePK, receita, quantidadeNegociacoes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BGeh8KdXwVCQ"
   },
   "source": [
    "#2 Obtenção dos Dados da BI Solutions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CCCNC64AzBG0"
   },
   "source": [
    "## 2.1 Baixando o Módulo wget\n",
    "\n",
    "Para baixar os dados referentes ao esquema relacional da constelação de fatos da BI Solutions, é utilizado o módulo  **wget**. O comando a seguir realiza a instalação desse módulo. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "3e0Eao1K0EYG"
   },
   "outputs": [],
   "source": [
    "#comentado, pois a instalação já foi realizada\n",
    "\n",
    "#instalando o módulo wget\n",
    "\n",
    "#%%capture\n",
    "#!pip install -q wget\n",
    "#!mkdir data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j56pVJ2hZ2i5"
   },
   "source": [
    "## 2.2 Obtenção dos Dados das Tabelas de Dimensão\n",
    "\n",
    "Os comandos a seguir baixam os dados que povoam as tabelas de dimensão. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "both",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "46QzTpLJwfkW",
    "outputId": "0fc40ddf-6989-44b7-e033-1ee63d6db1ce"
   },
   "outputs": [],
   "source": [
    "#comentado, pois banco já foi baixado\n",
    "\n",
    "#baixando os dados das tabelas de dimensão\n",
    "\n",
    "#import wget\n",
    "\n",
    "#url = \"https://raw.githubusercontent.com/GuiMuzziUSP/Data_Mart_BI_Solutions/main/data.csv\"\n",
    "#wget.download(url, \"data/data.csv\")\n",
    "\n",
    "#url = \"https://raw.githubusercontent.com/GuiMuzziUSP/Data_Mart_BI_Solutions/main/funcionario.csv\"\n",
    "#wget.download(url, \"data/funcionario.csv\")\n",
    "\n",
    "#url = \"https://raw.githubusercontent.com/GuiMuzziUSP/Data_Mart_BI_Solutions/main/equipe.csv\"\n",
    "#wget.download(url, \"data/equipe.csv\")\n",
    "\n",
    "#url = \"https://raw.githubusercontent.com/GuiMuzziUSP/Data_Mart_BI_Solutions/main/cargo.csv\"\n",
    "#wget.download(url, \"data/cargo.csv\")\n",
    "\n",
    "#url = \"https://raw.githubusercontent.com/GuiMuzziUSP/Data_Mart_BI_Solutions/main/cliente.csv\"\n",
    "#wget.download(url, \"data/cliente.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0o-dC7feszRc"
   },
   "source": [
    "## 2.3 Obtenção dos Dados Tabelas de Fatos\n",
    "\n",
    "Os comandos a seguir baixam os dados que povoam as tabelas de fatos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "XWM-CUFgBl_8",
    "outputId": "575ff48d-5284-4aeb-ff8b-f4766b2691ea"
   },
   "outputs": [],
   "source": [
    "#comentado, pois banco já foi baixado\n",
    "\n",
    "#baixando os dados das tabelas de fatos\n",
    "#url = \"https://raw.githubusercontent.com/GuiMuzziUSP/Data_Mart_BI_Solutions/main/pagamento.csv\"\n",
    "#wget.download(url, \"data/pagamento.csv\")\n",
    "\n",
    "#url = \"https://raw.githubusercontent.com/GuiMuzziUSP/Data_Mart_BI_Solutions/main/negociacao.csv\"\n",
    "#wget.download(url, \"data/negociacao.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sO16-7-jOioq"
   },
   "source": [
    "# 3 Apache Spark Cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YVEgY9qKflBV"
   },
   "source": [
    "## 3.1 Instalação\n",
    "\n",
    "Neste *notebook* é criado um *cluster* Spark composto apenas por um **nó mestre**. Ou seja, o *cluster* não possui um ou mais **nós de trabalho** e o **gerenciador de cluster**. Nessa configuração, as tarefas (*tasks*) são realizadas no próprio *driver* localizado no **nó mestre**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KaM-OnIjgLS2"
   },
   "source": [
    "Para que o cluster possa ser criado, primeiramente é instalado o Java Runtime Environment (JRE) versão 8. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "NXls3bfoglKW"
   },
   "outputs": [],
   "source": [
    "#comentado, pois instalação já foi realizada\n",
    "\n",
    "\n",
    "#instalando Java Runtime Environment (JRE) versão 8\n",
    "#%%capture\n",
    "#!apt-get remove openjdk*\n",
    "#!apt-get update --fix-missing\n",
    "#!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7BQzZfDYhb4j"
   },
   "source": [
    "Na sequência, é feito o *download* do Apache Spark versão 3.0.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "8a_Yv59zg3gm"
   },
   "outputs": [],
   "source": [
    "#comentado, pois instalação já foi realizada\n",
    "\n",
    "\n",
    "#baixando Apache Spark versão 3.0.0\n",
    "#%%capture\n",
    "#!wget -q https://archive.apache.org/dist/spark/spark-3.0.0/spark-3.0.0-bin-hadoop2.7.tgz\n",
    "#!tar xf spark-3.0.0-bin-hadoop2.7.tgz && rm spark-3.0.0-bin-hadoop2.7.tgz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RETWX6wqhkLf"
   },
   "source": [
    "Na sequência, são configuradas as variáveis de ambiente JAVA_HOME e SPARK_HOME. Isto permite que tanto o Java quanto o Spark possam ser encontrados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "iZpR7NwOh2EB"
   },
   "outputs": [],
   "source": [
    "#import os\n",
    "#configurando a variável de ambiente JAVA_HOME\n",
    "#os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "#configurando a variável de ambiente SPARK_HOME\n",
    "#os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.0-bin-hadoop2.7\"\n",
    "\n",
    "import os \n",
    "\n",
    "#import modificado para ambiente windows\n",
    "os.environ['SPARK_HOME'] = 'D:\\\\Program\\\\spark-3.0.0-bin-hadoop2.7'\n",
    "os.environ['PYSPARK_DRIVER_PYTHON_OPTS']='notebook'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ql0z7Ro1iHQb"
   },
   "source": [
    "Por fim, são instalados dois pacotes da linguagem de programação Python, cujas funcionalidades são descritas a seguir.\n",
    "\n",
    "> **Pacote findspark:** Usado para ler a variável de ambiente SPARK_HOME e armazenar seu valor na variável dinâmica de ambiente PYTHONPATH. Como resultado, Python pode encontrar a instalação do Spark. \n",
    "\n",
    "> **Pacote pyspark:** PySpark é a API do Python para Spark. Ela possibilita o uso de Python, considerando que o *framework* Apache Spark encontra-se desenvolvido na linguagem de programação Scala. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "5oSYOwKljPf5"
   },
   "outputs": [],
   "source": [
    "#comentado, pois instalação já foi realizada\n",
    "\n",
    "#%%capture\n",
    "#instalando o pacote findspark\n",
    "#!pip install -q findspark==1.4.2\n",
    "#instalando o pacote pyspark\n",
    "#!pip install -q pyspark==3.0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eAaLyjPzmIwZ"
   },
   "source": [
    "## 3.2 Conexão\n",
    "\n",
    "PySpark não é adicionado ao *sys.path* por padrão. Isso significa que não é possível importá-lo, pois o interpretador da linguagem Python não sabe onde encontrá-lo. \n",
    "\n",
    "Para resolver esse aspecto, é necessário instalar o módulo `findspark`. Esse módulo mostra onde PySpark está localizado. Os comandos a seguir têm essa finalidade.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "-zm1pBTEmjp4"
   },
   "outputs": [],
   "source": [
    "#importando o módulo findspark\n",
    "import findspark\n",
    "#carregando a variávels SPARK_HOME na variável dinâmica PYTHONPATH\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZDqfefF7YUab"
   },
   "source": [
    "Depois de configurados os pacotes e módulos e inicializadas as variáveis de ambiente, é possível iniciar o uso do Spark na aplicação de `data warehousing`. Para tanto, é necessário importar o comando `SparkSession` do módulo `pyspark.sql`. São utilizados os seguintes conceitos: <br>\n",
    "\n",
    "- `SparkSession`: permite a criação de `DataFrames`. Como resultado, as tabelas relacionais podem ser manipuladas por meio de `DataFrames` e é possível realizar consultas OLAP por meio de comandos SQL. <br>\n",
    "- `builder`: cria uma instância de SparkSession. <br>\n",
    "- `appName`: define um nome para a aplicação, o qual pode ser visto na interface de usuário web do Spark. <br> \n",
    "- `master`: define onde está o nó mestre do *cluster*. Como a aplicação é executada localmente e não em um *cluster*, indica-se isso pela *string* `local` seguida do parâmetro `[*]`. Ou seja, define-se que apenas núcleos locais são utilizados. \n",
    "- `getOrCreate`: cria uma SparkSession. Caso ela já exista, retorna a instância existente. \n",
    "\n",
    "\n",
    "**Observação**: A lista completa de todos os parâmetros que podem ser utilizados na inicialização do *cluster* pode ser encontrada neste [link](https://spark.apache.org/docs/latest/spark-standalone.html#cluster-launch-scripts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "9TxljJ_cwBCy"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "#estava tomando erro no JAVA_HOME que não estava configurado. \n",
    "#Dê preferencia para instalar em um local sem espaço em branco no nome do diretório em ambiente windows.\n",
    "spark = SparkSession.builder.appName(\"pyspark-notebook\").master(\"local[*]\").getOrCreate() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5qL9SiR_pQE2"
   },
   "source": [
    "# 4 Geração dos DataFrames em Spark da BI Solutions\n",
    "\n",
    "Um `DataFrame` em Spark é equivalente a uma tabela relacional. Portanto, um `DataFrame` possui um esquema, uma ou mais linhas (ou tuplas) e uma ou mais colunas (ou atributos).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DRVoz-SGt87W"
   },
   "source": [
    "## 4.1 Criação dos DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cellView": "both",
    "id": "FNR-3dV6oYk4"
   },
   "outputs": [],
   "source": [
    "#criando os DataFrames em Spark \n",
    "cargo = spark.read.csv(path=\"data/cargo.csv\", header=True, sep=\",\")\n",
    "cliente = spark.read.csv(path=\"data/cliente.csv\", header=True, sep=\",\")\n",
    "data = spark.read.csv(path=\"data/data.csv\", header=True, sep=\",\")\n",
    "equipe = spark.read.csv(path=\"data/equipe.csv\", header=True, sep=\",\")\n",
    "funcionario = spark.read.csv(path=\"data/funcionario.csv\", header=True, sep=\",\")\n",
    "negociacao = spark.read.csv(path=\"data/negociacao.csv\", header=True, sep=\",\")\n",
    "pagamento = spark.read.csv(path=\"data/pagamento.csv\", header=True, sep=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mrch9vLgjl_H"
   },
   "source": [
    "## 4.2 Atualização dos Tipos de Dados "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9A_ot2pOjsWB"
   },
   "source": [
    "Nos comandos a seguir, primeiro são identificados quais colunas de quais `DataFrames` devem ser do tipo de dado inteiro. Na sequência, ocorre a conversão. Por fim, são exibidos os esquemas dos `DataFrames`, possibilitando visualizar a mudança de tipo de dados das colunas especificadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "jmCV6Mur__z6"
   },
   "outputs": [],
   "source": [
    "# identificando quais colunas de quais DataFrames devem ser do tipo de dado inteiro\n",
    "colunas_cargo = [\"cargoPK\"]\n",
    "colunas_cliente = [\"clientePK\"]\n",
    "colunas_data = [\"dataPk\", \"dataDia\", \"dataMes\", \"dataBimestre\", \"dataTrimestre\", \"dataSemestre\", \"dataAno\"]\n",
    "colunas_equipe = [\"equipePK\"]\n",
    "colunas_funcionario = [\"funcPK\", \"funcDiaNascimento\", \"funcMesNascimento\", \"funcAnoNascimento\"]\n",
    "colunas_negociacao = [\"equipePK\", \"clientePK\", \"dataPK\", \"quantidadeNegociacoes\"]\n",
    "colunas_pagamento = [\"funcPK\", \"equipePK\", \"dataPK\", \"cargoPK\", \"quantidadeLancamentos\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "yPNnDJcG9R5H"
   },
   "outputs": [],
   "source": [
    "# importando o tipo de dado desejado\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "\n",
    "# atualizando o tipo de dado das colunas especificadas \n",
    "# substituindo as colunas já existentes \n",
    "\n",
    "for coluna in colunas_cargo:\n",
    "  cargo = cargo.withColumn(coluna, cargo[coluna].cast(IntegerType()))\n",
    "\n",
    "for coluna in colunas_cliente:\n",
    "  cliente = cliente.withColumn(coluna, cliente[coluna].cast(IntegerType()))\n",
    "\n",
    "for coluna in colunas_data:\n",
    "  data = data.withColumn(coluna, data[coluna].cast(IntegerType()))\n",
    "\n",
    "for coluna in colunas_equipe:\n",
    "  equipe = equipe.withColumn(coluna, equipe[coluna].cast(IntegerType()))\n",
    "\n",
    "for coluna in colunas_funcionario:\n",
    "  funcionario = funcionario.withColumn(coluna, funcionario[coluna].cast(IntegerType()))\n",
    "\n",
    "for coluna in colunas_negociacao:\n",
    "  negociacao = negociacao.withColumn(coluna, negociacao[coluna].cast(IntegerType()))\n",
    "\n",
    "for coluna in colunas_pagamento:\n",
    "  pagamento = pagamento.withColumn(coluna, pagamento[coluna].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J0dX_7U_AzIY"
   },
   "source": [
    "Nos comandos a seguir, primeiro são identificados quais colunas de quais `DataFrames` devem ser do tipo de dado número de ponto flutuante. Na sequência, ocorre a conversão. Por fim, são exibidos os esquemas dos `DataFrames`, possibilitando visualizar a mudança de tipo de dados das colunas especificadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "RBcQ7Ep7AWqN"
   },
   "outputs": [],
   "source": [
    "# identificando quais colunas de quais DataFrames devem ser do tipo de dado número de ponto flutuante\n",
    "colunas_negociacao = [\"receita\"]\n",
    "colunas_pagamento = [\"salario\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "rcfvkIK1BRSp"
   },
   "outputs": [],
   "source": [
    "# importando o tipo de dado desejado\n",
    "from pyspark.sql.types import FloatType\n",
    "\n",
    "\n",
    "# atualizando o tipo de dado das colunas especificadas \n",
    "# substituindo as colunas já existentes \n",
    "\n",
    "for coluna in colunas_negociacao:\n",
    "  negociacao = negociacao.withColumn(coluna, negociacao[coluna].cast(FloatType()))\n",
    "\n",
    "for coluna in colunas_pagamento:\n",
    "  pagamento = pagamento.withColumn(coluna, pagamento[coluna].cast(FloatType()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9wN5iOGKwnHG"
   },
   "source": [
    "## 4.3 Criação de Visões Temporárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "xJsqRI3TwsjS"
   },
   "outputs": [],
   "source": [
    "#criando as visões temporárias \n",
    "cargo.createOrReplaceTempView(\"cargo\")\n",
    "cliente.createOrReplaceTempView(\"cliente\")\n",
    "data.createOrReplaceTempView(\"data\")\n",
    "equipe.createOrReplaceTempView(\"equipe\")\n",
    "funcionario.createOrReplaceTempView(\"funcionario\")\n",
    "negociacao.createOrReplaceTempView(\"negociacao\")\n",
    "pagamento.createOrReplaceTempView(\"pagamento\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+-------------------+--------------------+-----------------------+----------+\n",
      "|cargoPK|           cargoNome|cargoRegimeTrabalho|cargoJornadaTrabalho|cargoEscolaridadeMinima|cargoNivel|\n",
      "+-------+--------------------+-------------------+--------------------+-----------------------+----------+\n",
      "|      1|PROGRAMADOR DE SI...|         TEMPORARIO|                 20H|                  MEDIO|    JUNIOR|\n",
      "|      2|PROGRAMADOR DE SI...|         TEMPORARIO|                 20H|               SUPERIOR|     PLENO|\n",
      "|      3|PROGRAMADOR DE SI...|         TEMPORARIO|                 20H|                    POS|    SENIOR|\n",
      "|      4|PROGRAMADOR DE SI...|         TEMPORARIO|                 40H|                  MEDIO|    JUNIOR|\n",
      "|      5|PROGRAMADOR DE SI...|         TEMPORARIO|                 40H|               SUPERIOR|     PLENO|\n",
      "+-------+--------------------+-------------------+--------------------+-----------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#visualizando um exemplo com 5 linhas do df para facilitar na criação das queries, conhecendo melhor a estrutura de dados\n",
    "cargo.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------------+-------------------+-------------+-----------------+------------------+-----------------+------------------+---------------+----------------+\n",
      "|clientePK|clienteNomeFantasia|       clienteSetor|clienteCidade|clienteEstadoNome|clienteEstadoSigla|clienteRegiaoNome|clienteRegiaoSigla|clientePaisNome|clientePaisSigla|\n",
      "+---------+-------------------+-------------------+-------------+-----------------+------------------+-----------------+------------------+---------------+----------------+\n",
      "|        1|           VIA FOOD|BEBIDAS E ALIMENTOS|    SAO PAULO|        SAO PAULO|                SP|          SUDESTE|                SE|         BRASIL|              BR|\n",
      "|        2|          VIA PIZZA|BEBIDAS E ALIMENTOS|    SAO PAULO|        SAO PAULO|                SP|          SUDESTE|                SE|         BRASIL|              BR|\n",
      "|        3|           VIA JAPA|BEBIDAS E ALIMENTOS|    SAO PAULO|        SAO PAULO|                SP|          SUDESTE|                SE|         BRASIL|              BR|\n",
      "|        4|            VIA VEG|BEBIDAS E ALIMENTOS|    SAO PAULO|        SAO PAULO|                SP|          SUDESTE|                SE|         BRASIL|              BR|\n",
      "|        5|          VIA DRINK|BEBIDAS E ALIMENTOS|   SAO CARLOS|        SAO PAULO|                SP|          SUDESTE|                SE|         BRASIL|              BR|\n",
      "+---------+-------------------+-------------------+-------------+-----------------+------------------+-----------------+------------------+---------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#visualizando um exemplo com 5 linhas do df para facilitar na criação das queries, conhecendo melhor a estrutura de dados\n",
    "cliente.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------+-------+-------+------------+-------------+------------+-------+\n",
      "|dataPk|dataCompleta|dataDia|dataMes|dataBimestre|dataTrimestre|dataSemestre|dataAno|\n",
      "+------+------------+-------+-------+------------+-------------+------------+-------+\n",
      "|     1|    1/1/2016|      1|      1|           1|            1|           1|   2016|\n",
      "|     2|    2/1/2016|      2|      1|           1|            1|           1|   2016|\n",
      "|     3|    3/1/2016|      3|      1|           1|            1|           1|   2016|\n",
      "|     4|    4/1/2016|      4|      1|           1|            1|           1|   2016|\n",
      "|     5|    5/1/2016|      5|      1|           1|            1|           1|   2016|\n",
      "+------+------------+-------+-------+------------+-------------+------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#visualizando um exemplo com 5 linhas do df para facilitar na criação das queries, conhecendo melhor a estrutura de dados\n",
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------+--------------------+--------------+------------------+-----------------+----------------+-----------------+--------------+---------------+\n",
      "|equipePK|   equipeNome|          filialNome|  filialCidade|  filialEstadoNome|filialEstadoSigla|filialRegiaoNome|filialRegiaoSigla|filialPaisNome|filialPaisSigla|\n",
      "+--------+-------------+--------------------+--------------+------------------+-----------------+----------------+-----------------+--------------+---------------+\n",
      "|       1|APP - DESKTOP|SAO PAULO - AV. P...|     SAO PAULO|         SAO PAULO|               SP|         SUDESTE|               SE|        BRASIL|             BR|\n",
      "|       2|APP - DESKTOP|RIO DE JANEIRO - ...|RIO DE JANEIRO|    RIO DE JANEIRO|               RJ|         SUDESTE|               SE|        BRASIL|             BR|\n",
      "|       3|          WEB|SAO PAULO - AV. P...|     SAO PAULO|         SAO PAULO|               SP|         SUDESTE|               SE|        BRASIL|             BR|\n",
      "|       4|          WEB|RIO DE JANEIRO - ...|RIO DE JANEIRO|    RIO DE JANEIRO|               RJ|         SUDESTE|               SE|        BRASIL|             BR|\n",
      "|       5|          WEB|CAMPO GRANDE - CE...|  CAMPO GRANDE|MATO GROSSO DO SUL|               MS|    CENTRO-OESTE|               CO|        BRASIL|             BR|\n",
      "+--------+-------------+--------------------+--------------+------------------+-----------------+----------------+-----------------+--------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#visualizando um exemplo com 5 linhas do df para facilitar na criação das queries, conhecendo melhor a estrutura de dados\n",
    "equipe.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------+-------------+--------+------------------+-----------------+-----------------+-----------------+-----------+--------------+---------------+--------------+---------------+------------+-------------+\n",
      "|funcPK|funcMatricula|     funcNome|funcSexo|funcDataNascimento|funcDiaNascimento|funcMesNascimento|funcAnoNascimento| funcCidade|funcEstadoNome|funcEstadoSigla|funcRegiaoNome|funcRegiaoSigla|funcPaisNome|funcPaisSigla|\n",
      "+------+-------------+-------------+--------+------------------+-----------------+-----------------+-----------------+-----------+--------------+---------------+--------------+---------------+------------+-------------+\n",
      "|     1|          M-1|ALINE ALMEIDA|       F|          1/1/1990|                1|                1|             1990|  SAO PAULO|     SAO PAULO|             SP|       SUDESTE|             SE|      BRASIL|           BR|\n",
      "|     2|          M-2|   ARAO ALVES|       M|          2/2/1990|                2|                2|             1990|   CAMPINAS|     SAO PAULO|             SP|       SUDESTE|             SE|      BRASIL|           BR|\n",
      "|     3|          M-3| ARON ANDRADE|       M|          3/3/1990|                3|                3|             1990|     SANTOS|     SAO PAULO|             SP|       SUDESTE|             SE|      BRASIL|           BR|\n",
      "|     4|          M-4|  ADA BARBOSA|       F|          4/4/1990|                4|                4|             1990|SANTO ANDRE|     SAO PAULO|             SP|       SUDESTE|             SE|      BRASIL|           BR|\n",
      "|     5|          M-5|ABADE BATISTA|       M|          5/5/1990|                5|                5|             1990| PIRACICABA|     SAO PAULO|             SP|       SUDESTE|             SE|      BRASIL|           BR|\n",
      "+------+-------------+-------------+--------+------------------+-----------------+-----------------+-----------------+-----------+--------------+---------------+--------------+---------------+------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#visualizando um exemplo com 5 linhas do df para facilitar na criação das queries, conhecendo melhor a estrutura de dados\n",
    "funcionario.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+------+--------+---------------------+\n",
      "|equipePK|clientePK|dataPK| receita|quantidadeNegociacoes|\n",
      "+--------+---------+------+--------+---------------------+\n",
      "|       2|        9|    22|11564.75|                    1|\n",
      "|       2|       24|    11| 17990.5|                    1|\n",
      "|       2|       28|    21| 16335.9|                    1|\n",
      "|       1|       30|    23| 8495.55|                    1|\n",
      "|       2|       43|    30|24748.75|                    1|\n",
      "+--------+---------+------+--------+---------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#visualizando um exemplo com 5 linhas do df para facilitar na criação das queries, conhecendo melhor a estrutura de dados\n",
    "negociacao.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+------+-------+-------+---------------------+\n",
      "|funcPK|equipePK|dataPK|cargoPK|salario|quantidadeLancamentos|\n",
      "+------+--------+------+-------+-------+---------------------+\n",
      "|   147|       2|     5|     64|1559.94|                    1|\n",
      "|   124|       2|     5|    329|8102.77|                    1|\n",
      "|   175|       1|     5|    328|2532.51|                    1|\n",
      "|   171|       1|     5|    245| 7882.7|                    1|\n",
      "|   148|       2|     5|     65|4404.59|                    1|\n",
      "+------+--------+------+-------+-------+---------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#visualizando um exemplo com 5 linhas do df para facilitar na criação das queries, conhecendo melhor a estrutura de dados\n",
    "pagamento.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WkL4w2MMudL7"
   },
   "source": [
    "# 5 Instruções Importantes sobre a Avaliação\n",
    "\n",
    "Esta avaliação é composta por 7 questões referentes a diferentes consultas OLAP. O valor de cada questão encontra-se especificado juntamente com a definição da questão. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uKdDsHnDwlaH"
   },
   "source": [
    "## 5.1 Especificação das Consultas\n",
    "\n",
    "As consultas OLAP devem ser respondidas de acordo com o solicitado em cada questão. As seguintes solicitações podem ser feitas:\n",
    "\n",
    "- Resolva a questão especificando a consulta OLAP na **linguagem SQL**. Neste caso, a consulta deve ser respondida usando os conceitos apresentados na Aula 07 da disciplina. Ou seja, a consulta deve ser respondida usando a linguagem SQL textual e o método `spark.sql()`. Não é possível usar os demais métodos do módulo `pyspark.sql` para especificar a consulta, com exceção do método `show()` para listar o resultado da consulta.  \n",
    "\n",
    "- Resolva a questão especificando a consulta OLAP usando os **métodos de pyspark.sql**. Neste caso, a consulta deve ser respondida usando os conceitos apresentados na Aula 08 da disciplina. Ou seja, a consulta deve ser respondida usando os demais métodos do módulo `pyspark.sql`. Não é possível usar o método `spark.sql()` para especificar a consulta.\n",
    "\n",
    "Caso a consulta seja especificada de forma diferente do que foi solicitado, a resposta não será considerada, mesmo que ela esteja correta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EsrYR2SJw-x3"
   },
   "source": [
    "## 5.2 Ordem das Colunas e das Linhas\n",
    "\n",
    "A resolução das questões deve seguir estritamente as especificações definidas em cada consulta. Isto significa que:\n",
    "\n",
    "- As **colunas** solicitadas devem ser exibidas exatamente na mesma ordem que a definida na questão. Note que todas as colunas a serem exibidas como resposta da consulta, bem como a ordem na qual elas devem aparecer são sempre definidas na questão. \n",
    "\n",
    "- As **linhas** retornadas como respostas devem ser exibidas exatamente na mesma ordem que a definida na questão. Note que a ordem na qual as linhas devem aparecer são sempre definidas na questão. \n",
    "\n",
    "- Os **nomes das colunas** renomeadas devem seguir estritamente os nomes definidos na questão. Para evitar possíveis erros, os nomes das colunas renomeadas não possuem acentos e espaços em branco, além de serem escritos utilizando apenas letras maiúsculas. Note que os nomes das colunas renomeadas são sempre definidos na questão.\n",
    "\n",
    "Essas orientações devem ser seguidas uma vez que a correção da avaliação será realizada de forma automática. Caso a consulta retorne resultados de forma diferente do que foi solicitado, a resposta não será considerada, mesmo que ela esteja correta.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3AZ0475X4L59"
   },
   "source": [
    "## 5.3 Listagem das Respostas das Consultas\n",
    "\n",
    "A resposta de cada consulta deve ser listada usando o método `show()`. Nenhum outro método pode ser utilizado com essa finalidade.  \n",
    "\n",
    "Devem ser listadas apenas as `20` primeiras linhas de resposta de cada consulta. Adicionalmente, devem ser listadas *strings* com tamanho maior do que 20 caracteres, ou seja, o parâmetro `truncate` do método `show()` deve ser inicializado como `false`.\n",
    "\n",
    "Portanto, a listagem das respostas deve ser feita utilizando o método `show()` como especificado a seguir. \n",
    "\n",
    "- Quando a consulta OLAP for especificada usando a **linguagem SQL**. Utilize o comando `spark.sql(consultaSQL).show(20,truncate=False)` para exibir o resultado da consulta. \n",
    "\n",
    "- Quando a consulta OLAP for especificada usando os demais **métodos de pyspark.sql**. Utilize o comando `nomeDoDataFrame.show(20,truncate=False)` para exibir o resultado da consulta.\n",
    "\n",
    "Por padrão, o método `show()` exibe as `20` primeiras linhas. Mesmo assim, defina o valor `20` como parâmetro."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VzIcWYeOVOsN"
   },
   "source": [
    "## 5.4 Arredondamento dos Dados\n",
    "\n",
    "Deve ser realizado o arredondamento dos dados todas as vezes que uma função de agregação for aplicada às medidas numéricas `salario` da tabela de dimensão `pagamento` e `receita` da tabela de dimensão `negociacao`. \n",
    "\n",
    "O arredondamento deve ser realizado usando a função `round()` na linguagem SQL e o método `round()` em `pyspark.sql` e deve arredondar os dados até duas casas decimais. Por exemplo, podem ser produzidos resultados da forma `112233.4` e `112233.44`. \n",
    "\n",
    "Portanto, o arredondamento dos dados deve ser feito como especificado a seguir.\n",
    "\n",
    "- Quando a consulta OLAP for especificada usando a **linguagem SQL**. Utilize a função `ROUND(funçãoDeAgregação,2)` para arredondar o dado até duas casas decimais.\n",
    "\n",
    "- Quando a consulta OLAP for especificada usando os demais **métodos de pyspark.sql**. Utilize o método `round(funçãoDeAgregação,2)` para arredondar o dado até duas casas decimais."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DQVQqm0pNDS1"
   },
   "source": [
    "## 5.5 Comentários Explicativos\n",
    "\n",
    "Devem ser colocados comentários no código que expliquem o passo a passo da resolução da questão. Os comentários explicativos devem ser realizados como especificado a seguir. \n",
    "\n",
    "- Quando a consulta OLAP for especificada usando a **linguagem SQL**. Utilize `#` para colocar comentários gerais (conforme explicado para os demais métodos de `pyspark.sql`) ou utilize `--` para colocar comentários no comando SQL. Por exemplo:\n",
    "\n",
    "```\n",
    "-- na cláusula SELECT são listadas as colunas a serem exibidas\n",
    "SELECT funcNome\n",
    "-- na cláusula FROM são especificadas as relações temporárias\n",
    "FROM funcionario\n",
    "-- na cláusula WHERE são definidas as condições de seleção\n",
    "WHERE funcPK = 1\n",
    "```\n",
    "\n",
    "- Quando a consulta OLAP for especificada usando os demais **métodos de pyspark.sql**. Utilize `#` para colocar comentário. Por exemplo:\n",
    "\n",
    "```\n",
    "# no comando a seguir, é aplicado o método select() sobre o DataFrame \n",
    "# para listar as colunas a serem exibidas, depois é aplicado o método\n",
    "# filter() para listar as condições de seleção  \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6IcbpvZHPn3S"
   },
   "source": [
    "## 5.6 Indentação e Organização\n",
    "\n",
    "As consultas e os comandos que respondem às questões dessa avaliação devem ser escritos de forma indentada. Em caso de dúvida, observem os *notebooks* da Aula 07 e da Aula 08 e verifiquem como as consultas e os comandos foram indentados.\n",
    "\n",
    "Com relação à organização, é necessário que as respostas às questões sejam localizadas aonde especificado no *notebook*. Por favor, procurem por \"Resposta da Questão\" para encontrar o local no qual as respostas devem ser especificadas. Também é possível localizar o local das respostas utilizando o menu de navegação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uFjCivy1Mg-A"
   },
   "source": [
    "## 5.7 Critério de Avaliação\n",
    "\n",
    "Na correção da avaliação, serão ponderados os seguintes aspectos:\n",
    "\n",
    "- Corretude da execução das consultas OLAP.\n",
    "\n",
    "- Atendimento às especificações definidas nas seções 5.1, 5.2, 5.3 e 5.4.\n",
    "\n",
    "- Atendimento às especificações da sintaxe das cláusulas e dos métodos utilizados para resolver cada questão.\n",
    "\n",
    "- Qualidade da documentação entregue, de acordo com as especificações definidas nas seções 5.5 e 5.6. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ss0pmgplPAL3"
   },
   "source": [
    "# 6 Questões"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_emI31_-uYc5"
   },
   "source": [
    "O mercado de trabalho brasileiro usualmente mostra que as mulheres ainda não possuem o mesmo reconhecimento que os homens. Existem diversas pesquisas que mostram que as mulheres ganham menos que homens em todos os cargos, áreas de atuação e níveis de escolaridade. Além disso, mulheres ainda são minoria quando consideradas posições nos principais cargos de gestão. Adicionalmente, existem estudos que indicam que a participação feminina no mercado de trabalho brasileiro aumenta a produtividade. \n",
    "\n",
    "O objetivo da avaliação é investigar se existe disparidade entre o sexo feminino e masculino na BI Solutions. São considerados os seguintes aspectos nas análises a serem realizadas: temporalidade e regionalidade. \n",
    "\n",
    "Os resultados obtidos na avaliação poderão ser posteriormente utilizados para definir estratégias que a BI Solutions deve executar para resolver essa disparidade, caso necessário. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nLD9FAdWK-Sp"
   },
   "source": [
    "## 6.1 Visão Comparativa Relacionada aos Sexos\n",
    "\n",
    "O objetivo das análises desta seção é obter uma visão relacionada aos sexos, por meio da comparação da média dos salários recebidos por mulheres e homens. Podem ser realizadas diferentes análises, sendo que duas delas são solicitadas a seguir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3kUBwA4WKmQ_"
   },
   "source": [
    "### Questão 1 \n",
    "\n",
    "**(valor: 1,0)** Liste, para cada `dataAno` e para cada sexo do funcionário, a média dos salários. Arredonde a média dos salários para até duas casas decimais. Devem ser exibidas as colunas na ordem e com os nomes especificados a seguir: \"ANO\", \"SEXO\" e \"MEDIASALARIO\". Ordene as linhas exibidas primeiro por ano e depois por sexo, todos em ordem ascendente. Liste as primeiras 20 linhas da resposta, sem truncamento das *strings*.\n",
    "\n",
    "**Resolva a questão especificando a consulta OLAP na linguagem SQL**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PsWybehcoEvc"
   },
   "source": [
    "### Resposta da Questão 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "KLOmAqmOoMvJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+------------+\n",
      "|ANO |SEXO|MEDIASALARIO|\n",
      "+----+----+------------+\n",
      "|2016|F   |9169.65     |\n",
      "|2016|M   |6906.46     |\n",
      "|2017|F   |8336.19     |\n",
      "|2017|M   |7131.79     |\n",
      "|2018|F   |8334.27     |\n",
      "|2018|M   |7605.94     |\n",
      "|2019|F   |7585.33     |\n",
      "|2019|M   |7789.65     |\n",
      "|2020|F   |7585.33     |\n",
      "|2020|M   |7789.65     |\n",
      "+----+----+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Resposta da Questão 1\n",
    "\n",
    "#------------------------------------------------------CÓDIGO COMENTADO------------------------------------------------------#\n",
    "# 01. selecionando dataAno como ANO, funcSexo como SEXO e a média do salário com arredondamento de 2 casas como MEDIASALARIO #\n",
    "# 02. especificando as relações de data com pagamento contendo mesma dataPK                                                  #\n",
    "# 03. especificando as relações de funcionario com pagamento contendo mesmo funcPK                                           #\n",
    "# 04. agrupando os resultados por ANO e SEXO                                                                                 #\n",
    "# 05. ordenando o ANO e SEXO de forma ascendente                                                                             #\n",
    "# 06. apresentando os 20 primeiros resultados sem truncamento das strings                                                    #\n",
    "#----------------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "consultaSQL = \"\"\"\n",
    "SELECT dataAno AS `ANO`, funcSexo AS `SEXO`, ROUND(AVG(salario),2) AS `MEDIASALARIO`\n",
    "FROM data JOIN pagamento ON (data.dataPK = pagamento.dataPK)\n",
    "          JOIN funcionario ON (funcionario.funcPK = pagamento.funcPK)\n",
    "GROUP BY ANO, SEXO\n",
    "ORDER BY ANO ASC, SEXO ASC  \n",
    "\"\"\"\n",
    "spark.sql(consultaSQL).show(20,truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ddwc0fdWQpL1"
   },
   "source": [
    "### Questão 2\n",
    "\n",
    "**(valor: 1,0)** Liste todas as agregações que podem ser geradas a partir da média dos salários dos funcionários por `dataAno` por `funcSexo` por `funcRegiaoNome`. Arredonde a média dos salários para até duas casas decimais. Devem ser exibidas as colunas na ordem e com os nomes especificados a seguir: \"ANO\", \"SEXO\", \"REGIAO\", \"MEDIASALARIO\". Ordene as linhas exibidas primeiro por ano, depois por sexo, depois por nome da região, todos em ordem ascendente. Liste as primeiras 20 linhas da resposta, sem truncamento das *strings*.\n",
    "\n",
    "**Resolva a questão especificando a consulta OLAP usando os métodos de pyspark.sql**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-tfKPSOfolLI"
   },
   "source": [
    "### Resposta da Questão 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "FHxd4JUlopoE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+--------+------------+\n",
      "|ANO |SEXO|REGIAO  |MEDIASALARIO|\n",
      "+----+----+--------+------------+\n",
      "|null|null|null    |7672.31     |\n",
      "|null|null|NORDESTE|7151.73     |\n",
      "|null|null|SUDESTE |7446.14     |\n",
      "|null|null|SUL     |9397.76     |\n",
      "|null|F   |null    |7948.58     |\n",
      "|null|F   |NORDESTE|7043.42     |\n",
      "|null|F   |SUDESTE |7821.46     |\n",
      "|null|F   |SUL     |9282.97     |\n",
      "|null|M   |null    |7581.58     |\n",
      "|null|M   |NORDESTE|7183.82     |\n",
      "|null|M   |SUDESTE |7322.23     |\n",
      "|null|M   |SUL     |9437.12     |\n",
      "|2016|null|null    |7404.36     |\n",
      "|2016|null|NORDESTE|9351.25     |\n",
      "|2016|null|SUDESTE |6542.64     |\n",
      "|2016|null|SUL     |14505.59    |\n",
      "|2016|F   |null    |9169.65     |\n",
      "|2016|F   |SUDESTE |8587.4      |\n",
      "|2016|F   |SUL     |14992.14    |\n",
      "|2016|M   |null    |6906.46     |\n",
      "+----+----+--------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Resposta da Questão 2\n",
    "\n",
    "#importando a função round para poder fazer o arredondamento dos valores agregados\n",
    "from pyspark.sql.functions import round\n",
    "\n",
    "#------------------------------------------------------CÓDIGO COMENTADO-------------------------------------------------------#\n",
    "# 01. utilizando dados de funcionario                                                                                         #\n",
    "# 02. junto com dados de pagamento pela chave primária funcPK                                                                 #\n",
    "# 03. junto com dados de data pela chave primária dataPK                                                                      #\n",
    "# 04. selecionando os dados requisitados dataAno, funcSexo, funcRegiaoNome e salario                                          #\n",
    "# 05. listando todas as agregações com cube usando as dataAno, funcSexo, funcRegiaoNome e agregando pela média dos salários.  #\n",
    "#     O método cube serve para criar subtotais para todas as combinações de atributos definidos na lista de agrupamento       #\n",
    "# 06. arredondando média dos salários para duas casas decimais                                                                #\n",
    "# 07. renomeando dataAno para ANO                                                                                             #\n",
    "# 08. renomeando funcSexo para SEXO                                                                                           #\n",
    "# 09. renomeando funcRegiaoNome para REGIAO                                                                                   #\n",
    "# 10. renomeando avg(salario) para MEDIASALARIO                                                                               #\n",
    "# 11. ordenando por dataAno, funcSexo e funcRegiaoNome, todos ascendentes                                                     #\n",
    "# 12. apresentando os 20 primeiros resultados sem truncamento das strings                                                     #\n",
    "#-----------------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "funcionario\\\n",
    "    .join(pagamento, on='funcPK')\\\n",
    "    .join(data, on='dataPK')\\\n",
    "    .select('dataAno','funcSexo','funcRegiaoNome','salario')\\\n",
    "    .cube('dataAno','funcSexo','funcRegiaoNome').avg('salario')\\\n",
    "    .withColumn('avg(salario)',round('avg(salario)',2))\\\n",
    "    .withColumnRenamed('dataAno','ANO')\\\n",
    "    .withColumnRenamed('funcSexo','SEXO')\\\n",
    "    .withColumnRenamed('funcRegiaoNome','REGIAO')\\\n",
    "    .withColumnRenamed('avg(salario)','MEDIASALARIO')\\\n",
    "    .orderBy('dataAno','funcSexo','funcRegiaoNome', ascending=True)\\\n",
    "    .show(20,truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oBBSsa9WlJ2f"
   },
   "source": [
    "## 6.2 Visão Específica da Atuação Feminina\n",
    "\n",
    "O objetivo das análises desta seção é obter uma visão direcionada especificamente à atuação feminina, considerando aspectos individuais referentes a salários e receitas. Podem ser realizadas diferentes análises, sendo que duas delas são solicitadas a seguir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T6QZzSzGbXQI"
   },
   "source": [
    "### Questão 3\n",
    "\n",
    "**(valor 1,5)** Liste, para cada `dataAno`, a soma dos salários das funcionárias do sexo feminino que nasceram entre os anos de 1970 (inclusive) e 1990 (inclusive) e que moram na região \"SUDESTE\" (\"SE\") ou \"NORDESTE\" (\"NE\"). Arredonde a soma dos salários para até duas casas decimais. Devem ser exibidas as colunas na ordem e com os nomes especificados a seguir: \"ANO\", \"IDADE\", \"REGIAO\" e \"TOTALSALARIO\". Ano corresponde ao atributo `dataAno` da tabela de dimensão `data`, idade corresponde ao cálculo feito considerando o ano atual de 2020 e o atributo `funcAnoNascimento` da tabela de dimensão `funcionario`, região corresponde ao atributo `funcRegiaoNome` da tabela de dimensão `funcionario`. Ordene as linhas exibidas primeiro por ano, depois por idade e depois por região, todos em ordem ascendente. Liste as primeiras 20 linhas da resposta, sem truncamento das *strings*.\n",
    "\n",
    "**Resolva a questão especificando a consulta OLAP na linguagem SQL**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eqsvVdf9pATO"
   },
   "source": [
    "### Resposta da Questão 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "_Blhjz07pDGt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+--------+------------+\n",
      "|ANO |IDADE|REGIAO  |TOTALSALARIO|\n",
      "+----+-----+--------+------------+\n",
      "|2016|30   |SUDESTE |342165.96   |\n",
      "|2016|47   |SUDESTE |172363.32   |\n",
      "|2017|30   |NORDESTE|21567.36    |\n",
      "|2017|30   |SUDESTE |1330655.03  |\n",
      "|2017|46   |SUDESTE |53737.44    |\n",
      "|2017|47   |SUDESTE |196181.64   |\n",
      "|2018|30   |NORDESTE|70918.68    |\n",
      "|2018|30   |SUDESTE |1768666.66  |\n",
      "|2018|35   |SUDESTE |113653.8    |\n",
      "|2018|46   |SUDESTE |53737.44    |\n",
      "|2018|47   |SUDESTE |196181.64   |\n",
      "|2019|30   |NORDESTE|416759.88   |\n",
      "|2019|30   |SUDESTE |1927991.98  |\n",
      "|2019|34   |SUDESTE |59745.6     |\n",
      "|2019|35   |SUDESTE |113653.8    |\n",
      "|2019|46   |SUDESTE |53737.44    |\n",
      "|2019|47   |SUDESTE |196181.64   |\n",
      "|2020|30   |NORDESTE|416759.88   |\n",
      "|2020|30   |SUDESTE |1927991.98  |\n",
      "|2020|34   |SUDESTE |59745.6     |\n",
      "+----+-----+--------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Resposta da Questão 3\n",
    "\n",
    "#------------------------------------------------------CÓDIGO COMENTADO------------------------------------------------------#\n",
    "# 01. selecionando dataAno como ANO                                                                                          #\n",
    "#     aplicando um select para extrair o ano atual e subtraindo de funcAnoNascimento para definir a IDADE                    #\n",
    "#     selecionando funcRegiaoNome como REGIAO                                                                                #\n",
    "#     realizando a soma dos salarios arredondando para 2 casas decimais como TOTALSALARIO                                    #\n",
    "# 02. especificando as relações de data com pagamento contendo mesma dataPK                                                  #\n",
    "# 03. especificando as relações de funcionario com pagamento contendo mesmo funcPK                                           #\n",
    "# 04. aplicando condição para funcionárias apenas do sexo feminino                                                           #\n",
    "# 05. que nasceram entre 1970 (inclusive) e 1990 (inclusive) aplicando a função BETWEEN                                      #\n",
    "# 06. que vivem no SUDESTE ou no NORDESTE (tanto pelo nome da região quanto pela sigla)                                      #\n",
    "# 07. agrupando os dados por ANO, IDADE e REGIAO                                                                             #\n",
    "# 08. ordenando por ANO, IDADE e REGIAO de forma ascendente                                                                  #\n",
    "# 09. apresentando os 20 primeiros resultados sem truncamento das strings                                                    #\n",
    "#----------------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "consultaSQL = \"\"\"\n",
    "SELECT dataAno AS `ANO`, ((SELECT EXTRACT (YEAR FROM CURRENT_DATE)) - funcAnoNascimento) AS `IDADE`, funcRegiaoNome AS `REGIAO`, ROUND(SUM(salario),2) AS `TOTALSALARIO`\n",
    "FROM data JOIN pagamento   ON (data.dataPK = pagamento.dataPK)\n",
    "          JOIN funcionario ON (funcionario.funcPK = pagamento.funcPK)\n",
    "WHERE funcSexo = 'F' \n",
    "      AND funcAnoNascimento BETWEEN 1970 AND 1990\n",
    "      AND (funcRegiaoNome = 'SUDESTE' OR  funcRegiaoNome = 'NORDESTE' OR funcRegiaoSigla = 'SE' OR funcRegiaoSigla = 'NE')\n",
    "GROUP BY ANO, IDADE, REGIAO \n",
    "ORDER BY ANO ASC, IDADE ASC, REGIAO ASC\n",
    "\"\"\"\n",
    "spark.sql(consultaSQL).show(20,truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZE-uEzVVm5Pk"
   },
   "source": [
    "### Questão 4 \n",
    "\n",
    "**(valor 1,5)** Considere que as equipes cujos valores de `equipePK` são iguais a `1, 3 e 5` possuem a maior quantidade de funcionárias do sexo feminino. Liste, para cada `dataAno`, a soma das receitas recebidas por essas equipes, o nome da equipe, o nome da filial e o setor do cliente, considerando apenas os clientes localizados na cidade de \"SAO CARLOS\". Arredonde a média dos salários para até duas casas decimais. Devem ser exibidas as colunas na ordem e com os nomes especificados a seguir: \"ANO\", \"NOMEEQUIPE\", \"NOMEFILIAL\", \"SETORCLIENTE\", \"TOTALRECEITA\". Ordene as linhas exibidas primeiro por ano, depois por nome da equipe, depois por nome da filial e depois por setor do cliente, todos em ordem ascendente. Liste as primeiras 20 linhas da resposta, sem truncamento das *strings*.\n",
    "\n",
    "**Resolva a questão especificando a consulta usando os métodos de pyspark.sql**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v5h4J6hCpf79"
   },
   "source": [
    "### Resposta da Questão 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "TPABkaULpiYv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------+------------------------+-------------------+------------+\n",
      "|ANO |NOMEEQUIPE   |NOMEFILIAL              |SETORCLIENTE       |TOTALRECEITA|\n",
      "+----+-------------+------------------------+-------------------+------------+\n",
      "|2016|APP - DESKTOP|SAO PAULO - AV. PAULISTA|BEBIDAS E ALIMENTOS|82203.8     |\n",
      "|2016|APP - DESKTOP|SAO PAULO - AV. PAULISTA|VESTUARIO          |71010.0     |\n",
      "|2017|APP - DESKTOP|SAO PAULO - AV. PAULISTA|BEBIDAS E ALIMENTOS|11256.35    |\n",
      "|2017|APP - DESKTOP|SAO PAULO - AV. PAULISTA|VESTUARIO          |103029.5    |\n",
      "|2017|WEB          |CAMPO GRANDE - CENTRO   |TECNOLOGIA         |57953.4     |\n",
      "|2017|WEB          |CAMPO GRANDE - CENTRO   |VESTUARIO          |12275.45    |\n",
      "|2017|WEB          |SAO PAULO - AV. PAULISTA|TECNOLOGIA         |3602.75     |\n",
      "|2017|WEB          |SAO PAULO - AV. PAULISTA|VESTUARIO          |37813.15    |\n",
      "|2018|APP - DESKTOP|SAO PAULO - AV. PAULISTA|BEBIDAS E ALIMENTOS|12383.8     |\n",
      "|2018|APP - DESKTOP|SAO PAULO - AV. PAULISTA|VESTUARIO          |76043.15    |\n",
      "|2018|WEB          |CAMPO GRANDE - CENTRO   |TECNOLOGIA         |26722.1     |\n",
      "|2018|WEB          |CAMPO GRANDE - CENTRO   |VESTUARIO          |970.1       |\n",
      "|2018|WEB          |SAO PAULO - AV. PAULISTA|TECNOLOGIA         |31092.85    |\n",
      "|2018|WEB          |SAO PAULO - AV. PAULISTA|VESTUARIO          |16979.95    |\n",
      "|2019|APP - DESKTOP|SAO PAULO - AV. PAULISTA|BEBIDAS E ALIMENTOS|37909.9     |\n",
      "|2019|APP - DESKTOP|SAO PAULO - AV. PAULISTA|VESTUARIO          |32699.5     |\n",
      "|2019|WEB          |CAMPO GRANDE - CENTRO   |TECNOLOGIA         |8521.45     |\n",
      "|2019|WEB          |CAMPO GRANDE - CENTRO   |VESTUARIO          |514.35      |\n",
      "|2019|WEB          |SAO PAULO - AV. PAULISTA|TECNOLOGIA         |16136.5     |\n",
      "|2019|WEB          |SAO PAULO - AV. PAULISTA|VESTUARIO          |1201.05     |\n",
      "+----+-------------+------------------------+-------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Reposta da Questão 4\n",
    "\n",
    "#------------------------------------------------------CÓDIGO COMENTADO------------------------------------------------------#\n",
    "# 01. utilizando dados de negociacao                                                                                         #\n",
    "# 02. juntando com dados de equipe pela chave primária equipePK                                                              #\n",
    "# 03. juntando com dados de data pela chave primária dataPK                                                                  #\n",
    "# 04. juntando com dados de cliente pela chave primária clientePK                                                            #\n",
    "# 05. aplicando condição para equipePK sendo 1, 3  e 5 e clientes da cidade de SAO CARLOS                                    #\n",
    "# 06. selecionando os dados requisitados dataAno, equipeNome, filialNome, clienteSetor e receita                             #\n",
    "# 07. agrupando por dataAno, equipeNome, filialNome, clienteSetor e agregando pela soma das receitas                         #\n",
    "# 08. arredondando a soma da receitas para 2 casas decimais                                                                  #\n",
    "# 09. renomeando dataAno para ANO                                                                                            #\n",
    "# 10. renomeando equipeNome para NOMEEQUIPE                                                                                  #\n",
    "# 11. renomeando filialNome para NOMEFILIAL                                                                                  #\n",
    "# 12. renomeando clienteSetor para SETORCLIENTE                                                                              #\n",
    "# 13. renomeando sum(receita) para TOTALRECEITA                                                                              #\n",
    "# 14. ordenando por ANO, NOMEEQUIPE, NOMEFILIAL e SETORCLIENTE de forma ascendente                                           #\n",
    "# 15. apresentando os 20 primeiros resultados sem truncamento das strings                                                    #\n",
    "#----------------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "negociacao\\\n",
    "    .join(equipe, on='equipePK')\\\n",
    "    .join(data, on='dataPK')\\\n",
    "    .join(cliente, on='clientePK')\\\n",
    "    .where('(equipePK = 1 OR equipePK = 3 OR equipePK = 5) AND clienteCidade = \"SAO CARLOS\"')\\\n",
    "    .select('dataAno', 'equipeNome', 'filialNome', 'clienteSetor', 'receita')\\\n",
    "    .groupBy('dataAno', 'equipeNome', 'filialNome', 'clienteSetor').sum('receita')\\\n",
    "    .withColumn('sum(receita)',round('sum(receita)',2))\\\n",
    "    .withColumnRenamed('dataAno','ANO')\\\n",
    "    .withColumnRenamed('equipeNome','NOMEEQUIPE')\\\n",
    "    .withColumnRenamed('filialNome','NOMEFILIAL')\\\n",
    "    .withColumnRenamed('clienteSetor','SETORCLIENTE')\\\n",
    "    .withColumnRenamed('sum(receita)','TOTALRECEITA')\\\n",
    "    .orderBy('ANO','NOMEEQUIPE','NOMEFILIAL', 'SETORCLIENTE',ascending=True)\\\n",
    "    .show(20,truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cif1-kov8bym"
   },
   "source": [
    "## 6.3 Visão Geral da Atuação Feminina\n",
    "\n",
    "O objetivo das análises desta seção é obter uma visão direcionada especificamente à atuação feminina, considerando aspectos conjuntos referentes a salários e receitas. Podem ser realizadas diferentes análises, dentre as quais destaca-se a análise base descrita a seguir.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wRagvNvcWX3Q"
   },
   "source": [
    "### **Análise Base** \n",
    "\n",
    "Liste, para cada `dataAno`, a soma dos salários das funcionárias de sexo feminino que moram no estado do \"RIO DE JANEIRO\" (\"RJ\") e as somas das receitas recebidas pelas equipes localizadas no estado do \"RIO DE JANEIRO\" (\"RJ\"). O estado no qual as funcionárias moram pode ser identificado pelos atributos `funcEstadoNome` ou `funcEstadoSigla` da tabela de dimensão `funcionario`, enquanto que o estado nos quais as equipes estão localizadas pode ser identificado pelos atributos `filialEstadoNome` ou `filialEstadoSigla` da tabela de dimensão `equipe`. Arredonde a soma dos salários e a soma das receitas para até duas casas decimais. Devem ser exibidas as colunas na ordem e com os nomes especificados a seguir: \"ANO\", \"TOTALSALARIO\", \"TOTALRECEITA\". Ordene as linhas exibidas por ano em ordem ascendente. Liste as primeiras 20 linhas da resposta, sem truncamento das *strings*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xr4W91rckYJJ"
   },
   "source": [
    "### Questão 5\n",
    "**(valor: 1,5) Resolva a \"Análise Base\" especificando a consulta OLAP na linguagem SQL**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZYjwVTL3p1Jc"
   },
   "source": [
    "### Resposta da Questão 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "_B7n3riYp9bj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------+------------+\n",
      "|ANO |TOTALSALARIO|TOTALRECEITA|\n",
      "+----+------------+------------+\n",
      "|2016|30061.2     |2205042.91  |\n",
      "|2017|30061.2     |3484981.8   |\n",
      "|2018|48108.36    |4741199.75  |\n",
      "|2019|70794.36    |5100984.61  |\n",
      "|2020|70794.36    |4192420.2   |\n",
      "+----+------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Resposta da Questão 5\n",
    "\n",
    "#------------------------------------------------------CÓDIGO COMENTADO------------------------------------------------------#\n",
    "#    Neste caso vamos usar a operação drill-across que compara medidas numéricas de tabelas de fatos diferentes              #\n",
    "#    utilizando uma dimensão em comum (no caso data).                                                                        #\n",
    "# 01. selecionando dataAnoP (dataAno já consolidada na subquery de salário) como ANO                                         #\n",
    "#     selecionando a soma dos salarios arredondando com 2 casas como TOTALSALARIO                                            #\n",
    "#     selecionando a soma das receitas arredondando com 2 casas como TOTALRECEITA                                            #\n",
    "#    Vamos executar dois sub-selects no comando FROM. O primeiro responsável pelos dados de salário e o segundo de receita   #\n",
    "# 02. selecionando dataAno de data e soma dos salarios de funcionario                                                        #\n",
    "# 03. especificando as relações de pagamento com data contendo mesma dataPK                                                  #\n",
    "# 04. especificando as relações de funcionario com pagamento contendo mesmo funcPK                                           #\n",
    "# 05. aplicando condição para funcionárias apenas do sexo feminino                                                           #\n",
    "# 06. aplicando condição para funcionárias do RIO DE JANEIRO (filtrando tanto pelo nome do estado quanto pela sigla)         #\n",
    "# 07. agrupando os dados por dataAno                                                                                         #\n",
    "# 08. aplicando os resultados do sub-select como dataAnoP para dataAno e salario como o total do salário das funcionárias    #\n",
    "# 09. cláusula para fazer a junção com outro sub-select, agora aplicado nos dados de receita                                 #\n",
    "# 10. selecionando dataAno de data e soma das receitas de negociação                                                         #\n",
    "# 11. especificando as relações de data com negociação contendo mesma dataPK                                                 #\n",
    "# 12. especificando as relações de equipe com negociação contendo mesmo equipePK                                             #\n",
    "# 13. aplicando condição para equipes do RIO DE JANEIRO (filtrando tanto pelo nome do estado quanto pela sigla)              #\n",
    "# 14. agrupando os dados por dataAno                                                                                         #\n",
    "# 15. aplicando os resultados do sub-select como dataAnoN para dataAno e receita como o total do receita das equipes         #\n",
    "# 16. aplicando condição para juntar a dimensão em comum, dataAnoP do salário igual ao dataAnoN da receita                   #\n",
    "# 17. agrupando por data, no caso dataAnoP                                                                                   #\n",
    "# 18. ordenando por data, no caso dataAnoP de forma ascendente                                                               #\n",
    "# 19. apresentando os 20 primeiros resultados sem truncamento das strings                                                    #\n",
    "#----------------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "consultaSQL = \"\"\"\n",
    "SELECT dataAnoP AS `ANO`, ROUND(SUM(salario),2) AS `TOTALSALARIO`, ROUND(SUM(receita),2) AS `TOTALRECEITA`\n",
    "FROM ( SELECT dataAno, SUM(salario)\n",
    "       FROM pagamento JOIN data        ON (pagamento.dataPK = data.dataPK)\n",
    "                      JOIN funcionario ON (funcionario.funcPK = pagamento.funcPK)\n",
    "        WHERE funcSexo = 'F'\n",
    "              AND (funcEstadoNome = 'RIO DE JANEIRO' OR funcEstadoSigla = 'RJ')\n",
    "        GROUP BY dataAno\n",
    "      ) AS sal(dataAnoP, salario)\n",
    "      JOIN \n",
    "      ( SELECT dataAno, SUM(receita)\n",
    "        FROM data JOIN negociacao ON (data.dataPK = negociacao.dataPK)\n",
    "                  JOIN equipe     ON (equipe.equipePK = negociacao.equipePK)\n",
    "        WHERE (filialEstadoNome = 'RIO DE JANEIRO' OR filialEstadoSigla = 'RJ')\n",
    "        GROUP BY dataAno\n",
    "      ) AS rec(dataAnoN, receita)\n",
    "WHERE dataAnoP = dataAnoN\n",
    "GROUP BY dataAnoP\n",
    "ORDER BY dataAnoP ASC\n",
    "\"\"\"\n",
    "spark.sql(consultaSQL).show(20,truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H6NnIh3qE3zE"
   },
   "source": [
    "###  Questão 6 \n",
    "\n",
    "**(valor: 1,5) Resolva a \"Análise Base\" especificando a consulta OLAP usando os métodos de pyspark.sql**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mbMGkFxAqEwP"
   },
   "source": [
    "### Resposta da Questão 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "at7o5_tbqHMa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------+------------+\n",
      "|ANO |TOTALSALARIO|TOTALRECEITA|\n",
      "+----+------------+------------+\n",
      "|2016|30061.2     |2205042.91  |\n",
      "|2017|30061.2     |3484981.8   |\n",
      "|2018|48108.36    |4741199.75  |\n",
      "|2019|70794.36    |5100984.61  |\n",
      "|2020|70794.36    |4192420.2   |\n",
      "+----+------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Resposta da Questão 6\n",
    "\n",
    "#------------------------------------------------------CÓDIGO COMENTADO------------------------------------------------------#\n",
    "#    Neste caso vamos usar a operação drill-across que compara medidas numéricas de tabelas de fatos diferentes              #\n",
    "#    utilizando uma dimensão em comum (no caso data). Neste caso, vamos precisar separar as consultas em dois blocos,        #\n",
    "#    sendo o primeiro referente aos dados de salario e o segundo referente aos dados de receitas.                            #\n",
    "# 01. utilizando dados de pagamento e atribuindo ao bloco 1 nomeado de pag                                                   #\n",
    "# 02. juntando com dados de data pela chave primária dataPK                                                                  #\n",
    "# 03. juntando com dados de funcionario pela chave primária funcPK                                                           #\n",
    "# 04. aplicando condição para identificar funcionárias do estado do RIO DE JANEIRO (tanto por nome quanto por sigla)         #\n",
    "# 05. selecionando os dados de dataAno e salario como resultados do bloco 1                                                  #\n",
    "# 06. agrupando os dados por dataAno                                                                                         #\n",
    "# 07. agregando os dados de salário como o total do salário das funcionárias                                                 #\n",
    "# 08. utilizando dados de negociacao e atribuindo ao bloco 2 nomeado de neg                                                  #\n",
    "# 09. juntando com dados de data pela chave primária dataPK                                                                  #\n",
    "# 10. juntando com dados de equipe pela chave primária equipePK                                                              #\n",
    "# 11. aplicando condição para identificar equipes do estado do RIO DE JANEIRO (tanto por nome quanto por sigla)              #\n",
    "# 12. selecionando os dados de dataAno e receita como resultados do bloco 2                                                  #\n",
    "# 13. agrupando os dados por dataAno                                                                                         #\n",
    "# 14. agregando os dados de receita como o total da receita das equipes                                                      #\n",
    "# 15. utilizando dados do bloco 1 nomeado de pag                                                                             #\n",
    "# 16. juntando com dados do bloco 2 nomeado de neg pela dimensão em comum entre ambas, no caso, dataAno                      #\n",
    "# 17. selecionando os dados de dataAno, total de salarios e total de receitas                                                #\n",
    "# 18. arredondando a soma dos salários para 2 casas decimais                                                                 #\n",
    "# 19. arredondando a soma da receitas para 2 casas decimais                                                                  #\n",
    "# 20. renomeando dataAno para ANO                                                                                            #\n",
    "# 21. renomeando sum(salario) para TOTALSALARIO                                                                              #\n",
    "# 22. renomeando sum(receita) para TOTALRECEITA                                                                              #\n",
    "# 23. ordenando por data, no caso ANO de forma ascendente                                                                    #\n",
    "# 24. apresentando os 20 primeiros resultados sem truncamento das strings                                                    #\n",
    "#----------------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "pag = pagamento\\\n",
    "   .join(data, on='dataPK')\\\n",
    "   .join(funcionario, on='funcPK')\\\n",
    "   .where('funcSexo = \"F\" AND (funcEstadoNome = \"RIO DE JANEIRO\" OR funcEstadoSigla = \"RJ\")')\\\n",
    "   .select('dataAno', 'salario')\\\n",
    "   .groupBy('dataAno')\\\n",
    "   .sum('salario')\n",
    "\n",
    "neg = negociacao\\\n",
    "   .join(data, on='dataPK')\\\n",
    "   .join(equipe, on='equipePK')\\\n",
    "   .where('filialEstadoNome = \"RIO DE JANEIRO\" OR filialEstadoSigla = \"RJ\"')\\\n",
    "   .select('dataAno', 'receita')\\\n",
    "   .groupBy('dataAno')\\\n",
    "   .sum(\"receita\")\n",
    "\n",
    "pag\\\n",
    "   .join(neg, on='dataAno')\\\n",
    "   .select('dataAno', 'sum(salario)', 'sum(receita)')\\\n",
    "   .withColumn('sum(salario)', round('sum(salario)',2))\\\n",
    "   .withColumn('sum(receita)', round('sum(receita)',2))\\\n",
    "   .withColumnRenamed('dataAno', 'ANO')\\\n",
    "   .withColumnRenamed(\"sum(salario)\", 'TOTALSALARIO')\\\n",
    "   .withColumnRenamed(\"sum(receita)\", 'TOTALRECEITA')\\\n",
    "   .orderBy('ANO',ascending=True)\\\n",
    "   .show(20,truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PWCX859nDwG3"
   },
   "source": [
    "## 6.4 Visão Comparativa Final\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oadu9w10TfFq"
   },
   "source": [
    "O objetivo da análise desta seção é obter uma visão relacionada aos sexos, por meio da comparação do total anual de gastos em salários para o pagamento das mulheres e dos homens em comparação ao total anual de receitas recebidas. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D9ccL9R-QPuT"
   },
   "source": [
    "### Questão 7\n",
    "\n",
    "**(valor 2,0)** Liste, para cada `dataAno`, a soma dos salários das funcionárias de sexo feminino, a soma dos salários dos funcionários do sexo masculino e as somas das receitas recebidas. Arredonde a soma dos salários e a soma das receitas para até duas casas decimais. Devem ser exibidas as colunas na ordem e com os nomes especificados a seguir: \"ANO\", \"TOTALSALARIOMULHERES\", \"TOTALSALARIOHOMENS\", \"TOTALRECEITA\". Ordene as linhas exibidas por ano em ordem ascendente. Liste as primeiras 20 linhas da resposta, sem truncamento das *strings*.\n",
    "\n",
    "**Resolva a questão especificando a consulta OLAP na linguagem SQL**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DFOQQmdbqbft"
   },
   "source": [
    "### Resposta da Questão 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "MrJNZCS2qeE7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+------------------+------------+\n",
      "|ANO |TOTALSALARIOMULHERES|TOTALSALARIOHOMENS|TOTALRECEITA|\n",
      "+----+--------------------+------------------+------------+\n",
      "|2016|1210393.21          |3232223.89        |4614246.97  |\n",
      "|2017|2500857.97          |7274421.87        |7200423.35  |\n",
      "|2018|3800427.49          |11135098.98       |11593539.66 |\n",
      "|2019|4733247.25          |13834419.20       |35353318.33 |\n",
      "|2020|4733247.25          |13834419.20       |30222175.87 |\n",
      "+----+--------------------+------------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Resposta da Questão 7\n",
    "\n",
    "#------------------------------------------------------CÓDIGO COMENTADO------------------------------------------------------#\n",
    "#    Neste caso vamos usar a operação drill-across que compara medidas numéricas de tabelas de fatos diferentes              #\n",
    "#    utilizando uma dimensão em comum (no caso data).                                                                        #\n",
    "# 01. selecionando dataAnoPF (dataAno já consolidada na subquery de salário para sexo feminino) como ANO                     #\n",
    "#     selecionando a soma dos salarios femininos arredondando com 2 casas como TOTALSALARIOMULHERES                          #\n",
    "#     selecionando a soma dos salarios masculinos arredondando com 2 casas como TOTALSALARIOHOMENS                           #\n",
    "#     selecionando a soma das receitas arredondando com 2 casas como TOTALRECEITA                                            #\n",
    "#    Nestes casos, tivemos alguns números sendo apresentados com notação científica, portanto, aplicamos a função CAST       #\n",
    "#    AS DECIMAL, para a saída ficar no formato adequado (requerido no exercício). Como parâmetros do DECIMAL passamos o      #\n",
    "#    valor 10 (tamanho considerado adequado - número de dígitos permitidos na parte inteira) e 2 (número de casas decimais). #\n",
    "#    Vamos executar três sub-selects no comando FROM. O primeiro responsável pelos dados de salário feminino                 #\n",
    "#    o segundo responsável pelos dados de salário masculino e o terceiro responsável pelos dados de receita.                 #\n",
    "# 02. selecionando dataAno de data e soma dos salarios como salarioF (que terá os dados para funcionárias de sexo feminino)  #\n",
    "# 03. especificando as relações de pagamento com data contendo mesma dataPK                                                  #\n",
    "# 04. especificando as relações de funcionario com pagamento contendo mesmo funcPK                                           #\n",
    "# 05. aplicando condição para funcionárias apenas do sexo feminino                                                           #\n",
    "# 06. agrupando os dados por dataAno                                                                                         #\n",
    "# 07. aplicando os resultados do sub-select como dataAnoPF para dataAno e salarioF como o total do salário das mulheres      #\n",
    "# 08. cláusula para juntarmos o segundo sub-select                                                                           #\n",
    "# 09. selecionando dataAno de data e soma dos salarios como salarioM (que terá os dados para funcionárias de sexo masculino) #\n",
    "# 10. especificando as relações de pagamento com data contendo mesma dataPK                                                  #\n",
    "# 11. especificando as relações de funcionario com pagamento contendo mesmo funcPK                                           #\n",
    "# 12. aplicando condição para funcionários apenas do sexo masculino                                                          #\n",
    "# 13. agrupando os dados por dataAno                                                                                         #\n",
    "# 14. aplicando os resultados do sub-select como dataAnoPM para dataAno e salarioM como o total do salário dos homens        #\n",
    "# 15. cláusula para juntarmos o terceiro sub-select                                                                          #\n",
    "# 16. selecionando dataAno de data e soma das receitas de negociação                                                         #\n",
    "# 17. especificando as relações de data com negociação contendo mesma dataPK                                                 #\n",
    "# 18. especificando as relações de equipe com negociação contendo mesmo equipePK                                             #\n",
    "# 19. agrupando os dados por dataAno                                                                                         #\n",
    "# 20. aplicando os resultados do sub-select como dataAnoN para dataAno e receita como o total do receita das equipes         #\n",
    "# 21. aplicando condição para juntar a dimensão em comum, dataAnoPF igual ao dataAnoN, igual ao dataAnoPM                    #\n",
    "# 22. agrupando por data, no caso dataAnoPF                                                                                  #\n",
    "# 23. ordenando por data, no caso dataAnoPF de forma ascendente                                                              #\n",
    "# 24. apresentando os 20 primeiros resultados sem truncamento das strings                                                    #\n",
    "#----------------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "consultaSQL = \"\"\"\n",
    "SELECT dataAnoPF AS `ANO`, CAST(ROUND(SUM(salarioF),2) AS DECIMAL(10,2)) AS `TOTALSALARIOMULHERES`, CAST(ROUND(SUM(salarioM),2) AS DECIMAL(10,2)) AS `TOTALSALARIOHOMENS`, CAST(ROUND(SUM(receita),2) AS DECIMAL(10,2)) AS `TOTALRECEITA`\n",
    "FROM  ( SELECT dataAno, SUM(salario) AS `salarioF`\n",
    "        FROM pagamento JOIN data        ON (pagamento.dataPK = data.dataPK)\n",
    "                       JOIN funcionario ON (funcionario.funcPK = pagamento.funcPK)\n",
    "        WHERE funcSexo = 'F'\n",
    "        GROUP BY dataAno\n",
    "      ) AS salF(dataAnoPF, salarioF)\n",
    "      JOIN \n",
    "      ( SELECT dataAno, SUM(salario) AS `salarioM`\n",
    "        FROM pagamento JOIN data        ON (pagamento.dataPK = data.dataPK)\n",
    "                       JOIN funcionario ON (funcionario.funcPK = pagamento.funcPK)\n",
    "        WHERE funcSexo = 'M'\n",
    "        GROUP BY dataAno\n",
    "      ) AS salM (dataAnoPM, salarioM)\n",
    "      JOIN \n",
    "      ( SELECT dataAno, SUM(receita)\n",
    "        FROM data JOIN negociacao ON (data.dataPK = negociacao.dataPK)\n",
    "                  JOIN equipe     ON (equipe.equipePK = negociacao.equipePK)\n",
    "        GROUP BY dataAno\n",
    "      ) AS rec(dataAnoN, receita)\n",
    "WHERE (dataAnoPF = dataAnoN AND dataAnoPF = dataAnoPM)\n",
    "GROUP BY dataAnoPF\n",
    "ORDER BY dataAnoPF ASC\n",
    "\"\"\"\n",
    "spark.sql(consultaSQL).show(20,truncate=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Avaliação Final.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
